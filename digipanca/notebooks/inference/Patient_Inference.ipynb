{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384be6a5-c2d1-4531-bfda-e41e1bc80355",
   "metadata": {},
   "source": [
    "# __Import & config__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d23d53-e5ce-4378-8153-6c6b956dd8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Usuario\\\\TFG\\\\digipanca\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b56e1a-3a74-49af-805c-983c3df4d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from celluloid import Camera\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from src.utils.config import load_config\n",
    "from src.utils.evaluation import load_trained_model\n",
    "from src.inference.predicter import Predicter2D, Predicter3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1af31c-6869-4039-90bb-72cdaf4bbf1f",
   "metadata": {},
   "source": [
    "# __Functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5855e29f-471f-4129-b9b9-949ba7ade5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_visualize(patient_id, predicter, output_dir, mode=\"2D\"):\n",
    "    \"\"\"\n",
    "    Predicts a patient's data, visualizes the results, and exports them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_id : str\n",
    "        ID of the patient to predict.\n",
    "    predicter : Predicter2D or Predicter3D\n",
    "        The predicter object to use for predictions.\n",
    "    output_dir : str\n",
    "        Directory to save the outputs.\n",
    "    mode : str, optional\n",
    "        Mode of prediction (\"2D\" or \"3D\"), by default \"2D\".\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Perform prediction\n",
    "    print(f\"üîç Predicting patient {patient_id}...\")\n",
    "    predictions, masks = predicter.predict_patient(patient_id)\n",
    "\n",
    "    # Convert predictions to NumPy arrays\n",
    "    predictions = predictions.squeeze(0).cpu().numpy()  # (C, D, H, W)\n",
    "    masks = masks.squeeze(0).cpu().numpy()              # (1, D, H, W)\n",
    "\n",
    "    # Visualize predictions and masks as an animation\n",
    "    visualize_animation(predictions, masks, output_dir, mode)\n",
    "\n",
    "    # Visualize predictions as a 3D volume\n",
    "    visualize_3d(predictions, output_dir)\n",
    "\n",
    "    # Export predictions and masks to NIfTI\n",
    "    export_to_nifti(predictions, masks, output_dir, patient_id)\n",
    "\n",
    "def visualize_animation(predictions, masks, output_dir, mode):\n",
    "    \"\"\"\n",
    "    Creates an animation of predictions and masks side by side.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : np.ndarray\n",
    "        Predicted volumes (C, D, H, W).\n",
    "    masks : np.ndarray\n",
    "        Ground truth masks (1, D, H, W).\n",
    "    output_dir : str\n",
    "        Directory to save the animation.\n",
    "    mode : str\n",
    "        Mode of prediction (\"2D\" or \"3D\").\n",
    "    \"\"\"\n",
    "    print(\"üé• Creating animation...\")\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    camera = Camera(fig)\n",
    "\n",
    "    # Iterate over slices\n",
    "    for i in range(predictions.shape[1]):  # Iterate over depth (D)\n",
    "        pred_slice = predictions[0, i, :, :]  # Channel 0 for visualization\n",
    "        mask_slice = masks[0, i, :, :]\n",
    "\n",
    "        ax[0].imshow(pred_slice, cmap=\"viridis\")\n",
    "        ax[0].set_title(\"Prediction\")\n",
    "        ax[1].imshow(mask_slice, cmap=\"gray\")\n",
    "        ax[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "        camera.snap()\n",
    "\n",
    "    animation = camera.animate()\n",
    "    animation.save(os.path.join(output_dir, f\"{mode}_animation.mp4\"))\n",
    "    print(f\"‚úÖ Animation saved to {output_dir}\")\n",
    "\n",
    "def visualize_3d(predictions, output_dir):\n",
    "    \"\"\"\n",
    "    Creates a 3D visualization of the predicted volume.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : np.ndarray\n",
    "        Predicted volumes (C, D, H, W).\n",
    "    output_dir : str\n",
    "        Directory to save the 3D visualization.\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating 3D visualization...\")\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # Use the first channel for visualization\n",
    "    volume = predictions[0]  # Shape: (D, H, W)\n",
    "\n",
    "    # Create a 3D scatter plot\n",
    "    depth, height, width = volume.shape\n",
    "    x, y, z = np.meshgrid(\n",
    "        np.arange(width), np.arange(height), np.arange(depth)\n",
    "    )\n",
    "    ax.scatter(x, y, z, c=volume.flatten(), cmap=\"viridis\", alpha=0.5)\n",
    "\n",
    "    ax.set_title(\"3D Volume Visualization\")\n",
    "    plt.savefig(os.path.join(output_dir, \"3d_visualization.png\"))\n",
    "    print(f\"‚úÖ 3D visualization saved to {output_dir}\")\n",
    "\n",
    "def export_to_nifti(predictions, masks, output_dir, patient_id):\n",
    "    \"\"\"\n",
    "    Exports predictions and masks to NIfTI format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : np.ndarray\n",
    "        Predicted volumes (C, D, H, W).\n",
    "    masks : np.ndarray\n",
    "        Ground truth masks (1, D, H, W).\n",
    "    output_dir : str\n",
    "        Directory to save the NIfTI files.\n",
    "    patient_id : str\n",
    "        ID of the patient.\n",
    "    \"\"\"\n",
    "    print(\"üíæ Exporting to NIfTI...\")\n",
    "    pred_nifti = nib.Nifti1Image(predictions[0], affine=np.eye(4))\n",
    "    mask_nifti = nib.Nifti1Image(masks[0], affine=np.eye(4))\n",
    "\n",
    "    pred_path = os.path.join(output_dir, f\"{patient_id}_predictions.nii.gz\")\n",
    "    mask_path = os.path.join(output_dir, f\"{patient_id}_masks.nii.gz\")\n",
    "\n",
    "    nib.save(pred_nifti, pred_path)\n",
    "    nib.save(mask_nifti, mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e25df-aaaf-428a-a162-f5963c0d4f4e",
   "metadata": {},
   "source": [
    "# __Test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fb2c7c-c928-4c9f-b742-cc15a238a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('configs/experiments/deep_aug_5.yaml')\n",
    "model_path = 'experiments/deep_aug/deep_aug_20250415_215856/checkpoints/best_model_epoch60.pth'\n",
    "model = load_trained_model(config, model_path)\n",
    "config_device = config['training']['device']\n",
    "device = torch.device(config_device if torch.cuda.is_available() else \"cpu\")\n",
    "test_dir = 'data/processed/2d/train/'\n",
    "patient_ids = [\"rtum79\", \"rtum1\", \"rtum33\", \"rtum3\", \"rtum20\", \"rtum70\", \"rtum19\", \"rtum26\", \"rtum13\", \"rtum71\", \"rtum87\", \"rtum69\", \"rtum58\", \"rtum82\", \"rtum86\", \"rtum68\", \"rtum4\", \"rtum81\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ca31c2-bc96-4fae-aae5-26487e70b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicter = Predicter2D(model, config, device, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b972ad79-7293-4700-8ddb-d95aea7e7046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab64578bc8824b85aa97cd1cda4997d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: torch.Size([1, 5, 103, 256, 256])\n",
      "masks: torch.Size([1, 103, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "patient_id = 'rtum79'\n",
    "predictions, masks = predicter.predict_patient(patient_id)\n",
    "print(f\"predictions: {predictions.shape}\")\n",
    "print(f\"masks: {masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec78ac50-c8f1-4d6c-9672-d57a97b46523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2d_animation(predictions, ground_truth, patient_id, output_dir):\n",
    "    \"\"\"\n",
    "    Creates an animation comparing predictions and ground truth masks\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : torch.Tensor\n",
    "        Model predictions (B, C, D, H, W)\n",
    "    ground_truth : torch.Tensor\n",
    "        Ground truth masks (B, D, H, W)\n",
    "    patient_id : str\n",
    "        Patient ID\n",
    "    output_dir : str\n",
    "        Output directory\n",
    "    \"\"\"\n",
    "    # Create colormap for visualization\n",
    "    cmap = ListedColormap(['green', 'purple', 'red', 'blue'])\n",
    "    boundaries = [0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "    norm = BoundaryNorm(boundaries, cmap.N, clip=True)\n",
    "    \n",
    "    # Convert tensors to numpy\n",
    "    pred_numpy = torch.argmax(predictions[0], dim=0).cpu().numpy()\n",
    "    gt_numpy = ground_truth[0].cpu().numpy()\n",
    "    \n",
    "    # Extract dimensions\n",
    "    D, H, W = pred_numpy.shape\n",
    "    \n",
    "    # Create the figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Create black background canvases\n",
    "    gt_bg = np.zeros((H, W))\n",
    "    pred_bg = np.zeros((H, W))\n",
    "    \n",
    "    # Initialize the plots with the first slice\n",
    "    gt_img = axes[0].imshow(gt_bg, cmap='gray')\n",
    "    gt_overlay = axes[0].imshow(\n",
    "        np.where(gt_numpy[0] > 0, gt_numpy[0], np.nan), \n",
    "        cmap=cmap, norm=norm, alpha=0.8\n",
    "    )\n",
    "    axes[0].set_title('Ground Truth', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    pred_img = axes[1].imshow(pred_bg, cmap='gray')\n",
    "    pred_overlay = axes[1].imshow(\n",
    "        np.where(pred_numpy[0] > 0, pred_numpy[0], np.nan), \n",
    "        cmap=cmap, norm=norm, alpha=0.8\n",
    "    )\n",
    "    axes[1].set_title('Prediction', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Add slice information\n",
    "    title = fig.suptitle(f\"Patient {patient_id} - Slice 0\", fontsize=14)\n",
    "    \n",
    "    # Create update function for animation\n",
    "    def update(frame):\n",
    "        # Update ground truth\n",
    "        gt_overlay.set_array(np.where(gt_numpy[frame] > 0, gt_numpy[frame], np.nan))\n",
    "        \n",
    "        # Update prediction\n",
    "        pred_overlay.set_array(np.where(pred_numpy[frame] > 0, pred_numpy[frame], np.nan))\n",
    "        \n",
    "        # Update title\n",
    "        title.set_text(f\"Patient {patient_id} - Slice {frame}\")\n",
    "        \n",
    "        return [gt_img, gt_overlay, pred_img, pred_overlay, title]\n",
    "    \n",
    "    # Create animation\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update, frames=D, interval=200, blit=False\n",
    "    )\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save animation\n",
    "    output_path = os.path.join(output_dir, f\"patient_{patient_id}_2d_animation.gif\")\n",
    "    \n",
    "    # Use PillowWriter directly\n",
    "    writer = animation.PillowWriter(fps=5)\n",
    "    anim.save(output_path, writer=writer)\n",
    "    \n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "    \n",
    "    print(f\"2D animation saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360e848-4728-4f06-9255-f689c490d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tensors(predictions, ground_truth, argmax=True):\n",
    "    if predictions.dim() == 5:\n",
    "        predictions = predictions.squeeze(0)\n",
    "        if argmax:\n",
    "            predictions = torch.argmax(predictions, dim=0)\n",
    "        else:\n",
    "            predictions = predictions.squeeze(0)\n",
    "    if ground_truth.dim() == 4:\n",
    "        ground_truth = ground_truth.unsqueeze(0)\n",
    "\n",
    "    pred_np = predictions.cpu().numpy()\n",
    "    gt_np = ground_truth.cpu().numpy()\n",
    "\n",
    "    return pred_np, gt_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de262e38-0e4f-40d4-a739-72c83e27e58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes before\n",
      "pred: torch.Size([1, 5, 103, 256, 256])\n",
      "gt: torch.Size([1, 103, 256, 256])\n",
      "shapes after\n",
      "pred: (103, 256, 256)\n",
      "gt: (103, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'test_predicter'\n",
    "create_2d_animation(predictions, masks, 'rtum79_test', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b3d511-a67c-44b9-a037-f995974fa24e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_3d_visualization(predictions, ground_truth, patient_id, output_dir):\n",
    "    \"\"\"\n",
    "    Creates 3D visualizations of predictions and ground truth\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : torch.Tensor\n",
    "        Model predictions (B, C, D, H, W)\n",
    "    ground_truth : torch.Tensor\n",
    "        Ground truth masks (B, D, H, W)\n",
    "    patient_id : str\n",
    "        Patient ID\n",
    "    output_dir : str\n",
    "        Output directory\n",
    "    \"\"\"\n",
    "    # Convert tensors to numpy\n",
    "    pred_numpy = torch.argmax(predictions[0], dim=0).cpu().numpy()\n",
    "    gt_numpy = ground_truth[0].cpu().numpy()\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create figure for 3D visualization\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    # Ground truth subplot\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.set_title('Ground Truth 3D', fontsize=14)\n",
    "    \n",
    "    # Prediction subplot\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.set_title('Prediction 3D', fontsize=14)\n",
    "    \n",
    "    # Colors for different classes\n",
    "    colors = ['green', 'purple', 'red', 'blue']\n",
    "    class_names = ['Pancreas', 'Tumor', 'Arteries', 'Veins']\n",
    "    \n",
    "    # Plot each class\n",
    "    for class_idx in range(1, 5):\n",
    "        # Ground truth visualization\n",
    "        voxels_gt = gt_numpy == class_idx\n",
    "        if np.any(voxels_gt):\n",
    "            # Get mask points, ensuring there are some\n",
    "            z_gt, y_gt, x_gt = np.where(voxels_gt)\n",
    "            \n",
    "            # Determine appropriate sampling for smooth visualization\n",
    "            sample_size = min(10000, len(z_gt))  # Cap to 10k points for performance\n",
    "            if len(z_gt) > sample_size:\n",
    "                indices = np.random.choice(len(z_gt), sample_size, replace=False)\n",
    "                z_gt, y_gt, x_gt = z_gt[indices], y_gt[indices], x_gt[indices]\n",
    "            \n",
    "            # Plot points\n",
    "            ax1.scatter(x_gt, y_gt, z_gt, c=colors[class_idx-1], alpha=0.7, s=5, \n",
    "                       label=f\"{class_names[class_idx-1]}\")\n",
    "        \n",
    "        # Prediction visualization\n",
    "        voxels_pred = pred_numpy == class_idx\n",
    "        if np.any(voxels_pred):\n",
    "            # Get mask points, ensuring there are some\n",
    "            z_pred, y_pred, x_pred = np.where(voxels_pred)\n",
    "            \n",
    "            # Determine appropriate sampling for smooth visualization\n",
    "            sample_size = min(10000, len(z_pred))  # Cap to 10k points for performance\n",
    "            if len(z_pred) > sample_size:\n",
    "                indices = np.random.choice(len(z_pred), sample_size, replace=False)\n",
    "                z_pred, y_pred, x_pred = z_pred[indices], y_pred[indices], x_pred[indices]\n",
    "                \n",
    "            # Plot points\n",
    "            ax2.scatter(x_pred, y_pred, z_pred, c=colors[class_idx-1], alpha=0.7, s=5,\n",
    "                      label=f\"{class_names[class_idx-1]}\")\n",
    "    \n",
    "    # Set labels and legends\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.legend(loc='upper right')\n",
    "        \n",
    "        # Ensure equal aspect ratio for better visualization\n",
    "        max_range = np.array([\n",
    "            ax.get_xlim()[1] - ax.get_xlim()[0],\n",
    "            ax.get_ylim()[1] - ax.get_ylim()[0],\n",
    "            ax.get_zlim()[1] - ax.get_zlim()[0]\n",
    "        ]).max() / 2.0\n",
    "        \n",
    "        mid_x = (ax.get_xlim()[1] + ax.get_xlim()[0]) / 2\n",
    "        mid_y = (ax.get_ylim()[1] + ax.get_ylim()[0]) / 2\n",
    "        mid_z = (ax.get_zlim()[1] + ax.get_zlim()[0]) / 2\n",
    "        \n",
    "        ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "        ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "        ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "        \n",
    "    plt.suptitle(f\"Patient {patient_id} - 3D Visualization\", fontsize=16)\n",
    "    \n",
    "    # Save figure\n",
    "    output_path = os.path.join(output_dir, f\"patient_{patient_id}_3d_visualization.png\")\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "    \n",
    "    print(f\"3D visualization saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e10ad9c1-780f-4b1c-9fa1-04a942e0302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D visualization saved to test_predicter\\patient_rtum79_3d_visualization.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test_predicter\\\\patient_rtum79_3d_visualization.png'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_3d_visualization(predictions, masks, patient_id, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5033de8-0ade-4b7c-8bf2-96b76568eb0d",
   "metadata": {},
   "source": [
    "# __Test with volume__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "549164aa-0f9a-4140-942c-83c54af101d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_2d_animation(predictions, ground_truth, patient_id, output_dir, volume=None):\n",
    "    \"\"\"\n",
    "    Creates an animation comparing predictions and ground truth masks,\n",
    "    optionally overlaid on the CT volume, and saves it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : torch.Tensor\n",
    "        Model predictions (B, C, D, H, W)\n",
    "    ground_truth : torch.Tensor\n",
    "        Ground truth masks (B, D, H, W)\n",
    "    patient_id : str\n",
    "        Patient ID\n",
    "    output_dir : str\n",
    "        Output directory\n",
    "    volume : torch.Tensor, optional\n",
    "        CT volume (B, D, H, W). If provided, it will be used as grayscale background.\n",
    "    \"\"\"\n",
    "    # Define colormap\n",
    "    cmap = ListedColormap(['green', 'purple', 'red', 'blue'])\n",
    "    norm = BoundaryNorm([0.5, 1.5, 2.5, 3.5, 4.5], cmap.N, clip=True)\n",
    "\n",
    "    # Extract first batch\n",
    "    pred_np = torch.argmax(predictions[0], dim=0).cpu().numpy()      # (D, H, W)\n",
    "    gt_np = ground_truth[0].cpu().numpy()                            # (D, H, W)\n",
    "    volume_np = volume[0][0].cpu().numpy() if volume is not None else None  # (D, H, W) or None\n",
    "\n",
    "    D, H, W = pred_np.shape\n",
    "\n",
    "    # Setup figure\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Use CT volume or black background\n",
    "    background = volume_np[0] if volume_np is not None else np.zeros((H, W))\n",
    "    \n",
    "    # Initial slice\n",
    "    gt_img = axes[0].imshow(background, cmap='gray')\n",
    "    gt_overlay = axes[0].imshow(np.where(gt_np[0] > 0, gt_np[0], np.nan), cmap=cmap, norm=norm, alpha=0.5)\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    pred_img = axes[1].imshow(background, cmap='gray')\n",
    "    pred_overlay = axes[1].imshow(np.where(pred_np[0] > 0, pred_np[0], np.nan), cmap=cmap, norm=norm, alpha=0.5)\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    title = fig.suptitle(f\"Patient {patient_id} - Slice 0\", fontsize=14)\n",
    "\n",
    "    def update(frame):\n",
    "        bg = volume_np[frame] if volume_np is not None else np.zeros((H, W))\n",
    "        gt_img.set_array(bg)\n",
    "        pred_img.set_array(bg)\n",
    "\n",
    "        gt_overlay.set_array(np.where(gt_np[frame] > 0, gt_np[frame], np.nan))\n",
    "        pred_overlay.set_array(np.where(pred_np[frame] > 0, pred_np[frame], np.nan))\n",
    "\n",
    "        title.set_text(f\"Patient {patient_id} - Slice {frame}\")\n",
    "        return [gt_img, gt_overlay, pred_img, pred_overlay, title]\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=D, interval=200, blit=False)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save animation\n",
    "    output_path = os.path.join(output_dir, f\"patient_{patient_id}_2d_animation.gif\")\n",
    "    \n",
    "    # Use PillowWriter directly\n",
    "    writer = animation.PillowWriter(fps=5)\n",
    "    anim.save(output_path, writer=writer)\n",
    "    \n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "    \n",
    "    print(f\"2D animation saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e480a5f3-3174-4402-8945-aa3dc1b3b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset2d import PancreasDataset2D\n",
    "from src.training.setup import get_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0922c3-8261-42b4-a9da-279e4a87bd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading dataset... 8834 slices found.\n"
     ]
    }
   ],
   "source": [
    "ds = PancreasDataset2D(\n",
    "    data_dir='data/processed/2d/train/',\n",
    "    transform=get_transforms(config)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1df206-d5e9-41fd-b4b0-b205717dc693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume: torch.Size([1, 1, 103, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "volume, _ = ds.get_patient_volume(patient_id)\n",
    "print(f\"volume: {volume.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a089391-fd14-495d-bd12-d34deae7c69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D animation saved to test_predicter\\patient_rtum79_vol_2d_animation.gif\n"
     ]
    }
   ],
   "source": [
    "output_path = create_2d_animation(predictions, masks, 'rtum79_vol', output_dir='test_predicter', volume=volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115eb209-9865-4ff1-8d8a-dd139eb38ced",
   "metadata": {},
   "source": [
    "# __Test legend__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd95ef3a-9c20-4b5a-871e-bb8ca75a8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "LABEL_COLORS = {\n",
    "    1: (\"green\", \"Class 1\"),\n",
    "    2: (\"purple\", \"Class 2\"),\n",
    "    3: (\"red\", \"Class 3\"),\n",
    "    4: (\"blue\", \"Class 4\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00a16f3b-8eec-4e44-a56a-df75a3845f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Define colormap and class info\n",
    "LABEL_COLORS = {\n",
    "    1: (\"green\", \"Class 1\"),\n",
    "    2: (\"purple\", \"Class 2\"),\n",
    "    3: (\"red\", \"Class 3\"),\n",
    "    4: (\"blue\", \"Class 4\"),\n",
    "}\n",
    "CMAP = ListedColormap([v[0] for v in LABEL_COLORS.values()])\n",
    "BOUNDARIES = [0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "NORM = BoundaryNorm(BOUNDARIES, CMAP.N, clip=True)\n",
    "\n",
    "def create_2d_animation(predictions, ground_truth, patient_id, output_dir, volume=None, alpha=0.6, filename=None):\n",
    "    pred_np = torch.argmax(predictions[0], dim=0).cpu().numpy()\n",
    "    gt_np = ground_truth[0].cpu().numpy()\n",
    "    volume_np = volume[0].cpu().numpy() if volume is not None else None\n",
    "    D, H, W = pred_np.shape\n",
    "\n",
    "    # Setup figure layout\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    gs = gridspec.GridSpec(2, 2, height_ratios=[6, 0.3])\n",
    "\n",
    "    ax_gt = fig.add_subplot(gs[0, 0])\n",
    "    ax_pred = fig.add_subplot(gs[0, 1])\n",
    "    ax_legend = fig.add_subplot(gs[1, :])  # Span both columns\n",
    "\n",
    "    # Hide legend axes border\n",
    "    ax_legend.axis('off')\n",
    "\n",
    "    # Build the legend as patches\n",
    "    legend_patches = [\n",
    "        mpatches.Patch(color=color, label=label) for color, label in LABEL_COLORS.values()\n",
    "    ]\n",
    "    ax_legend.legend(handles=legend_patches, loc='center', ncol=len(LABEL_COLORS), fontsize=10)\n",
    "\n",
    "    # Background and initial images\n",
    "    bg = volume_np[0] if volume_np is not None else np.zeros((H, W))\n",
    "    gt_img = ax_gt.imshow(bg, cmap='gray')\n",
    "    gt_overlay = ax_gt.imshow(np.where(gt_np[0] > 0, gt_np[0], np.nan), cmap=CMAP, norm=NORM, alpha=alpha)\n",
    "    ax_gt.set_title(\"Ground Truth\", fontsize=14)\n",
    "    ax_gt.axis(\"off\")\n",
    "\n",
    "    pred_img = ax_pred.imshow(bg, cmap='gray')\n",
    "    pred_overlay = ax_pred.imshow(np.where(pred_np[0] > 0, pred_np[0], np.nan), cmap=CMAP, norm=NORM, alpha=alpha)\n",
    "    ax_pred.set_title(\"Prediction\", fontsize=14)\n",
    "    ax_pred.axis(\"off\")\n",
    "\n",
    "    title = fig.suptitle(f\"Patient {patient_id} - Slice 0\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    def update(frame):\n",
    "        bg = volume_np[frame] if volume_np is not None else np.zeros((H, W))\n",
    "        gt_img.set_array(bg)\n",
    "        pred_img.set_array(bg)\n",
    "        gt_overlay.set_array(np.where(gt_np[frame] > 0, gt_np[frame], np.nan))\n",
    "        pred_overlay.set_array(np.where(pred_np[frame] > 0, pred_np[frame], np.nan))\n",
    "        title.set_text(f\"Patient {patient_id} - Slice {frame}\")\n",
    "        return [gt_img, gt_overlay, pred_img, pred_overlay, title]\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=D, interval=200, blit=False)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if filename is None:\n",
    "        filename = f\"patient_{patient_id}_2d_animation.gif\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    writer = animation.PillowWriter(fps=5)\n",
    "    anim.save(output_path, writer=writer)\n",
    "\n",
    "    plt.close(fig)\n",
    "    print(f\"2D animation saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb17d6d6-3bbf-41e9-831c-b9485f795010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D animation saved to test_predicter\\test_sin_volumen.gif\n"
     ]
    }
   ],
   "source": [
    "output_path = create_2d_animation(\n",
    "        predictions,\n",
    "        masks,\n",
    "        'rtum79',\n",
    "        output_dir='test_predicter',\n",
    "        volume=None,\n",
    "        filename='test_sin_volumen.gif',\n",
    "        alpha=0.8\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b715ca7-eb5b-4ca4-a2b1-332a2ea9eaaf",
   "metadata": {},
   "source": [
    "# __Another__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c35a871-3f5e-430c-858b-714652972ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Define colormap and class info\n",
    "CLASS_NAMES = {\n",
    "    1: 'Pancreas',\n",
    "    2: 'Tumor',\n",
    "    3: 'Arteries',\n",
    "    4: 'Veins'\n",
    "}\n",
    "CMAP = ListedColormap([v[0] for v in LABEL_COLORS.values()])\n",
    "BOUNDARIES = [0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "NORM = BoundaryNorm(BOUNDARIES, CMAP.N, clip=True)\n",
    "\n",
    "def create_2d_animation(predictions, ground_truth, patient_id, output_dir, volume=None, alpha=0.6, filename=None):\n",
    "    pred_np = torch.argmax(predictions[0], dim=0).cpu().numpy()\n",
    "    gt_np = ground_truth[0].cpu().numpy()\n",
    "    volume_np = volume[0].cpu().numpy() if volume is not None else None\n",
    "    D, H, W = pred_np.shape\n",
    "\n",
    "    class_names = CLASS_NAMES\n",
    "\n",
    "    # Setup figure - ajustado para dejar espacio para la leyenda\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6), dpi=150)\n",
    "    \n",
    "    # Use CT volume or black background\n",
    "    background = volume_np[0] if volume_np is not None else np.zeros((H, W))\n",
    "    \n",
    "    # Initial slice\n",
    "    gt_img = axes[0].imshow(background, cmap='gray')\n",
    "    gt_overlay = axes[0].imshow(\n",
    "        np.where(gt_np[0] > 0, gt_np[0], np.nan),\n",
    "        cmap=CMAP,\n",
    "        norm=NORM,\n",
    "        alpha=alpha\n",
    "    )\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    pred_img = axes[1].imshow(background, cmap='gray')\n",
    "    pred_overlay = axes[1].imshow(\n",
    "        np.where(pred_np[0] > 0, pred_np[0], np.nan),\n",
    "        cmap=CMAP,\n",
    "        norm=NORM,\n",
    "        alpha=alpha\n",
    "    )\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    title = fig.suptitle(f\"Patient {patient_id} - Slice 0\", fontsize=14)\n",
    "\n",
    "    # Crear parches de colores para la leyenda\n",
    "    legend_elements = []\n",
    "    for class_idx, class_name in class_names.items():\n",
    "        # Obtener el color asignado para esta clase desde el mapa de colores\n",
    "        rgba = CMAP(NORM(class_idx))\n",
    "        # Crear un parche de color\n",
    "        patch = mpatches.Patch(color=rgba, label=class_name)\n",
    "        legend_elements.append(patch)\n",
    "\n",
    "    # Agregar la leyenda a la figura\n",
    "    fig.legend(\n",
    "        handles=legend_elements,\n",
    "        loc='lower center',\n",
    "        ncol=min(len(class_names), 4),  # Distribuir en filas si hay muchas clases\n",
    "        bbox_to_anchor=(0.5, 0.02),\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True\n",
    "    )\n",
    "\n",
    "    # Ajustar la disposici√≥n para dejar espacio para la leyenda\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
    "\n",
    "    def update(frame):\n",
    "        bg = volume_np[frame] if volume_np is not None else np.zeros((H, W))\n",
    "        gt_img.set_array(bg)\n",
    "        pred_img.set_array(bg)\n",
    "\n",
    "        gt_overlay.set_array(np.where(gt_np[frame] > 0, gt_np[frame], np.nan))\n",
    "        pred_overlay.set_array(np.where(pred_np[frame] > 0, pred_np[frame], np.nan))\n",
    "\n",
    "        title.set_text(f\"Patient {patient_id} - Slice {frame}\")\n",
    "        return [gt_img, gt_overlay, pred_img, pred_overlay, title]\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=D, interval=200, blit=False)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save animation\n",
    "    if filename is None:\n",
    "        filename = f\"patient_{patient_id}_2d_animation.gif\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # Use PillowWriter directly\n",
    "    writer = animation.PillowWriter(fps=5)\n",
    "    anim.save(output_path, writer=writer)\n",
    "    \n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "    \n",
    "    print(f\"2D animation saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cbc0ff72-892f-4172-a323-72b8b06e2157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D animation saved to test_predicter\\test_legend.gif\n"
     ]
    }
   ],
   "source": [
    "output_path = create_2d_animation(\n",
    "        predictions,\n",
    "        masks,\n",
    "        'rtum79',\n",
    "        output_dir='test_predicter',\n",
    "        volume=None,\n",
    "        filename='test_legend.gif',\n",
    "        alpha=0.8\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
