{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62116a0d-79af-4e35-b513-80fd122f1357",
   "metadata": {},
   "source": [
    "# Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7477aaf3-030c-4476-a7c5-4779c07834b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4166ac-30c2-4340-b2c8-9dc7a563e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Usuario\\\\TFG\\\\digipanca\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e8822c-64a1-4e5d-8723-df4a4c0ef262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from src.utils.config import load_config\n",
    "from src.data.dataset2d import PancreasDataset2D\n",
    "from src.data.dataset3d import PancreasDataset3D\n",
    "from src.data.transforms import build_transforms_from_config\n",
    "from src.data.augmentation import build_augmentations_from_config\n",
    "from src.training.setup.dataset_factory import get_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72ed02-8408-4f3a-9bf5-9695175521df",
   "metadata": {},
   "source": [
    "# __PancreasDataset2D__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c824ff0e-edca-4d8b-8865-ad52f043d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ApplyWindow': {'window_level': 50, 'window_width': 400}}, {'Normalize': {}}, {'CropBorders': {'crop_size': 120}}, {'Resize': {'size': [8, 8]}}, {'ToTensor': {}}]\n",
      "[{'Affine': {'scale': [0.95, 1.05], 'translate_percent': [0.02, 0.02], 'rotate': [-10, 10], 'p': 0.2}}, {'RandomBrightnessContrast': {'brightness_limit': 0.2, 'contrast_limit': 0.2, 'p': 0.3}}, {'GaussianBlur': {'blur_limit': [3, 7], 'p': 0.3}}, {'ElasticTransform': {'alpha': 1.0, 'sigma': 50, 'p': 0.3}}, {'GridDistortion': {'num_steps': 5, 'distort_limit': 0.3, 'p': 0.3}}, {'ToTensorV2': {}}]\n"
     ]
    }
   ],
   "source": [
    "transforms_config = load_config('configs/experiments/one_deep.yaml').get('transforms', None)\n",
    "print(transforms_config)\n",
    "aug_config = load_config('configs/experiments/one_deep.yaml').get('augmentations', None)\n",
    "print(aug_config)\n",
    "transforms = build_transforms_from_config(transforms_config)\n",
    "augment = build_augmentations_from_config(aug_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a745338f-570f-4684-874e-80b0f0f02e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config('configs/experiments/deep_aug_5.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3670b4-8060-4761-b123-bd1851675ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loading dataset... 7004 slices found.\n",
      "ðŸ“Š Loading dataset... 1830 slices found.\n"
     ]
    }
   ],
   "source": [
    "train_2d = get_dataset(\n",
    "    config=config,\n",
    "    split_type=\"train\",\n",
    "    transform=transforms,\n",
    "    augment=augment\n",
    ")\n",
    "val_2d = get_dataset(\n",
    "    config=config,\n",
    "    split_type=\"val\",\n",
    "    transform=transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f159a8a-6f5c-4e43-bdc1-5d19d5946f72",
   "metadata": {},
   "source": [
    "## __KFold test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca88a9d-8a7f-4de1-ae50-3b26ad8067c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "ðŸ“Š Loading dataset... 7004 slices found.\n",
      "ðŸ“Š Loading dataset... 1830 slices found.\n",
      "Fold 2/5\n",
      "ðŸ“Š Loading dataset... 7080 slices found.\n",
      "ðŸ“Š Loading dataset... 1754 slices found.\n",
      "Fold 3/5\n",
      "ðŸ“Š Loading dataset... 7076 slices found.\n",
      "ðŸ“Š Loading dataset... 1758 slices found.\n",
      "Fold 4/5\n",
      "ðŸ“Š Loading dataset... 6991 slices found.\n",
      "ðŸ“Š Loading dataset... 1843 slices found.\n",
      "Fold 5/5\n",
      "ðŸ“Š Loading dataset... 7185 slices found.\n",
      "ðŸ“Š Loading dataset... 1649 slices found.\n"
     ]
    }
   ],
   "source": [
    "config = load_config('configs/experiments/test_kfcv.yaml')\n",
    "n_splits = config['training']['n_splits']\n",
    "\n",
    "for i in range(n_splits):\n",
    "    print(f\"Fold {i+1}/{n_splits}\")\n",
    "    train_2d = get_dataset(\n",
    "        config=config,\n",
    "        split_type=\"train\",\n",
    "        fold_idx=i,\n",
    "        transform=transforms,\n",
    "        augment=augment\n",
    "    )\n",
    "    val_2d = get_dataset(\n",
    "        config=config,\n",
    "        split_type=\"val\",\n",
    "        fold_idx=i,\n",
    "        transform=transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1a8ae-426d-4bc9-8840-cdf5b82c0cea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# __Old method__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd897299-7df7-48ee-ad8d-c64ba20628b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_old(\n",
    "    config,\n",
    "    split_type='train',\n",
    "    data_folder='train',\n",
    "    fold_idx=None,\n",
    "    transform=None,\n",
    "    augment=None\n",
    "):\n",
    "    \"\"\"Initialize dataset based on configuration.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict\n",
    "        Configuration dictionary.\n",
    "    split_type : str, optional\n",
    "        Split type (train/val/test), by default 'train'.\n",
    "    data_folder : str, optional\n",
    "        Data folder name, by default 'train'.\n",
    "    fold_idx : int, optional\n",
    "        Fold index for cross-validation, by default None.\n",
    "    transform : callable, optional\n",
    "        Transform function, by default None.\n",
    "    augment : callable, optional\n",
    "        Augmentation function, by default None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PancreasDataset or PancreasDataset3D\n",
    "        Pancreas dataset object.\n",
    "    \"\"\"\n",
    "    # Check that there is not augmentation for validation/test sets\n",
    "    if split_type != 'train' and augment is not None:\n",
    "        raise ValueError(\"Augmentations are only allowed for the training set.\")\n",
    "    # Ensure split type is valid\n",
    "    if split_type not in ['train', 'val', 'test']:\n",
    "        raise ValueError(f\"Invalid split type: {split_type}\")\n",
    "    \n",
    "    # Check if cross-validation is enabled\n",
    "    if fold_idx is not None:\n",
    "        with open(config['data']['split_file'], 'r') as f:\n",
    "            folds = json.load(f)\n",
    "        patient_ids = folds[fold_idx][split_type]\n",
    "    else:\n",
    "        with open(config['data']['split_file'], 'r') as f:\n",
    "            folds = json.load(f)\n",
    "        patient_ids = folds[split_type]\n",
    "\n",
    "    # data_folder is the folder name in the processed directory\n",
    "    # e.g. 'train' or 'test'\n",
    "    data_dir = os.path.join(config['data']['processed_dir'], data_folder)\n",
    "\n",
    "    if config['data'].get('is_3d', False):\n",
    "        return PancreasDataset3D(\n",
    "            data_dir=data_dir,\n",
    "            transform=transform,\n",
    "            load_into_memory=config['data'].get('load_into_memory', False),\n",
    "            patient_ids=patient_ids\n",
    "        )\n",
    "    else:\n",
    "        return PancreasDataset2D(\n",
    "            data_dir=data_dir,\n",
    "            transform=transform,\n",
    "            augment=augment,\n",
    "            load_into_memory=config['data'].get('load_into_memory', False),\n",
    "            patient_ids=patient_ids\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94448ff-5151-4303-8832-f95439ff940e",
   "metadata": {},
   "source": [
    "# __New method__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2cc5d54-6cad-471e-b84a-4ac2d2e6bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "    config,\n",
    "    data,\n",
    "    split_type='train',\n",
    "    data_folder='train',\n",
    "    transform=None,\n",
    "    augment=None\n",
    "):\n",
    "    \"\"\"Initialize dataset based on configuration.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict\n",
    "        Configuration dictionary.\n",
    "    split_type : str, optional\n",
    "        Split type (train/val/test), by default 'train'.\n",
    "    data_folder : str, optional\n",
    "        Data folder name, by default 'train'.\n",
    "    fold_idx : int, optional\n",
    "        Fold index for cross-validation, by default None.\n",
    "    transform : callable, optional\n",
    "        Transform function, by default None.\n",
    "    augment : callable, optional\n",
    "        Augmentation function, by default None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PancreasDataset or PancreasDataset3D\n",
    "        Pancreas dataset object.\n",
    "    \"\"\"\n",
    "    # Check that there is not augmentation for validation/test sets\n",
    "    if split_type != 'train' and augment is not None:\n",
    "        raise ValueError(\"Augmentations are only allowed for the training set.\")\n",
    "    # Ensure split type is valid\n",
    "    if split_type not in ['train', 'val', 'test']:\n",
    "        raise ValueError(f\"Invalid split type: {split_type}\")\n",
    "    \n",
    "    # Check if cross-validation is enabled\n",
    "    patient_ids = data[split_type]\n",
    "\n",
    "    print(patient_ids)\n",
    "\n",
    "    # data_folder is the folder name in the processed directory\n",
    "    # e.g. 'train' or 'test'\n",
    "    data_dir = os.path.join(config['data']['processed_dir'], data_folder)\n",
    "\n",
    "    if config['data'].get('is_3d', False):\n",
    "        return PancreasDataset3D(\n",
    "            data_dir=data_dir,\n",
    "            transform=transform,\n",
    "            load_into_memory=config['data'].get('load_into_memory', False),\n",
    "            patient_ids=patient_ids\n",
    "        )\n",
    "    else:\n",
    "        return PancreasDataset2D(\n",
    "            data_dir=data_dir,\n",
    "            transform=transform,\n",
    "            augment=augment,\n",
    "            load_into_memory=config['data'].get('load_into_memory', False),\n",
    "            patient_ids=patient_ids\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e7999-d4fe-4ea9-9c9d-e73b3b705215",
   "metadata": {},
   "source": [
    "## __Test new method__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7e06911-45d5-48e6-8d37-d61a89156579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'train': ['rtum6', 'rtum76', 'rtum2', 'rtum37', 'rtum46', 'rtum35', 'rtum18', 'rtum7', 'rtum14', 'rtum45', 'rtum38', 'rtum41', 'rtum50', 'rtum5', 'rtum24', 'rtum48', 'rtum40', 'rtum16', 'rtum54', 'rtum65', 'rtum27', 'rtum75', 'rtum32', 'rtum52', 'rtum21', 'rtum31', 'rtum12', 'rtum25', 'rtum44', 'rtum17', 'rtum72', 'rtum15', 'rtum60', 'rtum42', 'rtum80', 'rtum9', 'rtum59', 'rtum49', 'rtum55', 'rtum51', 'rtum88', 'rtum23', 'rtum73', 'rtum34', 'rtum47', 'rtum66', 'rtum62', 'rtum53', 'rtum8', 'rtum61', 'rtum39', 'rtum85', 'rtum63', 'rtum67', 'rtum78', 'rtum43', 'rtum36', 'rtum10', 'rtum57', 'rtum29', 'rtum11', 'rtum30', 'rtum83', 'rtum77', 'rtum84', 'rtum28', 'rtum64', 'rtum74', 'rtum22', 'rtum56'], 'val': ['rtum79', 'rtum1', 'rtum33', 'rtum3', 'rtum20', 'rtum70', 'rtum19', 'rtum26', 'rtum13', 'rtum71', 'rtum87', 'rtum69', 'rtum58', 'rtum82', 'rtum86', 'rtum68', 'rtum4', 'rtum81'], 'test': []}\n",
      "\n",
      "=================================================================\n",
      "\n",
      "<class 'list'>\n",
      "{'train': ['rtum10', 'rtum11', 'rtum12', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum2', 'rtum21', 'rtum22', 'rtum23', 'rtum24', 'rtum25', 'rtum27', 'rtum28', 'rtum29', 'rtum30', 'rtum31', 'rtum32', 'rtum34', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum39', 'rtum40', 'rtum41', 'rtum42', 'rtum43', 'rtum44', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum56', 'rtum57', 'rtum59', 'rtum6', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum65', 'rtum66', 'rtum67', 'rtum7', 'rtum72', 'rtum73', 'rtum74', 'rtum75', 'rtum76', 'rtum77', 'rtum78', 'rtum8', 'rtum80', 'rtum83', 'rtum84', 'rtum85', 'rtum88', 'rtum9'], 'val': ['rtum1', 'rtum13', 'rtum19', 'rtum20', 'rtum26', 'rtum3', 'rtum33', 'rtum4', 'rtum58', 'rtum68', 'rtum69', 'rtum70', 'rtum71', 'rtum79', 'rtum81', 'rtum82', 'rtum86', 'rtum87']}\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum12', 'rtum13', 'rtum15', 'rtum17', 'rtum19', 'rtum20', 'rtum21', 'rtum22', 'rtum23', 'rtum25', 'rtum26', 'rtum27', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum31', 'rtum32', 'rtum33', 'rtum34', 'rtum36', 'rtum39', 'rtum4', 'rtum42', 'rtum43', 'rtum44', 'rtum47', 'rtum49', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum56', 'rtum57', 'rtum58', 'rtum59', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum65', 'rtum66', 'rtum67', 'rtum68', 'rtum69', 'rtum70', 'rtum71', 'rtum72', 'rtum73', 'rtum74', 'rtum75', 'rtum77', 'rtum78', 'rtum79', 'rtum8', 'rtum80', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum85', 'rtum86', 'rtum87', 'rtum88', 'rtum9'], 'val': ['rtum14', 'rtum16', 'rtum18', 'rtum2', 'rtum24', 'rtum35', 'rtum37', 'rtum38', 'rtum40', 'rtum41', 'rtum45', 'rtum46', 'rtum48', 'rtum5', 'rtum50', 'rtum6', 'rtum7', 'rtum76']}\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum13', 'rtum14', 'rtum16', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum22', 'rtum23', 'rtum24', 'rtum26', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum33', 'rtum34', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum39', 'rtum4', 'rtum40', 'rtum41', 'rtum43', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum53', 'rtum55', 'rtum56', 'rtum57', 'rtum58', 'rtum59', 'rtum6', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum66', 'rtum67', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum73', 'rtum74', 'rtum76', 'rtum77', 'rtum78', 'rtum79', 'rtum8', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum85', 'rtum86', 'rtum87', 'rtum88'], 'val': ['rtum12', 'rtum15', 'rtum17', 'rtum21', 'rtum25', 'rtum27', 'rtum31', 'rtum32', 'rtum42', 'rtum44', 'rtum52', 'rtum54', 'rtum60', 'rtum65', 'rtum72', 'rtum75', 'rtum80', 'rtum9']}\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum12', 'rtum13', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum21', 'rtum22', 'rtum24', 'rtum25', 'rtum26', 'rtum27', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum31', 'rtum32', 'rtum33', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum4', 'rtum40', 'rtum41', 'rtum42', 'rtum43', 'rtum44', 'rtum45', 'rtum46', 'rtum48', 'rtum5', 'rtum50', 'rtum52', 'rtum54', 'rtum56', 'rtum57', 'rtum58', 'rtum6', 'rtum60', 'rtum64', 'rtum65', 'rtum67', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum72', 'rtum74', 'rtum75', 'rtum76', 'rtum77', 'rtum78', 'rtum79', 'rtum80', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum86', 'rtum87', 'rtum9'], 'val': ['rtum23', 'rtum34', 'rtum39', 'rtum47', 'rtum49', 'rtum51', 'rtum53', 'rtum55', 'rtum59', 'rtum61', 'rtum62', 'rtum63', 'rtum66', 'rtum73', 'rtum8', 'rtum85', 'rtum88']}\n",
      "{'train': ['rtum1', 'rtum12', 'rtum13', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum21', 'rtum23', 'rtum24', 'rtum25', 'rtum26', 'rtum27', 'rtum3', 'rtum31', 'rtum32', 'rtum33', 'rtum34', 'rtum35', 'rtum37', 'rtum38', 'rtum39', 'rtum4', 'rtum40', 'rtum41', 'rtum42', 'rtum44', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum58', 'rtum59', 'rtum6', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum65', 'rtum66', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum72', 'rtum73', 'rtum75', 'rtum76', 'rtum79', 'rtum8', 'rtum80', 'rtum81', 'rtum82', 'rtum85', 'rtum86', 'rtum87', 'rtum88', 'rtum9'], 'val': ['rtum10', 'rtum11', 'rtum22', 'rtum28', 'rtum29', 'rtum30', 'rtum36', 'rtum43', 'rtum56', 'rtum57', 'rtum64', 'rtum67', 'rtum74', 'rtum77', 'rtum78', 'rtum83', 'rtum84']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "config = load_config('configs/experiments/deep_aug_5.yaml')\n",
    "with open(config['data']['split_file'], 'r') as f:\n",
    "    split_data = json.load(f)\n",
    "    print(type(split_data))\n",
    "split_data = [split_data]\n",
    "for data in split_data:\n",
    "    print(data)\n",
    "\n",
    "print()\n",
    "print('='*65)\n",
    "print()\n",
    "\n",
    "config = load_config('configs/experiments/test_kfcv.yaml')\n",
    "with open(config['data']['split_file'], 'r') as f:\n",
    "    split_data = json.load(f)\n",
    "    print(type(split_data))\n",
    "\n",
    "for data in split_data:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0def45ce-1fb8-47bc-b9d1-58536ca4d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.split_manager import SplitManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfdd465f-f2a9-47bd-b0fd-cd21a1db5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['rtum6', 'rtum76', 'rtum2', 'rtum37', 'rtum46', 'rtum35', 'rtum18', 'rtum7', 'rtum14', 'rtum45', 'rtum38', 'rtum41', 'rtum50', 'rtum5', 'rtum24', 'rtum48', 'rtum40', 'rtum16', 'rtum54', 'rtum65', 'rtum27', 'rtum75', 'rtum32', 'rtum52', 'rtum21', 'rtum31', 'rtum12', 'rtum25', 'rtum44', 'rtum17', 'rtum72', 'rtum15', 'rtum60', 'rtum42', 'rtum80', 'rtum9', 'rtum59', 'rtum49', 'rtum55', 'rtum51', 'rtum88', 'rtum23', 'rtum73', 'rtum34', 'rtum47', 'rtum66', 'rtum62', 'rtum53', 'rtum8', 'rtum61', 'rtum39', 'rtum85', 'rtum63', 'rtum67', 'rtum78', 'rtum43', 'rtum36', 'rtum10', 'rtum57', 'rtum29', 'rtum11', 'rtum30', 'rtum83', 'rtum77', 'rtum84', 'rtum28', 'rtum64', 'rtum74', 'rtum22', 'rtum56'], 'val': ['rtum79', 'rtum1', 'rtum33', 'rtum3', 'rtum20', 'rtum70', 'rtum19', 'rtum26', 'rtum13', 'rtum71', 'rtum87', 'rtum69', 'rtum58', 'rtum82', 'rtum86', 'rtum68', 'rtum4', 'rtum81'], 'test': []}\n",
      "\n",
      "=================================================================\n",
      "\n",
      "{'train': ['rtum10', 'rtum11', 'rtum12', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum2', 'rtum21', 'rtum22', 'rtum23', 'rtum24', 'rtum25', 'rtum27', 'rtum28', 'rtum29', 'rtum30', 'rtum31', 'rtum32', 'rtum34', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum39', 'rtum40', 'rtum41', 'rtum42', 'rtum43', 'rtum44', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum56', 'rtum57', 'rtum59', 'rtum6', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum65', 'rtum66', 'rtum67', 'rtum7', 'rtum72', 'rtum73', 'rtum74', 'rtum75', 'rtum76', 'rtum77', 'rtum78', 'rtum8', 'rtum80', 'rtum83', 'rtum84', 'rtum85', 'rtum88', 'rtum9'], 'val': ['rtum1', 'rtum13', 'rtum19', 'rtum20', 'rtum26', 'rtum3', 'rtum33', 'rtum4', 'rtum58', 'rtum68', 'rtum69', 'rtum70', 'rtum71', 'rtum79', 'rtum81', 'rtum82', 'rtum86', 'rtum87']}\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum12', 'rtum13', 'rtum15', 'rtum17', 'rtum19', 'rtum20', 'rtum21', 'rtum22', 'rtum23', 'rtum25', 'rtum26', 'rtum27', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum31', 'rtum32', 'rtum33', 'rtum34', 'rtum36', 'rtum39', 'rtum4', 'rtum42', 'rtum43', 'rtum44', 'rtum47', 'rtum49', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum56', 'rtum57', 'rtum58', 'rtum59', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum65', 'rtum66', 'rtum67', 'rtum68', 'rtum69', 'rtum70', 'rtum71', 'rtum72', 'rtum73', 'rtum74', 'rtum75', 'rtum77', 'rtum78', 'rtum79', 'rtum8', 'rtum80', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum85', 'rtum86', 'rtum87', 'rtum88', 'rtum9'], 'val': ['rtum14', 'rtum16', 'rtum18', 'rtum2', 'rtum24', 'rtum35', 'rtum37', 'rtum38', 'rtum40', 'rtum41', 'rtum45', 'rtum46', 'rtum48', 'rtum5', 'rtum50', 'rtum6', 'rtum7', 'rtum76']}\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum13', 'rtum14', 'rtum16', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum22', 'rtum23', 'rtum24', 'rtum26', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum33', 'rtum34', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum39', 'rtum4', 'rtum40', 'rtum41', 'rtum43', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum53', 'rtum55', 'rtum56', 'rtum57', 'rtum58', 'rtum59', 'rtum6', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum66', 'rtum67', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum73', 'rtum74', 'rtum76', 'rtum77', 'rtum78', 'rtum79', 'rtum8', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum85', 'rtum86', 'rtum87', 'rtum88'], 'val': ['rtum12', 'rtum15', 'rtum17', 'rtum21', 'rtum25', 'rtum27', 'rtum31', 'rtum32', 'rtum42', 'rtum44', 'rtum52', 'rtum54', 'rtum60', 'rtum65', 'rtum72', 'rtum75', 'rtum80', 'rtum9']}\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum12', 'rtum13', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum21', 'rtum22', 'rtum24', 'rtum25', 'rtum26', 'rtum27', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum31', 'rtum32', 'rtum33', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum4', 'rtum40', 'rtum41', 'rtum42', 'rtum43', 'rtum44', 'rtum45', 'rtum46', 'rtum48', 'rtum5', 'rtum50', 'rtum52', 'rtum54', 'rtum56', 'rtum57', 'rtum58', 'rtum6', 'rtum60', 'rtum64', 'rtum65', 'rtum67', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum72', 'rtum74', 'rtum75', 'rtum76', 'rtum77', 'rtum78', 'rtum79', 'rtum80', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum86', 'rtum87', 'rtum9'], 'val': ['rtum23', 'rtum34', 'rtum39', 'rtum47', 'rtum49', 'rtum51', 'rtum53', 'rtum55', 'rtum59', 'rtum61', 'rtum62', 'rtum63', 'rtum66', 'rtum73', 'rtum8', 'rtum85', 'rtum88']}\n",
      "{'train': ['rtum1', 'rtum12', 'rtum13', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum21', 'rtum23', 'rtum24', 'rtum25', 'rtum26', 'rtum27', 'rtum3', 'rtum31', 'rtum32', 'rtum33', 'rtum34', 'rtum35', 'rtum37', 'rtum38', 'rtum39', 'rtum4', 'rtum40', 'rtum41', 'rtum42', 'rtum44', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum58', 'rtum59', 'rtum6', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum65', 'rtum66', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum72', 'rtum73', 'rtum75', 'rtum76', 'rtum79', 'rtum8', 'rtum80', 'rtum81', 'rtum82', 'rtum85', 'rtum86', 'rtum87', 'rtum88', 'rtum9'], 'val': ['rtum10', 'rtum11', 'rtum22', 'rtum28', 'rtum29', 'rtum30', 'rtum36', 'rtum43', 'rtum56', 'rtum57', 'rtum64', 'rtum67', 'rtum74', 'rtum77', 'rtum78', 'rtum83', 'rtum84']}\n"
     ]
    }
   ],
   "source": [
    "config = load_config('configs/experiments/deep_aug_5.yaml')\n",
    "spman = SplitManager(split_data=config['data']['split_file'])\n",
    "for data in spman:\n",
    "    print(data)\n",
    "\n",
    "print()\n",
    "print('='*65)\n",
    "print()\n",
    "\n",
    "config = load_config('configs/experiments/test_kfcv.yaml')\n",
    "spman = SplitManager(split_data=config['data']['split_file'])\n",
    "for data in spman:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4007a697-1122-416f-ad85-577f5c5aff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN-VAL SPLIT\n",
      "Fold 1/1\n",
      "['rtum6', 'rtum76', 'rtum2', 'rtum37', 'rtum46', 'rtum35', 'rtum18', 'rtum7', 'rtum14', 'rtum45', 'rtum38', 'rtum41', 'rtum50', 'rtum5', 'rtum24', 'rtum48', 'rtum40', 'rtum16', 'rtum54', 'rtum65', 'rtum27', 'rtum75', 'rtum32', 'rtum52', 'rtum21', 'rtum31', 'rtum12', 'rtum25', 'rtum44', 'rtum17', 'rtum72', 'rtum15', 'rtum60', 'rtum42', 'rtum80', 'rtum9', 'rtum59', 'rtum49', 'rtum55', 'rtum51', 'rtum88', 'rtum23', 'rtum73', 'rtum34', 'rtum47', 'rtum66', 'rtum62', 'rtum53', 'rtum8', 'rtum61', 'rtum39', 'rtum85', 'rtum63', 'rtum67', 'rtum78', 'rtum43', 'rtum36', 'rtum10', 'rtum57', 'rtum29', 'rtum11', 'rtum30', 'rtum83', 'rtum77', 'rtum84', 'rtum28', 'rtum64', 'rtum74', 'rtum22', 'rtum56']\n",
      "ðŸ“Š Loading dataset... 7004 slices found.\n",
      "['rtum79', 'rtum1', 'rtum33', 'rtum3', 'rtum20', 'rtum70', 'rtum19', 'rtum26', 'rtum13', 'rtum71', 'rtum87', 'rtum69', 'rtum58', 'rtum82', 'rtum86', 'rtum68', 'rtum4', 'rtum81']\n",
      "ðŸ“Š Loading dataset... 1830 slices found.\n"
     ]
    }
   ],
   "source": [
    "config = load_config('configs/experiments/deep_aug_5.yaml')\n",
    "spman = SplitManager(split_data=config['data']['split_file'])\n",
    "print(\"TRAIN-VAL SPLIT\")\n",
    "for i, split in enumerate(spman):\n",
    "    print(f\"Fold {i+1}/{len(spman)}\")\n",
    "    train_2d = get_dataset(\n",
    "        config=config,\n",
    "        data=split,\n",
    "        split_type=\"train\",\n",
    "        transform=transforms,\n",
    "        augment=augment\n",
    "    )\n",
    "    val_2d = get_dataset(\n",
    "        config=config,\n",
    "        data=split,\n",
    "        split_type=\"val\",\n",
    "        transform=transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10873dd4-9bb4-4e8b-a0c4-f13da0755776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-FOLD CV SPLIT\n",
      "Fold 1/5\n",
      "{'train': ['rtum10', 'rtum11', 'rtum12', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum2', 'rtum21', 'rtum22', 'rtum23', 'rtum24', 'rtum25', 'rtum27', 'rtum28', 'rtum29', 'rtum30', 'rtum31', 'rtum32', 'rtum34', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum39', 'rtum40', 'rtum41', 'rtum42', 'rtum43', 'rtum44', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum56', 'rtum57', 'rtum59', 'rtum6', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum65', 'rtum66', 'rtum67', 'rtum7', 'rtum72', 'rtum73', 'rtum74', 'rtum75', 'rtum76', 'rtum77', 'rtum78', 'rtum8', 'rtum80', 'rtum83', 'rtum84', 'rtum85', 'rtum88', 'rtum9'], 'val': ['rtum1', 'rtum13', 'rtum19', 'rtum20', 'rtum26', 'rtum3', 'rtum33', 'rtum4', 'rtum58', 'rtum68', 'rtum69', 'rtum70', 'rtum71', 'rtum79', 'rtum81', 'rtum82', 'rtum86', 'rtum87']}\n",
      "ðŸ“Š Loading dataset... 7004 slices found.\n",
      "ðŸ“Š Loading dataset... 1830 slices found.\n",
      "Fold 2/5\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum12', 'rtum13', 'rtum15', 'rtum17', 'rtum19', 'rtum20', 'rtum21', 'rtum22', 'rtum23', 'rtum25', 'rtum26', 'rtum27', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum31', 'rtum32', 'rtum33', 'rtum34', 'rtum36', 'rtum39', 'rtum4', 'rtum42', 'rtum43', 'rtum44', 'rtum47', 'rtum49', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum56', 'rtum57', 'rtum58', 'rtum59', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum65', 'rtum66', 'rtum67', 'rtum68', 'rtum69', 'rtum70', 'rtum71', 'rtum72', 'rtum73', 'rtum74', 'rtum75', 'rtum77', 'rtum78', 'rtum79', 'rtum8', 'rtum80', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum85', 'rtum86', 'rtum87', 'rtum88', 'rtum9'], 'val': ['rtum14', 'rtum16', 'rtum18', 'rtum2', 'rtum24', 'rtum35', 'rtum37', 'rtum38', 'rtum40', 'rtum41', 'rtum45', 'rtum46', 'rtum48', 'rtum5', 'rtum50', 'rtum6', 'rtum7', 'rtum76']}\n",
      "ðŸ“Š Loading dataset... 7080 slices found.\n",
      "ðŸ“Š Loading dataset... 1754 slices found.\n",
      "Fold 3/5\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum13', 'rtum14', 'rtum16', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum22', 'rtum23', 'rtum24', 'rtum26', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum33', 'rtum34', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum39', 'rtum4', 'rtum40', 'rtum41', 'rtum43', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum53', 'rtum55', 'rtum56', 'rtum57', 'rtum58', 'rtum59', 'rtum6', 'rtum61', 'rtum62', 'rtum63', 'rtum64', 'rtum66', 'rtum67', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum73', 'rtum74', 'rtum76', 'rtum77', 'rtum78', 'rtum79', 'rtum8', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum85', 'rtum86', 'rtum87', 'rtum88'], 'val': ['rtum12', 'rtum15', 'rtum17', 'rtum21', 'rtum25', 'rtum27', 'rtum31', 'rtum32', 'rtum42', 'rtum44', 'rtum52', 'rtum54', 'rtum60', 'rtum65', 'rtum72', 'rtum75', 'rtum80', 'rtum9']}\n",
      "ðŸ“Š Loading dataset... 7076 slices found.\n",
      "ðŸ“Š Loading dataset... 1758 slices found.\n",
      "Fold 4/5\n",
      "{'train': ['rtum1', 'rtum10', 'rtum11', 'rtum12', 'rtum13', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum21', 'rtum22', 'rtum24', 'rtum25', 'rtum26', 'rtum27', 'rtum28', 'rtum29', 'rtum3', 'rtum30', 'rtum31', 'rtum32', 'rtum33', 'rtum35', 'rtum36', 'rtum37', 'rtum38', 'rtum4', 'rtum40', 'rtum41', 'rtum42', 'rtum43', 'rtum44', 'rtum45', 'rtum46', 'rtum48', 'rtum5', 'rtum50', 'rtum52', 'rtum54', 'rtum56', 'rtum57', 'rtum58', 'rtum6', 'rtum60', 'rtum64', 'rtum65', 'rtum67', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum72', 'rtum74', 'rtum75', 'rtum76', 'rtum77', 'rtum78', 'rtum79', 'rtum80', 'rtum81', 'rtum82', 'rtum83', 'rtum84', 'rtum86', 'rtum87', 'rtum9'], 'val': ['rtum23', 'rtum34', 'rtum39', 'rtum47', 'rtum49', 'rtum51', 'rtum53', 'rtum55', 'rtum59', 'rtum61', 'rtum62', 'rtum63', 'rtum66', 'rtum73', 'rtum8', 'rtum85', 'rtum88']}\n",
      "ðŸ“Š Loading dataset... 6991 slices found.\n",
      "ðŸ“Š Loading dataset... 1843 slices found.\n",
      "Fold 5/5\n",
      "{'train': ['rtum1', 'rtum12', 'rtum13', 'rtum14', 'rtum15', 'rtum16', 'rtum17', 'rtum18', 'rtum19', 'rtum2', 'rtum20', 'rtum21', 'rtum23', 'rtum24', 'rtum25', 'rtum26', 'rtum27', 'rtum3', 'rtum31', 'rtum32', 'rtum33', 'rtum34', 'rtum35', 'rtum37', 'rtum38', 'rtum39', 'rtum4', 'rtum40', 'rtum41', 'rtum42', 'rtum44', 'rtum45', 'rtum46', 'rtum47', 'rtum48', 'rtum49', 'rtum5', 'rtum50', 'rtum51', 'rtum52', 'rtum53', 'rtum54', 'rtum55', 'rtum58', 'rtum59', 'rtum6', 'rtum60', 'rtum61', 'rtum62', 'rtum63', 'rtum65', 'rtum66', 'rtum68', 'rtum69', 'rtum7', 'rtum70', 'rtum71', 'rtum72', 'rtum73', 'rtum75', 'rtum76', 'rtum79', 'rtum8', 'rtum80', 'rtum81', 'rtum82', 'rtum85', 'rtum86', 'rtum87', 'rtum88', 'rtum9'], 'val': ['rtum10', 'rtum11', 'rtum22', 'rtum28', 'rtum29', 'rtum30', 'rtum36', 'rtum43', 'rtum56', 'rtum57', 'rtum64', 'rtum67', 'rtum74', 'rtum77', 'rtum78', 'rtum83', 'rtum84']}\n",
      "ðŸ“Š Loading dataset... 7185 slices found.\n",
      "ðŸ“Š Loading dataset... 1649 slices found.\n"
     ]
    }
   ],
   "source": [
    "config = load_config('configs/experiments/test_kfcv.yaml')\n",
    "spman = SplitManager(split_data=config['data']['split_file'])\n",
    "print(\"5-FOLD CV SPLIT\")\n",
    "for i, split in enumerate(spman):\n",
    "    print(f\"Fold {i+1}/{len(spman)}\")\n",
    "    print(split)\n",
    "    train_2d = get_dataset(\n",
    "        config=config,\n",
    "        data=split,\n",
    "        split_type=\"train\",\n",
    "        transform=transforms,\n",
    "        augment=augment\n",
    "    )\n",
    "    val_2d = get_dataset(\n",
    "        config=config,\n",
    "        data=split,\n",
    "        split_type=\"val\",\n",
    "        transform=transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "764bafb4-5bc7-4039-86e8-b0655787fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-FOLD CV SPLIT\n",
      "Fold 1/2\n",
      "{'train': ['rtum10'], 'val': ['rtum1']}\n",
      "['rtum10']\n",
      "ðŸ“Š Loading dataset... 56 slices found.\n",
      "['rtum1']\n",
      "ðŸ“Š Loading dataset... 91 slices found.\n",
      "Fold 2/2\n",
      "{'train': ['rtum1'], 'val': ['rtum14']}\n",
      "['rtum1']\n",
      "ðŸ“Š Loading dataset... 91 slices found.\n",
      "['rtum14']\n",
      "ðŸ“Š Loading dataset... 125 slices found.\n"
     ]
    }
   ],
   "source": [
    "config = load_config('configs/experiments/one_deep_kf.yaml')\n",
    "spman = SplitManager(split_data=config['data']['split_file'])\n",
    "print(\"2-FOLD CV SPLIT\")\n",
    "for i, split in enumerate(spman):\n",
    "    print(f\"Fold {i+1}/{len(spman)}\")\n",
    "    print(split)\n",
    "    train_2d = get_dataset(\n",
    "        config=config,\n",
    "        data=split,\n",
    "        split_type=\"train\",\n",
    "        transform=transforms,\n",
    "        augment=augment\n",
    "    )\n",
    "    val_2d = get_dataset(\n",
    "        config=config,\n",
    "        data=split,\n",
    "        split_type=\"val\",\n",
    "        transform=transforms\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
