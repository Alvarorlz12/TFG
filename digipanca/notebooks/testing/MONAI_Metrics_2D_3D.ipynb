{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ce6575-341d-4bad-9409-eade76f170ce",
   "metadata": {},
   "source": [
    "# _Imports & config_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17916a0-c82e-40db-92cd-db9db9fdd70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b446319-a3c9-4b6c-aad6-3afef4315093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52c4321-1539-4013-b6ca-28c8e36e0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Usuario\\\\TFG\\\\digipanca\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff181a2-6db0-45a0-a7c1-addb980ce083",
   "metadata": {},
   "source": [
    "# __Class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad1c676f-6a13-4e14-acbd-7e778909e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai.metrics import DiceMetric, MeanIoU, ConfusionMatrixMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    \"\"\"\n",
    "    Unified segmentation metrics for both 2D and 3D pancreas segmentation, using MONAI.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.dice_metric = DiceMetric(include_background=True, reduction=\"none\")\n",
    "        self.iou_metric = MeanIoU(include_background=True, reduction=\"none\")\n",
    "        self.confusion_matrix = ConfusionMatrixMetric(metric_name=[\"precision\", \"recall\"], reduction=\"none\")\n",
    "        self.post_pred = AsDiscrete(argmax=True, to_onehot=None)  # Convert logits to one-hot\n",
    "        self.post_true = AsDiscrete(to_onehot=None)  # Convert labels to one-hot\n",
    "\n",
    "    def compute_metrics(self, y_pred, y_true):\n",
    "        num_classes = y_pred.shape[1]\n",
    "    \n",
    "        # Update one-hot transform for the number of classes\n",
    "        self.post_pred.to_onehot = num_classes\n",
    "        self.post_true.to_onehot = num_classes\n",
    "    \n",
    "        # Convert logits to one-hot predictions\n",
    "        y_pred_one_hot = self.post_pred(y_pred)\n",
    "    \n",
    "        # Verificar si la forma de y_true tiene un canal de tamaño 1\n",
    "        if y_true.ndim == y_pred.ndim - 1:  \n",
    "            # Asegúrate de que y_true tenga la forma correcta (B, 1, H, W) para 2D\n",
    "            y_true = y_true.unsqueeze(1)  # Añadir el canal si falta\n",
    "    \n",
    "        print(\"y_true shape after unsqueeze:\", y_true.shape)  # Depuración de la forma\n",
    "    \n",
    "        # Convertir a one-hot\n",
    "        y_true_one_hot = self.post_true(y_true)\n",
    "    \n",
    "        # Compute Dice score per class\n",
    "        dice_scores = self.dice_metric(y_pred_one_hot, y_true_one_hot).cpu().numpy()\n",
    "        mean_dice = dice_scores.mean()\n",
    "    \n",
    "        # Compute IoU score per class\n",
    "        iou_scores = self.iou_metric(y_pred_one_hot, y_true_one_hot).cpu().numpy()\n",
    "        mean_iou = iou_scores.mean()\n",
    "    \n",
    "        # Compute Precision and Recall per class\n",
    "        precision, recall = self.confusion_matrix(y_pred_one_hot, y_true_one_hot)\n",
    "        precision = precision.cpu().numpy()\n",
    "        recall = recall.cpu().numpy()\n",
    "        mean_precision = precision.mean()\n",
    "        mean_recall = recall.mean()\n",
    "    \n",
    "        # Format results\n",
    "        metrics = {\n",
    "            \"dice_mean\": mean_dice,\n",
    "            \"iou_mean\": mean_iou,\n",
    "            \"precision_mean\": mean_precision,\n",
    "            \"recall_mean\": mean_recall,\n",
    "        }\n",
    "    \n",
    "        for i in range(num_classes):\n",
    "            metrics[f\"dice_class_{i}\"] = dice_scores[i]\n",
    "            metrics[f\"iou_class_{i}\"] = iou_scores[i]\n",
    "            metrics[f\"precision_class_{i}\"] = precision[i]\n",
    "            metrics[f\"recall_class_{i}\"] = recall[i]\n",
    "    \n",
    "        return metrics\n",
    "    \n",
    "    # def compute_metrics(self, y_pred, y_true):\n",
    "    #     \"\"\"\n",
    "    #     Compute Dice, IoU, Precision, and Recall scores for segmentation.\n",
    "        \n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     y_pred : torch.Tensor\n",
    "    #         Predicted logits of shape (B, C, H, W) for 2D or (B, C, D, H, W) for 3D.\n",
    "    #     y_true : torch.Tensor\n",
    "    #         Ground truth labels of shape (B, H, W) for 2D or (B, D, H, W) for 3D.\n",
    "        \n",
    "    #     Returns\n",
    "    #     -------\n",
    "    #     dict\n",
    "    #         Dictionary with Dice, IoU, Precision, and Recall scores per class and mean.\n",
    "    #     \"\"\"\n",
    "    #     num_classes = y_pred.shape[1]\n",
    "        \n",
    "    #     # Update the one-hot transform for the number of classes\n",
    "    #     self.post_pred.to_onehot = num_classes\n",
    "    #     self.post_true.to_onehot = num_classes\n",
    "        \n",
    "    #     # Convert logits to one-hot predictions\n",
    "    #     y_pred_one_hot = self.post_pred(y_pred)\n",
    "    #     print(y_true.shape)\n",
    "    #     # y_true = y_true = y_true.unsqueeze(1) if y_true.ndim == y_pred.ndim - 1 else y_true\n",
    "    #     if y_true.ndim == y_pred.ndim - 1:  \n",
    "    #         y_true = y_true.unsqueeze(1)\n",
    "    #     print(y_true.shape)\n",
    "    #     y_true_one_hot = self.post_true(y_true)\n",
    "        \n",
    "    #     # Compute Dice score per class\n",
    "    #     dice_scores = self.dice_metric(y_pred_one_hot, y_true_one_hot).cpu().numpy()\n",
    "    #     mean_dice = dice_scores.mean()\n",
    "        \n",
    "    #     # Compute IoU score per class\n",
    "    #     iou_scores = self.iou_metric(y_pred_one_hot, y_true_one_hot).cpu().numpy()\n",
    "    #     mean_iou = iou_scores.mean()\n",
    "        \n",
    "    #     # Compute Precision and Recall per class\n",
    "    #     precision, recall = self.confusion_matrix(y_pred_one_hot, y_true_one_hot)\n",
    "    #     precision = precision.cpu().numpy()\n",
    "    #     recall = recall.cpu().numpy()\n",
    "    #     mean_precision = precision.mean()\n",
    "    #     mean_recall = recall.mean()\n",
    "        \n",
    "    #     # Format results\n",
    "    #     metrics = {\n",
    "    #         \"dice_mean\": mean_dice,\n",
    "    #         \"iou_mean\": mean_iou,\n",
    "    #         \"precision_mean\": mean_precision,\n",
    "    #         \"recall_mean\": mean_recall,\n",
    "    #     }\n",
    "        \n",
    "    #     for i in range(num_classes):\n",
    "    #         metrics[f\"dice_class_{i}\"] = dice_scores[i]\n",
    "    #         metrics[f\"iou_class_{i}\"] = iou_scores[i]\n",
    "    #         metrics[f\"precision_class_{i}\"] = precision[i]\n",
    "    #         metrics[f\"recall_class_{i}\"] = recall[i]\n",
    "        \n",
    "    #     return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4567e17-08b0-402f-9285-0ccbc0137130",
   "metadata": {},
   "source": [
    "# __Test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9cd8575-282b-4a6d-a053-4fa1648e67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test_segmentation_metrics():\n",
    "    metric_calculator = SegmentationMetrics()\n",
    "    \n",
    "    # Test 2D case\n",
    "    batch_size, num_classes, height, width = 4, 5, 256, 256\n",
    "    y_pred_2d = torch.randn(batch_size, num_classes, height, width)  # Logits\n",
    "    y_true_2d = torch.randint(0, num_classes, (batch_size, 1, height, width))  # Ground truth with channel dim\n",
    "    \n",
    "    print(\"Testing 2D segmentation metrics...\")\n",
    "    metrics_2d = metric_calculator.compute_metrics(y_pred_2d, y_true_2d)\n",
    "    print(metrics_2d)\n",
    "    \n",
    "    # Test 3D case\n",
    "    batch_size, num_classes, depth, height, width = 1, 5, 64, 128, 128\n",
    "    y_pred_3d = torch.randn(batch_size, num_classes, depth, height, width)  # Logits\n",
    "    y_true_3d = torch.randint(0, num_classes, (batch_size, 1, depth, height, width))  # Ground truth with channel dim\n",
    "    \n",
    "    print(\"\\nTesting 3D segmentation metrics...\")\n",
    "    metrics_3d = metric_calculator.compute_metrics(y_pred_3d, y_true_3d)\n",
    "    print(metrics_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60f6e307-f7ae-4e1f-aa61-ca317a95e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 2D segmentation metrics...\n",
      "y_true shape after unsqueeze: torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "labels should have a channel with length equal to one.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_segmentation_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 11\u001b[0m, in \u001b[0;36mtest_segmentation_metrics\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m y_true_2d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, num_classes, (batch_size, \u001b[38;5;241m1\u001b[39m, height, width))  \u001b[38;5;66;03m# Ground truth with channel dim\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting 2D segmentation metrics...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m metrics_2d \u001b[38;5;241m=\u001b[39m \u001b[43mmetric_calculator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics_2d)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Test 3D case\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 35\u001b[0m, in \u001b[0;36mSegmentationMetrics.compute_metrics\u001b[1;34m(self, y_pred, y_true)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true shape after unsqueeze:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_true\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Depuración de la forma\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Convertir a one-hot\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m y_true_one_hot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_true\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Compute Dice score per class\u001b[39;00m\n\u001b[0;32m     38\u001b[0m dice_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdice_metric(y_pred_one_hot, y_true_one_hot)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pancreas-segmentation\\lib\\site-packages\\monai\\transforms\\post\\array.py:222\u001b[0m, in \u001b[0;36mAsDiscrete.__call__\u001b[1;34m(self, img, argmax, to_onehot, threshold, rounding)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_onehot, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of classes for One-Hot must be an integer, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(to_onehot)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 222\u001b[0m     img_t \u001b[38;5;241m=\u001b[39m \u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m threshold\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pancreas-segmentation\\lib\\site-packages\\monai\\networks\\utils.py:211\u001b[0m, in \u001b[0;36mone_hot\u001b[1;34m(labels, num_classes, dtype, dim)\u001b[0m\n\u001b[0;32m    208\u001b[0m sh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sh[dim] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels should have a channel with length equal to one.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    213\u001b[0m sh[dim] \u001b[38;5;241m=\u001b[39m num_classes\n\u001b[0;32m    215\u001b[0m o \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(size\u001b[38;5;241m=\u001b[39msh, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mAssertionError\u001b[0m: labels should have a channel with length equal to one."
     ]
    }
   ],
   "source": [
    "test_segmentation_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ad2fb7-6b68-4c74-87d2-f6170b1bcd43",
   "metadata": {},
   "source": [
    "# __Class 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb190b59-7deb-4d30-bef0-de899d7c6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    \"\"\"\n",
    "    Class for computing segmentation metrics that works for both 2D and 3D data.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_tensors(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Helper method to prepare tensors for metric computation.\n",
    "        Handles both 2D and 3D cases, and converts to one-hot if needed.\n",
    "        \"\"\"\n",
    "        # Determine if we're working with 2D or 3D data\n",
    "        is_3d = y_pred.dim() == 4 and (y_true.dim() == 4 or y_true.dim() == 5)  # Adjusted condition\n",
    "        \n",
    "        # Convert to one-hot if inputs are class indices\n",
    "        if y_pred.dim() == (4 if is_3d else 3):  # [B, H, W(, D)] class indices\n",
    "            n_classes = torch.max(y_true).item() + 1\n",
    "            shape = (y_pred.size(0), n_classes) + y_pred.size()[1:]\n",
    "            y_pred_one_hot = torch.zeros(shape, device=y_pred.device)\n",
    "            y_pred_one_hot.scatter_(1, y_pred.unsqueeze(1).long(), 1)  # Added .long()\n",
    "            \n",
    "            y_true_one_hot = torch.zeros(shape, device=y_true.device)\n",
    "            y_true_one_hot.scatter_(1, y_true.unsqueeze(1).long(), 1)  # Added .long()\n",
    "        else:\n",
    "            # If already in form [B, C, H, W(, D)] (logits or one-hot)\n",
    "            if y_pred.dim() == (5 if is_3d else 4) and y_true.dim() == (4 if is_3d else 3):\n",
    "                # y_pred is logits and y_true is class indices\n",
    "                n_classes = y_pred.size(1)\n",
    "                y_pred_one_hot = torch.nn.functional.softmax(y_pred, dim=1)\n",
    "                \n",
    "                shape = (y_true.size(0), n_classes) + y_true.size()[1:]\n",
    "                y_true_one_hot = torch.zeros(shape, device=y_true.device)\n",
    "                y_true_one_hot.scatter_(1, y_true.unsqueeze(1).long(), 1)  # Added .long()\n",
    "            else:\n",
    "                # Assume both are already in proper format\n",
    "                y_pred_one_hot = y_pred\n",
    "                y_true_one_hot = y_true\n",
    "                n_classes = y_pred.size(1)\n",
    "        \n",
    "        return y_pred_one_hot, y_true_one_hot, n_classes\n",
    "    \n",
    "    @staticmethod\n",
    "    def dice_coefficient(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute Dice coefficient for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate dice for each class\n",
    "        dice_scores = []\n",
    "        class_dice = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * true_class)\n",
    "            union = torch.sum(pred_class) + torch.sum(true_class)\n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            dice_scores.append(dice)\n",
    "            class_dice[f\"dice_class_{i}\"] = dice.item()\n",
    "        \n",
    "        mean_dice = torch.mean(torch.stack(dice_scores))\n",
    "        class_dice[\"dice_mean\"] = mean_dice.item()\n",
    "        \n",
    "        return mean_dice, class_dice\n",
    "    \n",
    "    @staticmethod\n",
    "    def iou_score(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute IoU (Jaccard Index) for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate IoU for each class\n",
    "        iou_scores = []\n",
    "        class_iou = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * true_class)\n",
    "            union = torch.sum(pred_class) + torch.sum(true_class) - intersection\n",
    "            iou = (intersection + smooth) / (union + smooth)\n",
    "            iou_scores.append(iou)\n",
    "            class_iou[f\"iou_class_{i}\"] = iou.item()\n",
    "        \n",
    "        mean_iou = torch.mean(torch.stack(iou_scores))\n",
    "        class_iou[\"iou_mean\"] = mean_iou.item()\n",
    "        \n",
    "        return mean_iou, class_iou\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute precision and recall for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate precision and recall for each class\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        class_precision = {}\n",
    "        class_recall = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            true_positives = torch.sum(pred_class * true_class)\n",
    "            predicted_positives = torch.sum(pred_class)\n",
    "            actual_positives = torch.sum(true_class)\n",
    "            \n",
    "            precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "            recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            \n",
    "            class_precision[f\"precision_class_{i}\"] = precision.item()\n",
    "            class_recall[f\"recall_class_{i}\"] = recall.item()\n",
    "        \n",
    "        mean_precision = torch.mean(torch.stack(precision_scores))\n",
    "        mean_recall = torch.mean(torch.stack(recall_scores))\n",
    "        \n",
    "        class_precision[\"precision_mean\"] = mean_precision.item()\n",
    "        class_recall[\"recall_mean\"] = mean_recall.item()\n",
    "        \n",
    "        return mean_precision, mean_recall, class_precision, class_recall\n",
    "    \n",
    "    @staticmethod\n",
    "    def all_metrics(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute all metrics for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Convert logits to class indices if necessary\n",
    "        if y_pred.dim() in [4, 5]:  # Could be [B, C, H, W] or [B, C, H, W, D]\n",
    "            y_pred_indices = torch.argmax(y_pred, dim=1)\n",
    "        else:\n",
    "            y_pred_indices = y_pred\n",
    "            \n",
    "        # Calculate all metrics\n",
    "        mean_dice, class_dice = SegmentationMetrics.dice_coefficient(y_pred, y_true)\n",
    "        metrics.update(class_dice)\n",
    "        \n",
    "        mean_iou, class_iou = SegmentationMetrics.iou_score(y_pred, y_true)\n",
    "        metrics.update(class_iou)\n",
    "        \n",
    "        mean_precision, mean_recall, class_precision, class_recall = SegmentationMetrics.precision_recall(y_pred, y_true)\n",
    "        metrics.update(class_precision)\n",
    "        metrics.update(class_recall)\n",
    "        \n",
    "        # Add overall metrics\n",
    "        metrics['dice'] = mean_dice.item()\n",
    "        metrics['iou'] = mean_iou.item()\n",
    "        metrics['precision'] = mean_precision.item()\n",
    "        metrics['recall'] = mean_recall.item()\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7485f3-8ec9-4c83-9937-9c5e3fd24b16",
   "metadata": {},
   "source": [
    "# __Test 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06856317-1730-47a0-83bd-ea906ae849b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "\n",
    "def test_metrics():\n",
    "    # Configuración inicial\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nTesting on: {device}\")\n",
    "    \n",
    "    # 1. Test 2D case (compatibility check)\n",
    "    print(\"\\n=== Testing 2D case ===\")\n",
    "    batch_size, classes, h, w = 2, 3, 128, 128\n",
    "    \n",
    "    # Create random predictions and ground truth\n",
    "    y_true_2d = torch.randint(0, classes, (batch_size, h, w)).to(device)\n",
    "    y_pred_logits_2d = torch.randn(batch_size, classes, h, w).to(device)\n",
    "    y_pred_indices_2d = torch.argmax(y_pred_logits_2d, dim=1)\n",
    "    \n",
    "    # Test with logits\n",
    "    print(\"\\nTesting with logits (2D):\")\n",
    "    metrics_logits = SegmentationMetrics.all_metrics(y_pred_logits_2d, y_true_2d)\n",
    "    for k, v in metrics_logits.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "    # Test with class indices\n",
    "    print(\"\\nTesting with class indices (2D):\")\n",
    "    metrics_indices = SegmentationMetrics.all_metrics(y_pred_indices_2d, y_true_2d)\n",
    "    for k, v in metrics_indices.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "    # 2. Test 3D case\n",
    "    print(\"\\n=== Testing 3D case ===\")\n",
    "    batch_size, classes, h, w, d = 2, 3, 64, 64, 32\n",
    "    \n",
    "    # Create random predictions and ground truth\n",
    "    y_true_3d = torch.randint(0, classes, (batch_size, h, w, d)).to(device)\n",
    "    y_pred_logits_3d = torch.randn(batch_size, classes, h, w, d).to(device)\n",
    "    y_pred_indices_3d = torch.argmax(y_pred_logits_3d, dim=1)\n",
    "    \n",
    "    # Test with logits\n",
    "    print(\"\\nTesting with logits (3D):\")\n",
    "    metrics_logits_3d = SegmentationMetrics.all_metrics(y_pred_logits_3d, y_true_3d)\n",
    "    for k, v in metrics_logits_3d.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "    # Test with class indices\n",
    "    print(\"\\nTesting with class indices (3D):\")\n",
    "    metrics_indices_3d = SegmentationMetrics.all_metrics(y_pred_indices_3d, y_true_3d)\n",
    "    for k, v in metrics_indices_3d.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "    # 3. Test edge cases\n",
    "    print(\"\\n=== Testing edge cases ===\")\n",
    "    \n",
    "    # Perfect prediction test\n",
    "    print(\"\\nPerfect prediction test (3D):\")\n",
    "    perfect_pred = y_true_3d.clone()\n",
    "    perfect_metrics = SegmentationMetrics.all_metrics(perfect_pred, y_true_3d)\n",
    "    print(f\"Dice: {perfect_metrics['dice']:.4f} (should be 1.0)\")\n",
    "    print(f\"IoU: {perfect_metrics['iou']:.4f} (should be 1.0)\")\n",
    "    \n",
    "    # Worst prediction test (no overlap)\n",
    "    print(\"\\nWorst prediction test (3D):\")\n",
    "    worst_pred = (y_true_3d + 1) % classes  # Guarantees no overlap\n",
    "    worst_metrics = SegmentationMetrics.all_metrics(worst_pred, y_true_3d)\n",
    "    print(f\"Dice: {worst_metrics['dice']:.4f} (should be ~0.0)\")\n",
    "    print(f\"IoU: {worst_metrics['iou']:.4f} (should be ~0.0)\")\n",
    "    \n",
    "    # Empty prediction test\n",
    "    print(\"\\nEmpty prediction test (3D):\")\n",
    "    empty_pred = torch.zeros_like(y_true_3d)\n",
    "    empty_metrics = SegmentationMetrics.all_metrics(empty_pred, y_true_3d)\n",
    "    print(f\"Dice: {empty_metrics['dice_class_0']:.4f} (background)\")\n",
    "    print(f\"IoU: {empty_metrics['iou_class_0']:.4f} (background)\")\n",
    "\n",
    "def test_metric_consistency():\n",
    "    \"\"\"Test consistency between 2D and 3D implementations by using 3D with depth=1\"\"\"\n",
    "    print(\"\\n=== Testing 2D-3D consistency ===\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    batch_size, classes, h, w = 2, 3, 128, 128\n",
    "    d = 1  # Treat as 2D\n",
    "    \n",
    "    # Create identical test cases in 2D and \"3D with depth=1\"\n",
    "    y_true_2d = torch.randint(0, classes, (batch_size, h, w)).to(device)\n",
    "    y_pred_2d = torch.randn(batch_size, classes, h, w).to(device)\n",
    "    \n",
    "    y_true_3d = y_true_2d.unsqueeze(-1)  # [B, H, W, 1]\n",
    "    y_pred_3d = y_pred_2d.unsqueeze(-1)  # [B, C, H, W, 1]\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics_2d = SegmentationMetrics.all_metrics(y_pred_2d, y_true_2d)\n",
    "    metrics_3d = SegmentationMetrics.all_metrics(y_pred_3d, y_true_3d)\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\nComparing Dice scores:\")\n",
    "    for i in range(classes):\n",
    "        key = f\"dice_class_{i}\"\n",
    "        print(f\"Class {i}: 2D={metrics_2d[key]:.6f} | 3D={metrics_3d[key]:.6f} | Diff={abs(metrics_2d[key]-metrics_3d[key]):.2e}\")\n",
    "    \n",
    "    print(\"\\nComparing IoU scores:\")\n",
    "    for i in range(classes):\n",
    "        key = f\"iou_class_{i}\"\n",
    "        print(f\"Class {i}: 2D={metrics_2d[key]:.6f} | 3D={metrics_3d[key]:.6f} | Diff={abs(metrics_2d[key]-metrics_3d[key]):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22328983-9343-4826-b826-d667e7016908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on: cpu\n",
      "\n",
      "=== Testing 2D case ===\n",
      "\n",
      "Testing with logits (2D):\n",
      "dice_class_0: 0.3313\n",
      "dice_class_1: 0.3347\n",
      "dice_class_2: 0.3330\n",
      "dice_mean: 0.3330\n",
      "iou_class_0: 0.1985\n",
      "iou_class_1: 0.2010\n",
      "iou_class_2: 0.1998\n",
      "iou_mean: 0.1998\n",
      "precision_class_0: 0.3294\n",
      "precision_class_1: 0.3355\n",
      "precision_class_2: 0.3341\n",
      "precision_mean: 0.3330\n",
      "recall_class_0: 0.3331\n",
      "recall_class_1: 0.3339\n",
      "recall_class_2: 0.3320\n",
      "recall_mean: 0.3330\n",
      "dice: 0.3330\n",
      "iou: 0.1998\n",
      "precision: 0.3330\n",
      "recall: 0.3330\n",
      "\n",
      "Testing with class indices (2D):\n",
      "dice_class_0: 0.3366\n",
      "dice_class_1: 0.3397\n",
      "dice_class_2: 0.3369\n",
      "dice_mean: 0.3378\n",
      "iou_class_0: 0.2024\n",
      "iou_class_1: 0.2046\n",
      "iou_class_2: 0.2026\n",
      "iou_mean: 0.2032\n",
      "precision_class_0: 0.3339\n",
      "precision_class_1: 0.3405\n",
      "precision_class_2: 0.3390\n",
      "precision_mean: 0.3378\n",
      "recall_class_0: 0.3393\n",
      "recall_class_1: 0.3390\n",
      "recall_class_2: 0.3349\n",
      "recall_mean: 0.3378\n",
      "dice: 0.3378\n",
      "iou: 0.2032\n",
      "precision: 0.3378\n",
      "recall: 0.3378\n",
      "\n",
      "=== Testing 3D case ===\n",
      "\n",
      "Testing with logits (3D):\n",
      "dice_class_0: 0.3337\n",
      "dice_class_1: 0.3330\n",
      "dice_class_2: 0.3340\n",
      "dice_mean: 0.3336\n",
      "iou_class_0: 0.2003\n",
      "iou_class_1: 0.1997\n",
      "iou_class_2: 0.2005\n",
      "iou_mean: 0.2002\n",
      "precision_class_0: 0.3339\n",
      "precision_class_1: 0.3331\n",
      "precision_class_2: 0.3337\n",
      "precision_mean: 0.3336\n",
      "recall_class_0: 0.3336\n",
      "recall_class_1: 0.3328\n",
      "recall_class_2: 0.3343\n",
      "recall_mean: 0.3336\n",
      "dice: 0.3336\n",
      "iou: 0.2002\n",
      "precision: 0.3336\n",
      "recall: 0.3336\n",
      "\n",
      "Testing with class indices (3D):\n",
      "dice_class_0: 0.3338\n",
      "dice_class_1: 0.3318\n",
      "dice_class_2: 0.3351\n",
      "dice_mean: 0.3336\n",
      "iou_class_0: 0.2003\n",
      "iou_class_1: 0.1989\n",
      "iou_class_2: 0.2013\n",
      "iou_mean: 0.2002\n",
      "precision_class_0: 0.3342\n",
      "precision_class_1: 0.3322\n",
      "precision_class_2: 0.3343\n",
      "precision_mean: 0.3336\n",
      "recall_class_0: 0.3334\n",
      "recall_class_1: 0.3314\n",
      "recall_class_2: 0.3360\n",
      "recall_mean: 0.3336\n",
      "dice: 0.3336\n",
      "iou: 0.2002\n",
      "precision: 0.3336\n",
      "recall: 0.3336\n",
      "\n",
      "=== Testing edge cases ===\n",
      "\n",
      "Perfect prediction test (3D):\n",
      "Dice: 1.0000 (should be 1.0)\n",
      "IoU: 1.0000 (should be 1.0)\n",
      "\n",
      "Worst prediction test (3D):\n",
      "Dice: 0.0000 (should be ~0.0)\n",
      "IoU: 0.0000 (should be ~0.0)\n",
      "\n",
      "Empty prediction test (3D):\n",
      "Dice: 0.5001 (background)\n",
      "IoU: 0.3334 (background)\n",
      "\n",
      "=== Testing 2D-3D consistency ===\n",
      "\n",
      "Comparing Dice scores:\n",
      "Class 0: 2D=0.330663 | 3D=0.330663 | Diff=0.00e+00\n",
      "Class 1: 2D=0.335383 | 3D=0.335383 | Diff=0.00e+00\n",
      "Class 2: 2D=0.334938 | 3D=0.334938 | Diff=0.00e+00\n",
      "\n",
      "Comparing IoU scores:\n",
      "Class 0: 2D=0.198081 | 3D=0.198081 | Diff=0.00e+00\n",
      "Class 1: 2D=0.201478 | 3D=0.201478 | Diff=0.00e+00\n",
      "Class 2: 2D=0.201156 | 3D=0.201156 | Diff=0.00e+00\n"
     ]
    }
   ],
   "source": [
    "test_metrics()\n",
    "test_metric_consistency()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89b98f-722a-4f16-939d-ae3a15265f6f",
   "metadata": {},
   "source": [
    "# another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4afd2a6-2b6e-41af-aa77-c98ab40e933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    \"\"\"\n",
    "    Class for computing segmentation metrics that works for both 2D and 3D data.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_tensors(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Helper method to prepare tensors for metric computation.\n",
    "        Handles both 2D and 3D cases, and converts to one-hot if needed.\n",
    "        \"\"\"\n",
    "        # Determine if we're working with 2D or 3D data\n",
    "        is_3d = y_pred.dim() == 5 or (y_pred.dim() == 4 and y_true.dim() == 4)  # Adjusted condition\n",
    "        \n",
    "        # Convert to one-hot if inputs are class indices\n",
    "        if y_pred.dim() == (4 if is_3d else 3):  # [B, H, W(, D)] class indices\n",
    "            n_classes = torch.max(y_true).item() + 1\n",
    "            shape = (y_pred.size(0), n_classes) + y_pred.size()[1:]\n",
    "            y_pred_one_hot = torch.zeros(shape, device=y_pred.device)\n",
    "            y_pred_one_hot.scatter_(1, y_pred.unsqueeze(1).long(), 1)\n",
    "            \n",
    "            y_true_one_hot = torch.zeros(shape, device=y_true.device)\n",
    "            y_true_one_hot.scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "        else:\n",
    "            # If already in form [B, C, H, W(, D)] (logits or one-hot)\n",
    "            if y_pred.dim() == (5 if is_3d else 4) and y_true.dim() == (4 if is_3d else 3):\n",
    "                # y_pred is logits and y_true is class indices\n",
    "                n_classes = y_pred.size(1)\n",
    "                y_pred_one_hot = torch.nn.functional.softmax(y_pred, dim=1)\n",
    "                \n",
    "                shape = (y_true.size(0), n_classes) + y_true.size()[1:]\n",
    "                y_true_one_hot = torch.zeros(shape, device=y_true.device)\n",
    "                y_true_one_hot.scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "            else:\n",
    "                # Assume both are already in proper format\n",
    "                y_pred_one_hot = y_pred\n",
    "                y_true_one_hot = y_true\n",
    "                n_classes = y_pred.size(1)\n",
    "        \n",
    "        return y_pred_one_hot, y_true_one_hot, n_classes\n",
    "    \n",
    "    @staticmethod\n",
    "    def dice_coefficient(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute Dice coefficient for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate dice for each class\n",
    "        dice_scores = []\n",
    "        class_dice = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * true_class)\n",
    "            union = torch.sum(pred_class) + torch.sum(true_class)\n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            dice_scores.append(dice)\n",
    "            class_dice[f\"dice_class_{i}\"] = dice.item()\n",
    "        \n",
    "        mean_dice = torch.mean(torch.stack(dice_scores))\n",
    "        class_dice[\"dice_mean\"] = mean_dice.item()\n",
    "        \n",
    "        return mean_dice, class_dice\n",
    "    \n",
    "    @staticmethod\n",
    "    def iou_score(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute IoU (Jaccard Index) for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate IoU for each class\n",
    "        iou_scores = []\n",
    "        class_iou = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * true_class)\n",
    "            union = torch.sum(pred_class) + torch.sum(true_class) - intersection\n",
    "            iou = (intersection + smooth) / (union + smooth)\n",
    "            iou_scores.append(iou)\n",
    "            class_iou[f\"iou_class_{i}\"] = iou.item()\n",
    "        \n",
    "        mean_iou = torch.mean(torch.stack(iou_scores))\n",
    "        class_iou[\"iou_mean\"] = mean_iou.item()\n",
    "        \n",
    "        return mean_iou, class_iou\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute precision and recall for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate precision and recall for each class\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        class_precision = {}\n",
    "        class_recall = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            true_positives = torch.sum(pred_class * true_class)\n",
    "            predicted_positives = torch.sum(pred_class)\n",
    "            actual_positives = torch.sum(true_class)\n",
    "            \n",
    "            precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "            recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            \n",
    "            class_precision[f\"precision_class_{i}\"] = precision.item()\n",
    "            class_recall[f\"recall_class_{i}\"] = recall.item()\n",
    "        \n",
    "        mean_precision = torch.mean(torch.stack(precision_scores))\n",
    "        mean_recall = torch.mean(torch.stack(recall_scores))\n",
    "        \n",
    "        class_precision[\"precision_mean\"] = mean_precision.item()\n",
    "        class_recall[\"recall_mean\"] = mean_recall.item()\n",
    "        \n",
    "        return mean_precision, mean_recall, class_precision, class_recall\n",
    "    \n",
    "    @staticmethod\n",
    "    def all_metrics(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute all metrics for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Convert logits to class indices if necessary\n",
    "        if y_pred.dim() in [4, 5]:  # Could be [B, C, H, W] or [B, C, H, W, D]\n",
    "            y_pred_indices = torch.argmax(y_pred, dim=1)\n",
    "        else:\n",
    "            y_pred_indices = y_pred\n",
    "            \n",
    "        # Calculate all metrics\n",
    "        mean_dice, class_dice = SegmentationMetrics.dice_coefficient(y_pred, y_true)\n",
    "        metrics.update(class_dice)\n",
    "        \n",
    "        mean_iou, class_iou = SegmentationMetrics.iou_score(y_pred, y_true)\n",
    "        metrics.update(class_iou)\n",
    "        \n",
    "        mean_precision, mean_recall, class_precision, class_recall = SegmentationMetrics.precision_recall(y_pred, y_true)\n",
    "        metrics.update(class_precision)\n",
    "        metrics.update(class_recall)\n",
    "        \n",
    "        # Add overall metrics\n",
    "        metrics['dice'] = mean_dice.item()\n",
    "        metrics['iou'] = mean_iou.item()\n",
    "        metrics['precision'] = mean_precision.item()\n",
    "        metrics['recall'] = mean_recall.item()\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6db9d353-f8fd-4408-92db-85247c7ee7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on: cpu\n",
      "\n",
      "=== Testing 2D case ===\n",
      "\n",
      "Testing with logits (2D):\n",
      "dice: 0.3313\n",
      "dice_class_0: 0.3320\n",
      "dice_class_1: 0.3326\n",
      "dice_class_2: 0.3294\n",
      "dice_mean: 0.3313\n",
      "iou: 0.1986\n",
      "iou_class_0: 0.1991\n",
      "iou_class_1: 0.1995\n",
      "iou_class_2: 0.1972\n",
      "iou_mean: 0.1986\n",
      "precision: 0.3313\n",
      "precision_class_0: 0.3310\n",
      "precision_class_1: 0.3334\n",
      "precision_class_2: 0.3296\n",
      "precision_mean: 0.3313\n",
      "recall: 0.3314\n",
      "recall_class_0: 0.3330\n",
      "recall_class_1: 0.3319\n",
      "recall_class_2: 0.3291\n",
      "recall_mean: 0.3314\n",
      "\n",
      "Testing with class indices (2D):\n",
      "dice: 0.3267\n",
      "dice_class_0: 0.3298\n",
      "dice_class_1: 0.3285\n",
      "dice_class_2: 0.3220\n",
      "dice_mean: 0.3267\n",
      "iou: 0.1953\n",
      "iou_class_0: 0.1974\n",
      "iou_class_1: 0.1965\n",
      "iou_class_2: 0.1919\n",
      "iou_mean: 0.1953\n",
      "precision: 0.3267\n",
      "precision_class_0: 0.3285\n",
      "precision_class_1: 0.3291\n",
      "precision_class_2: 0.3227\n",
      "precision_mean: 0.3267\n",
      "recall: 0.3268\n",
      "recall_class_0: 0.3311\n",
      "recall_class_1: 0.3279\n",
      "recall_class_2: 0.3213\n",
      "recall_mean: 0.3268\n",
      "\n",
      "=== Testing 3D case ===\n",
      "\n",
      "Testing with logits (3D):\n",
      "dice: 0.3335\n",
      "dice_class_0: 0.3326\n",
      "dice_class_1: 0.3346\n",
      "dice_class_2: 0.3333\n",
      "dice_mean: 0.3335\n",
      "iou: 0.2001\n",
      "iou_class_0: 0.1995\n",
      "iou_class_1: 0.2009\n",
      "iou_class_2: 0.2000\n",
      "iou_mean: 0.2001\n",
      "precision: 0.3335\n",
      "precision_class_0: 0.3328\n",
      "precision_class_1: 0.3349\n",
      "precision_class_2: 0.3328\n",
      "precision_mean: 0.3335\n",
      "recall: 0.3335\n",
      "recall_class_0: 0.3325\n",
      "recall_class_1: 0.3343\n",
      "recall_class_2: 0.3337\n",
      "recall_mean: 0.3335\n",
      "\n",
      "Testing with class indices (3D):\n",
      "dice: 0.3335\n",
      "dice_class_0: 0.3324\n",
      "dice_class_1: 0.3351\n",
      "dice_class_2: 0.3330\n",
      "dice_mean: 0.3335\n",
      "iou: 0.2001\n",
      "iou_class_0: 0.1993\n",
      "iou_class_1: 0.2012\n",
      "iou_class_2: 0.1998\n",
      "iou_mean: 0.2001\n",
      "precision: 0.3335\n",
      "precision_class_0: 0.3328\n",
      "precision_class_1: 0.3353\n",
      "precision_class_2: 0.3324\n",
      "precision_mean: 0.3335\n",
      "recall: 0.3335\n",
      "recall_class_0: 0.3320\n",
      "recall_class_1: 0.3348\n",
      "recall_class_2: 0.3337\n",
      "recall_mean: 0.3335\n",
      "\n",
      "All tests completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def test_metrics():\n",
    "    # Configuración inicial\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nTesting on: {device}\")\n",
    "    \n",
    "    # 1. Test 2D case (compatibility check)\n",
    "    print(\"\\n=== Testing 2D case ===\")\n",
    "    batch_size, classes, h, w = 2, 3, 128, 128\n",
    "    \n",
    "    # Create random predictions and ground truth\n",
    "    y_true_2d = torch.randint(0, classes, (batch_size, h, w)).to(device)\n",
    "    y_pred_logits_2d = torch.randn(batch_size, classes, h, w).to(device)\n",
    "    y_pred_indices_2d = torch.argmax(y_pred_logits_2d, dim=1)\n",
    "    \n",
    "    # Test with logits\n",
    "    print(\"\\nTesting with logits (2D):\")\n",
    "    metrics_logits = SegmentationMetrics.all_metrics(y_pred_logits_2d, y_true_2d)\n",
    "    for k, v in sorted(metrics_logits.items()):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "    # Test with class indices\n",
    "    print(\"\\nTesting with class indices (2D):\")\n",
    "    metrics_indices = SegmentationMetrics.all_metrics(y_pred_indices_2d, y_true_2d)\n",
    "    for k, v in sorted(metrics_indices.items()):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "    # 2. Test 3D case\n",
    "    print(\"\\n=== Testing 3D case ===\")\n",
    "    batch_size, classes, h, w, d = 2, 3, 64, 64, 32\n",
    "    \n",
    "    # Create random predictions and ground truth\n",
    "    y_true_3d = torch.randint(0, classes, (batch_size, h, w, d)).to(device)\n",
    "    y_pred_logits_3d = torch.randn(batch_size, classes, h, w, d).to(device)\n",
    "    y_pred_indices_3d = torch.argmax(y_pred_logits_3d, dim=1)\n",
    "    \n",
    "    # Test with logits\n",
    "    print(\"\\nTesting with logits (3D):\")\n",
    "    metrics_logits_3d = SegmentationMetrics.all_metrics(y_pred_logits_3d, y_true_3d)\n",
    "    for k, v in sorted(metrics_logits_3d.items()):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    \n",
    "    # Test with class indices\n",
    "    print(\"\\nTesting with class indices (3D):\")\n",
    "    metrics_indices_3d = SegmentationMetrics.all_metrics(y_pred_indices_3d, y_true_3d)\n",
    "    for k, v in sorted(metrics_indices_3d.items()):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "test_metrics()\n",
    "print(\"\\nAll tests completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8d0b6-3d34-47f7-985c-9940b796f2a3",
   "metadata": {},
   "source": [
    "# __VS MONAI__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1714268f-54cb-45e0-a707-1cf6b165da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Testing on: cpu\n",
      "\n",
      "=== 2D Random Case ===\n",
      "Dice Score:\n",
      "  MONAI: 0.333610\n",
      "  Yours: 0.333237\n",
      "  Difference: 3.73e-04\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 0.200209\n",
      "  Yours: 0.199932\n",
      "  Difference: 2.76e-04\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dice scores differ too much! 0.33361002802848816 vs 0.33323726058006287",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 101\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(torch\u001b[38;5;241m.\u001b[39mtensor(monai_iou), torch\u001b[38;5;241m.\u001b[39mtensor(your_iou), atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m), \\\n\u001b[0;32m     95\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# First run your original tests\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# test_metrics()\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Then run the MONAI comparison\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m \u001b[43mcompare_with_monai\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll tests passed! Your implementation matches MONAI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms results.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[48], line 92\u001b[0m, in \u001b[0;36mcompare_with_monai\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Difference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(monai_iou\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39myour_iou)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Verify they're almost equal\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(torch\u001b[38;5;241m.\u001b[39mtensor(monai_dice), torch\u001b[38;5;241m.\u001b[39mtensor(your_dice), atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m), \\\n\u001b[0;32m     93\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(torch\u001b[38;5;241m.\u001b[39mtensor(monai_iou), torch\u001b[38;5;241m.\u001b[39mtensor(your_iou), atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m), \\\n\u001b[0;32m     95\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Dice scores differ too much! 0.33361002802848816 vs 0.33323726058006287"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.metrics import DiceMetric, MeanIoU\n",
    "from monai.data import decollate_batch\n",
    "from monai.transforms import AsDiscrete, EnsureType\n",
    "\n",
    "class MonaiTester:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        # MONAI metrics\n",
    "        self.dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "        self.iou_metric = MeanIoU(include_background=True, reduction=\"mean\")\n",
    "        # Post-processing transforms\n",
    "        self.post_pred = AsDiscrete(argmax=True, to_onehot=num_classes)\n",
    "        self.post_label = AsDiscrete(to_onehot=num_classes)\n",
    "        self.ensure_type = EnsureType()\n",
    "\n",
    "    def compute_monai_metrics(self, y_pred, y_true):\n",
    "        # Add channel dimension to labels if needed\n",
    "        if y_true.dim() == y_pred.dim() - 1:  # [B, H, W] vs [B, C, H, W]\n",
    "            y_true = y_true.unsqueeze(1)  # Add channel dim\n",
    "            \n",
    "        # Convert to MONAI expected format\n",
    "        y_pred_ = [self.post_pred(self.ensure_type(i)) for i in decollate_batch(y_pred)]\n",
    "        y_true_ = [self.post_label(self.ensure_type(i)) for i in decollate_batch(y_true)]\n",
    "        \n",
    "        # Compute metrics\n",
    "        self.dice_metric(y_pred=y_pred_, y=y_true_)\n",
    "        self.iou_metric(y_pred=y_pred_, y=y_true_)\n",
    "        \n",
    "        dice = self.dice_metric.aggregate().item()\n",
    "        iou = self.iou_metric.aggregate().item()\n",
    "        \n",
    "        # Reset for next round\n",
    "        self.dice_metric.reset()\n",
    "        self.iou_metric.reset()\n",
    "        \n",
    "        return dice, iou\n",
    "\n",
    "def compare_with_monai():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nComparison Testing on: {device}\")\n",
    "    num_classes = 3\n",
    "    \n",
    "    # Initialize testers\n",
    "    monai_tester = MonaiTester(num_classes=num_classes)\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        (\"2D Random\", (2, 128, 128)),\n",
    "        (\"3D Random\", (2, 64, 64, 32)),\n",
    "        (\"2D Perfect\", (2, 128, 128)),\n",
    "        (\"3D Perfect\", (2, 64, 64, 32)),\n",
    "        (\"2D Worst\", (2, 128, 128)),\n",
    "        (\"3D Worst\", (2, 64, 64, 32))\n",
    "    ]\n",
    "    \n",
    "    for name, shape in test_cases:\n",
    "        print(f\"\\n=== {name} Case ===\")\n",
    "        \n",
    "        # Generate test data\n",
    "        if \"Perfect\" in name:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.nn.functional.one_hot(y_true, num_classes).permute(0, -1, *range(1, y_true.dim())).float()\n",
    "        elif \"Worst\" in name:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.nn.functional.one_hot((y_true + 1) % num_classes, num_classes).permute(0, -1, *range(1, y_true.dim())).float()\n",
    "        else:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.randn((shape[0], num_classes) + shape[1:]).to(device)\n",
    "        \n",
    "        # Compute metrics with both implementations\n",
    "        # MONAI metrics\n",
    "        monai_dice, monai_iou = monai_tester.compute_monai_metrics(y_pred, y_true)\n",
    "        \n",
    "        # Your metrics\n",
    "        your_metrics = SegmentationMetrics.all_metrics(y_pred, y_true)\n",
    "        your_dice = your_metrics['dice']\n",
    "        your_iou = your_metrics['iou']\n",
    "        \n",
    "        # Print comparison\n",
    "        print(f\"Dice Score:\")\n",
    "        print(f\"  MONAI: {monai_dice:.6f}\")\n",
    "        print(f\"  Yours: {your_dice:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_dice - your_dice):.2e}\")\n",
    "        \n",
    "        print(f\"\\nIoU (Jaccard):\")\n",
    "        print(f\"  MONAI: {monai_iou:.6f}\")\n",
    "        print(f\"  Yours: {your_iou:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_iou - your_iou):.2e}\")\n",
    "        \n",
    "        # Verify they're almost equal\n",
    "        assert torch.allclose(torch.tensor(monai_dice), torch.tensor(your_dice), atol=1e-5), \\\n",
    "               f\"Dice scores differ too much! {monai_dice} vs {your_dice}\"\n",
    "        assert torch.allclose(torch.tensor(monai_iou), torch.tensor(your_iou), atol=1e-5), \\\n",
    "               f\"IoU scores differ too much! {monai_iou} vs {your_iou}\"\n",
    "\n",
    "# First run your original tests\n",
    "# test_metrics()\n",
    "\n",
    "# Then run the MONAI comparison\n",
    "compare_with_monai()\n",
    "\n",
    "print(\"\\nAll tests passed! Your implementation matches MONAI's results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e40947d3-c36f-4b56-a908-c444f54d23be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Testing on: cpu\n",
      "\n",
      "=== 2D Random Case ===\n",
      "Dice Score:\n",
      "  MONAI: 0.333076\n",
      "  Yours: 0.333989\n",
      "  Difference: 9.13e-04\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 0.199828\n",
      "  Yours: 0.200475\n",
      "  Difference: 6.47e-04\n",
      "\n",
      "=== 3D Random Case ===\n",
      "Dice Score:\n",
      "  MONAI: 0.331340\n",
      "  Yours: 0.332777\n",
      "  Difference: 1.44e-03\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 0.198568\n",
      "  Yours: 0.199600\n",
      "  Difference: 1.03e-03\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dice scores differ too much! 0.33133983612060547 vs 0.33277687430381775",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 60\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_dice \u001b[38;5;241m-\u001b[39m your_dice) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     55\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_iou \u001b[38;5;241m-\u001b[39m your_iou) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     57\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 60\u001b[0m \u001b[43mcompare_with_monai\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll tests passed! Your implementation matches MONAI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms results within tolerance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[49], line 54\u001b[0m, in \u001b[0;36mcompare_with_monai\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Difference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(monai_iou\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39myour_iou)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# More tolerant verification (1e-3 instead of 1e-5)\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_dice \u001b[38;5;241m-\u001b[39m your_dice) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     55\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_iou \u001b[38;5;241m-\u001b[39m your_iou) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     57\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Dice scores differ too much! 0.33133983612060547 vs 0.33277687430381775"
     ]
    }
   ],
   "source": [
    "def compare_with_monai():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nComparison Testing on: {device}\")\n",
    "    num_classes = 3\n",
    "    \n",
    "    # Initialize testers\n",
    "    monai_tester = MonaiTester(num_classes=num_classes)\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        (\"2D Random\", (2, 128, 128)),\n",
    "        (\"3D Random\", (2, 64, 64, 32)),\n",
    "        (\"2D Perfect\", (2, 128, 128)),\n",
    "        (\"3D Perfect\", (2, 64, 64, 32)),\n",
    "        (\"2D Worst\", (2, 128, 128)),\n",
    "        (\"3D Worst\", (2, 64, 64, 32))\n",
    "    ]\n",
    "    \n",
    "    for name, shape in test_cases:\n",
    "        print(f\"\\n=== {name} Case ===\")\n",
    "        \n",
    "        # Generate test data\n",
    "        if \"Perfect\" in name:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.nn.functional.one_hot(y_true, num_classes).permute(0, -1, *range(1, y_true.dim())).float()\n",
    "        elif \"Worst\" in name:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.nn.functional.one_hot((y_true + 1) % num_classes, num_classes).permute(0, -1, *range(1, y_true.dim())).float()\n",
    "        else:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.randn((shape[0], num_classes) + shape[1:]).to(device)\n",
    "        \n",
    "        # Compute metrics with both implementations\n",
    "        # MONAI metrics\n",
    "        monai_dice, monai_iou = monai_tester.compute_monai_metrics(y_pred, y_true)\n",
    "        \n",
    "        # Your metrics\n",
    "        your_metrics = SegmentationMetrics.all_metrics(y_pred, y_true)\n",
    "        your_dice = your_metrics['dice']\n",
    "        your_iou = your_metrics['iou']\n",
    "        \n",
    "        # Print comparison\n",
    "        print(f\"Dice Score:\")\n",
    "        print(f\"  MONAI: {monai_dice:.6f}\")\n",
    "        print(f\"  Yours: {your_dice:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_dice - your_dice):.2e}\")\n",
    "        \n",
    "        print(f\"\\nIoU (Jaccard):\")\n",
    "        print(f\"  MONAI: {monai_iou:.6f}\")\n",
    "        print(f\"  Yours: {your_iou:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_iou - your_iou):.2e}\")\n",
    "        \n",
    "        # More tolerant verification (1e-3 instead of 1e-5)\n",
    "        assert abs(monai_dice - your_dice) < 1e-3, \\\n",
    "               f\"Dice scores differ too much! {monai_dice} vs {your_dice}\"\n",
    "        assert abs(monai_iou - your_iou) < 1e-3, \\\n",
    "               f\"IoU scores differ too much! {monai_iou} vs {your_iou}\"\n",
    "\n",
    "\n",
    "compare_with_monai()\n",
    "print(\"\\nAll tests passed! Your implementation matches MONAI's results within tolerance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a69d6ce-c6aa-46b1-80e9-8094afb31145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Testing on: cpu\n",
      "\n",
      "=== 2D Random Case ===\n",
      "Dice Score:\n",
      "  MONAI: 0.331915\n",
      "  Yours: 0.332830\n",
      "  Difference: 9.15e-04\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 0.198990\n",
      "  Yours: 0.199639\n",
      "  Difference: 6.50e-04\n",
      "\n",
      "=== 3D Random Case ===\n",
      "Dice Score:\n",
      "  MONAI: 0.331693\n",
      "  Yours: 0.332525\n",
      "  Difference: 8.32e-04\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 0.198821\n",
      "  Yours: 0.199419\n",
      "  Difference: 5.98e-04\n",
      "\n",
      "=== 2D Perfect Case ===\n",
      "Dice Score:\n",
      "  MONAI: 1.000000\n",
      "  Yours: 0.576109\n",
      "  Difference: 4.24e-01\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 1.000000\n",
      "  Yours: 0.404603\n",
      "  Difference: 5.95e-01\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dice scores differ too much! 1.0 vs 0.5761087536811829",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 59\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_dice \u001b[38;5;241m-\u001b[39m your_dice) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     55\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_iou \u001b[38;5;241m-\u001b[39m your_iou) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     57\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mcompare_with_monai\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll tests passed! Your implementation matches MONAI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms results within tolerance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[50], line 54\u001b[0m, in \u001b[0;36mcompare_with_monai\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Difference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(monai_iou\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39myour_iou)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# More tolerant verification (1e-3 instead of 1e-5)\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_dice \u001b[38;5;241m-\u001b[39m your_dice) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     55\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_iou \u001b[38;5;241m-\u001b[39m your_iou) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     57\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Dice scores differ too much! 1.0 vs 0.5761087536811829"
     ]
    }
   ],
   "source": [
    "def compare_with_monai():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nComparison Testing on: {device}\")\n",
    "    num_classes = 3\n",
    "    \n",
    "    # Initialize testers\n",
    "    monai_tester = MonaiTester(num_classes=num_classes)\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        (\"2D Random\", (2, 128, 128)),\n",
    "        (\"3D Random\", (2, 64, 64, 32)),\n",
    "        (\"2D Perfect\", (2, 128, 128)),\n",
    "        (\"3D Perfect\", (2, 64, 64, 32)),\n",
    "        (\"2D Worst\", (2, 128, 128)),\n",
    "        (\"3D Worst\", (2, 64, 64, 32))\n",
    "    ]\n",
    "    \n",
    "    for name, shape in test_cases:\n",
    "        print(f\"\\n=== {name} Case ===\")\n",
    "        \n",
    "        # Generate test data\n",
    "        if \"Perfect\" in name:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.nn.functional.one_hot(y_true, num_classes).permute(0, -1, *range(1, y_true.dim())).float()\n",
    "        elif \"Worst\" in name:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.nn.functional.one_hot((y_true + 1) % num_classes, num_classes).permute(0, -1, *range(1, y_true.dim())).float()\n",
    "        else:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.randn((shape[0], num_classes) + shape[1:]).to(device)\n",
    "        \n",
    "        # Compute metrics with both implementations\n",
    "        # MONAI metrics\n",
    "        monai_dice, monai_iou = monai_tester.compute_monai_metrics(y_pred, y_true)\n",
    "        \n",
    "        # Your metrics\n",
    "        your_metrics = SegmentationMetrics.all_metrics(y_pred, y_true)\n",
    "        your_dice = your_metrics['dice']\n",
    "        your_iou = your_metrics['iou']\n",
    "        \n",
    "        # Print comparison\n",
    "        print(f\"Dice Score:\")\n",
    "        print(f\"  MONAI: {monai_dice:.6f}\")\n",
    "        print(f\"  Yours: {your_dice:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_dice - your_dice):.2e}\")\n",
    "        \n",
    "        print(f\"\\nIoU (Jaccard):\")\n",
    "        print(f\"  MONAI: {monai_iou:.6f}\")\n",
    "        print(f\"  Yours: {your_iou:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_iou - your_iou):.2e}\")\n",
    "        \n",
    "        # More tolerant verification (1e-3 instead of 1e-5)\n",
    "        assert abs(monai_dice - your_dice) < 1e-3, \\\n",
    "               f\"Dice scores differ too much! {monai_dice} vs {your_dice}\"\n",
    "        assert abs(monai_iou - your_iou) < 1e-3, \\\n",
    "               f\"IoU scores differ too much! {monai_iou} vs {your_iou}\"\n",
    "\n",
    "compare_with_monai()\n",
    "print(\"\\nAll tests passed! Your implementation matches MONAI's results within tolerance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63a48d43-3b55-4de6-9b9d-725272c62675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    \"\"\"\n",
    "    Class for computing segmentation metrics that works for both 2D and 3D data.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_tensors(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Helper method to prepare tensors for metric computation.\n",
    "        Handles both 2D and 3D cases, and converts to one-hot if needed.\n",
    "        \"\"\"\n",
    "        # Case 1: y_pred is class indices [B, H, W(, D)]\n",
    "        if y_pred.dim() == y_true.dim():\n",
    "            n_classes = torch.max(y_true).item() + 1\n",
    "            y_pred_one_hot = torch.zeros((y_pred.size(0), n_classes) + y_pred.size()[1:], \n",
    "                                      device=y_pred.device)\n",
    "            y_pred_one_hot.scatter_(1, y_pred.unsqueeze(1).long(), 1)\n",
    "            \n",
    "            y_true_one_hot = torch.zeros_like(y_pred_one_hot)\n",
    "            y_true_one_hot.scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "        \n",
    "        # Case 2: y_pred is logits [B, C, H, W(, D)]\n",
    "        else:\n",
    "            n_classes = y_pred.size(1)\n",
    "            y_pred_one_hot = torch.softmax(y_pred, dim=1)\n",
    "            \n",
    "            y_true_one_hot = torch.zeros_like(y_pred_one_hot)\n",
    "            y_true_one_hot.scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "            \n",
    "        return y_pred_one_hot, y_true_one_hot, n_classes\n",
    "    \n",
    "    @staticmethod\n",
    "    def dice_coefficient(y_pred, y_true, smooth=1e-8):\n",
    "        \"\"\"\n",
    "        Compute Dice coefficient for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate dice for each class\n",
    "        dice_scores = []\n",
    "        class_dice = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * true_class)\n",
    "            union = torch.sum(pred_class) + torch.sum(true_class)\n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            dice_scores.append(dice)\n",
    "            class_dice[f\"dice_class_{i}\"] = dice.item()\n",
    "        \n",
    "        mean_dice = torch.mean(torch.stack(dice_scores))\n",
    "        class_dice[\"dice_mean\"] = mean_dice.item()\n",
    "        \n",
    "        return mean_dice, class_dice\n",
    "    \n",
    "    @staticmethod\n",
    "    def iou_score(y_pred, y_true, smooth=1e-8):\n",
    "        \"\"\"\n",
    "        Compute IoU (Jaccard Index) for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate IoU for each class\n",
    "        iou_scores = []\n",
    "        class_iou = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            intersection = torch.sum(pred_class * true_class)\n",
    "            union = torch.sum(pred_class) + torch.sum(true_class) - intersection\n",
    "            iou = (intersection + smooth) / (union + smooth)\n",
    "            iou_scores.append(iou)\n",
    "            class_iou[f\"iou_class_{i}\"] = iou.item()\n",
    "        \n",
    "        mean_iou = torch.mean(torch.stack(iou_scores))\n",
    "        class_iou[\"iou_mean\"] = mean_iou.item()\n",
    "        \n",
    "        return mean_iou, class_iou\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall(y_pred, y_true, smooth=1e-8):\n",
    "        \"\"\"\n",
    "        Compute precision and recall for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        y_pred_one_hot, y_true_one_hot, n_classes = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        # Calculate precision and recall for each class\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        class_precision = {}\n",
    "        class_recall = {}\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i, ...]\n",
    "            true_class = y_true_one_hot[:, i, ...]\n",
    "            \n",
    "            true_positives = torch.sum(pred_class * true_class)\n",
    "            predicted_positives = torch.sum(pred_class)\n",
    "            actual_positives = torch.sum(true_class)\n",
    "            \n",
    "            precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "            recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            \n",
    "            class_precision[f\"precision_class_{i}\"] = precision.item()\n",
    "            class_recall[f\"recall_class_{i}\"] = recall.item()\n",
    "        \n",
    "        mean_precision = torch.mean(torch.stack(precision_scores))\n",
    "        mean_recall = torch.mean(torch.stack(recall_scores))\n",
    "        \n",
    "        class_precision[\"precision_mean\"] = mean_precision.item()\n",
    "        class_recall[\"recall_mean\"] = mean_recall.item()\n",
    "        \n",
    "        return mean_precision, mean_recall, class_precision, class_recall\n",
    "    \n",
    "    @staticmethod\n",
    "    def all_metrics(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute all metrics for 2D or 3D data.\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Convert logits to class indices if necessary\n",
    "        if y_pred.dim() in [4, 5]:  # Could be [B, C, H, W] or [B, C, H, W, D]\n",
    "            y_pred_indices = torch.argmax(y_pred, dim=1)\n",
    "        else:\n",
    "            y_pred_indices = y_pred\n",
    "            \n",
    "        # Calculate all metrics\n",
    "        mean_dice, class_dice = SegmentationMetrics.dice_coefficient(y_pred, y_true)\n",
    "        metrics.update(class_dice)\n",
    "        \n",
    "        mean_iou, class_iou = SegmentationMetrics.iou_score(y_pred, y_true)\n",
    "        metrics.update(class_iou)\n",
    "        \n",
    "        mean_precision, mean_recall, class_precision, class_recall = SegmentationMetrics.precision_recall(y_pred, y_true)\n",
    "        metrics.update(class_precision)\n",
    "        metrics.update(class_recall)\n",
    "        \n",
    "        # Add overall metrics\n",
    "        metrics['dice'] = mean_dice.item()\n",
    "        metrics['iou'] = mean_iou.item()\n",
    "        metrics['precision'] = mean_precision.item()\n",
    "        metrics['recall'] = mean_recall.item()\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a06f8613-82c9-4dec-88c6-6c31d9c400b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Testing on: cpu\n",
      "\n",
      "=== 3D Random Case ===\n",
      "Dice Score:\n",
      "  MONAI: 0.332715\n",
      "  Yours: 0.332840\n",
      "  Difference: 1.25e-04\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 0.199557\n",
      "  Yours: 0.199645\n",
      "  Difference: 8.84e-05\n",
      "\n",
      "=== 3D Perfect Case ===\n",
      "Dice Score:\n",
      "  MONAI: 1.000000\n",
      "  Yours: 0.576117\n",
      "  Difference: 4.24e-01\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 1.000000\n",
      "  Yours: 0.404610\n",
      "  Difference: 5.95e-01\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dice scores differ too much! 1.0 vs 0.5761168599128723",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 59\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_dice \u001b[38;5;241m-\u001b[39m your_dice) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     55\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_iou \u001b[38;5;241m-\u001b[39m your_iou) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     57\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mcompare_with_monai\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll tests passed! Your implementation matches MONAI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms results within tolerance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[70], line 54\u001b[0m, in \u001b[0;36mcompare_with_monai\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Difference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(monai_iou\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39myour_iou)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# More tolerant verification (1e-3 instead of 1e-5)\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_dice \u001b[38;5;241m-\u001b[39m your_dice) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     55\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_dice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_iou \u001b[38;5;241m-\u001b[39m your_iou) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \\\n\u001b[0;32m     57\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU scores differ too much! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonai_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myour_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Dice scores differ too much! 1.0 vs 0.5761168599128723"
     ]
    }
   ],
   "source": [
    "def compare_with_monai():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nComparison Testing on: {device}\")\n",
    "    num_classes = 3\n",
    "    \n",
    "    # Initialize testers\n",
    "    monai_tester = MonaiTester(num_classes=num_classes)\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        # (\"2D Random\", (2, 128, 128)),\n",
    "        (\"3D Random\", (2, 64, 64, 32)),\n",
    "        # (\"2D Perfect\", (2, 128, 128)),\n",
    "        (\"3D Perfect\", (2, 64, 64, 32)),\n",
    "        # (\"2D Worst\", (2, 128, 128)),\n",
    "        (\"3D Worst\", (2, 64, 64, 32))\n",
    "    ]\n",
    "    \n",
    "    for name, shape in test_cases:\n",
    "        print(f\"\\n=== {name} Case ===\")\n",
    "        \n",
    "        # Generate test data\n",
    "        if \"Perfect\" in name:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.nn.functional.one_hot(y_true, num_classes).permute(0, -1, *range(1, y_true.dim())).float()\n",
    "        elif \"Worst\" in name:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.nn.functional.one_hot((y_true + 1) % num_classes, num_classes).permute(0, -1, *range(1, y_true.dim())).float()\n",
    "        else:\n",
    "            y_true = torch.randint(0, num_classes, shape).to(device)\n",
    "            y_pred = torch.randn((shape[0], num_classes) + shape[1:]).to(device)\n",
    "        \n",
    "        # Compute metrics with both implementations\n",
    "        # MONAI metrics\n",
    "        monai_dice, monai_iou = monai_tester.compute_monai_metrics(y_pred, y_true)\n",
    "        \n",
    "        # Your metrics\n",
    "        your_metrics = SegmentationMetrics.all_metrics(y_pred, y_true)\n",
    "        your_dice = your_metrics['dice']\n",
    "        your_iou = your_metrics['iou']\n",
    "        \n",
    "        # Print comparison\n",
    "        print(f\"Dice Score:\")\n",
    "        print(f\"  MONAI: {monai_dice:.6f}\")\n",
    "        print(f\"  Yours: {your_dice:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_dice - your_dice):.2e}\")\n",
    "        \n",
    "        print(f\"\\nIoU (Jaccard):\")\n",
    "        print(f\"  MONAI: {monai_iou:.6f}\")\n",
    "        print(f\"  Yours: {your_iou:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_iou - your_iou):.2e}\")\n",
    "        \n",
    "        # More tolerant verification (1e-3 instead of 1e-5)\n",
    "        assert abs(monai_dice - your_dice) < 1e-3, \\\n",
    "               f\"Dice scores differ too much! {monai_dice} vs {your_dice}\"\n",
    "        assert abs(monai_iou - your_iou) < 1e-3, \\\n",
    "               f\"IoU scores differ too much! {monai_iou} vs {your_iou}\"\n",
    "\n",
    "compare_with_monai()\n",
    "print(\"\\nAll tests passed! Your implementation matches MONAI's results within tolerance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae06fceb-76bc-4b7e-91ef-3fc3d2c0d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    @staticmethod\n",
    "    def _ensure_onehot(tensor, num_classes):\n",
    "        \"\"\"Convert tensor to one-hot format consistently with MONAI\"\"\"\n",
    "        if tensor.dim() == 4:  # [B, H, W, D] -> [B, C, H, W, D]\n",
    "            tensor = tensor.unsqueeze(1)\n",
    "        if tensor.shape[1] != num_classes:\n",
    "            tensor = torch.nn.functional.one_hot(tensor.long(), num_classes)\n",
    "            tensor = tensor.permute(0, -1, *range(1, tensor.dim()-1)).float()\n",
    "        return tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_tensors(y_pred, y_true):\n",
    "        \"\"\"Unified tensor preparation matching MONAI's expectations\"\"\"\n",
    "        # Get number of classes from y_true if not provided\n",
    "        num_classes = y_pred.shape[1] if y_pred.dim() > y_true.dim() else torch.max(y_true).item() + 1\n",
    "        \n",
    "        # Convert both tensors to one-hot format\n",
    "        y_pred_oh = SegmentationMetrics._ensure_onehot(y_pred, num_classes)\n",
    "        y_true_oh = SegmentationMetrics._ensure_onehot(y_true, num_classes)\n",
    "        \n",
    "        return y_pred_oh, y_true_oh, num_classes\n",
    "\n",
    "    @staticmethod\n",
    "    def dice_coefficient(y_pred, y_true, smooth=1e-5):  # Adjusted smoothing to match MONAI\n",
    "        y_pred_oh, y_true_oh, _ = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        intersection = torch.sum(y_pred_oh * y_true_oh, dim=(2,3,4))\n",
    "        union = torch.sum(y_pred_oh, dim=(2,3,4)) + torch.sum(y_true_oh, dim=(2,3,4))\n",
    "        \n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        return torch.mean(dice), {f\"dice_class_{i}\": dice[:,i].mean().item() \n",
    "                                for i in range(dice.shape[1])}\n",
    "\n",
    "    @staticmethod\n",
    "    def iou_score(y_pred, y_true, smooth=1e-5):\n",
    "        y_pred_oh, y_true_oh, _ = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        intersection = torch.sum(y_pred_oh * y_true_oh, dim=(2,3,4))\n",
    "        union = torch.sum(y_pred_oh, dim=(2,3,4)) + torch.sum(y_true_oh, dim=(2,3,4)) - intersection\n",
    "        \n",
    "        iou = (intersection + smooth) / (union + smooth)\n",
    "        return torch.mean(iou), {f\"iou_class_{i}\": iou[:,i].mean().item() \n",
    "                               for i in range(iou.shape[1])}\n",
    "\n",
    "    @staticmethod\n",
    "    def all_metrics(y_pred, y_true):\n",
    "        metrics = {}\n",
    "        mean_dice, dice_classes = SegmentationMetrics.dice_coefficient(y_pred, y_true)\n",
    "        mean_iou, iou_classes = SegmentationMetrics.iou_score(y_pred, y_true)\n",
    "        \n",
    "        metrics.update(dice_classes)\n",
    "        metrics.update(iou_classes)\n",
    "        metrics.update({\n",
    "            'dice': mean_dice.item(),\n",
    "            'iou': mean_iou.item()\n",
    "        })\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b815274-4b7e-46aa-9636-631529280ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Testing on: cpu\n",
      "\n",
      "=== 2D Random Case ===\n",
      "Dice Score:\n",
      "  MONAI: 0.333918\n",
      "  Yours: 0.400248\n",
      "  Difference: 6.63e-02\n",
      "\n",
      "IoU (Jaccard):\n",
      "  MONAI: 0.200429\n",
      "  Yours: 0.250199\n",
      "  Difference: 4.98e-02\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dice mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 55\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_dice \u001b[38;5;241m-\u001b[39m your_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdice\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m             \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_iou \u001b[38;5;241m-\u001b[39m your_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miou\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mcompare_with_monai\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll tests passed! Implementation matches MONAI.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[60], line 51\u001b[0m, in \u001b[0;36mcompare_with_monai\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(your_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour perfect prediction failed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_dice \u001b[38;5;241m-\u001b[39m your_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdice\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(monai_iou \u001b[38;5;241m-\u001b[39m your_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miou\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIoU mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Dice mismatch"
     ]
    }
   ],
   "source": [
    "def compare_with_monai():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nComparison Testing on: {device}\")\n",
    "    num_classes = 3\n",
    "    \n",
    "    monai_tester = MonaiTester(num_classes=num_classes)\n",
    "    \n",
    "    # Test cases - now using proper one-hot format\n",
    "    test_cases = [\n",
    "        (\"2D Random\", (2, num_classes, 128, 128)),\n",
    "        (\"3D Random\", (2, num_classes, 64, 64, 32)),\n",
    "        (\"2D Perfect\", (2, num_classes, 128, 128)),\n",
    "        (\"3D Perfect\", (2, num_classes, 64, 64, 32))\n",
    "    ]\n",
    "    \n",
    "    for name, shape in test_cases:\n",
    "        print(f\"\\n=== {name} Case ===\")\n",
    "        \n",
    "        # Generate proper one-hot test data\n",
    "        if \"Perfect\" in name:\n",
    "            y_true = torch.zeros(shape, device=device)\n",
    "            y_true[:, 0] = 1  # All background\n",
    "            y_pred = y_true.clone()\n",
    "        else:\n",
    "            y_true = torch.rand(shape, device=device)\n",
    "            y_true = y_true / y_true.sum(dim=1, keepdim=True)  # Simulate softmax\n",
    "            y_pred = torch.rand_like(y_true)\n",
    "        \n",
    "        # MONAI metrics\n",
    "        monai_dice, monai_iou = monai_tester.compute_monai_metrics(y_pred, torch.argmax(y_true, dim=1))\n",
    "        \n",
    "        # Your metrics\n",
    "        your_metrics = SegmentationMetrics.all_metrics(y_pred, torch.argmax(y_true, dim=1))\n",
    "        \n",
    "        # Print comparisons\n",
    "        print(f\"Dice Score:\")\n",
    "        print(f\"  MONAI: {monai_dice:.6f}\")\n",
    "        print(f\"  Yours: {your_metrics['dice']:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_dice - your_metrics['dice']):.2e}\")\n",
    "        \n",
    "        print(f\"\\nIoU (Jaccard):\")\n",
    "        print(f\"  MONAI: {monai_iou:.6f}\")\n",
    "        print(f\"  Yours: {your_metrics['iou']:.6f}\")\n",
    "        print(f\"  Difference: {abs(monai_iou - your_metrics['iou']):.2e}\")\n",
    "        \n",
    "        # Verify perfect cases match exactly\n",
    "        if \"Perfect\" in name:\n",
    "            assert abs(monai_dice - 1.0) < 1e-6, \"MONAI perfect prediction failed\"\n",
    "            assert abs(your_metrics['dice'] - 1.0) < 1e-6, \"Your perfect prediction failed\"\n",
    "        else:\n",
    "            assert abs(monai_dice - your_metrics['dice']) < 1e-3, \"Dice mismatch\"\n",
    "            assert abs(monai_iou - your_metrics['iou']) < 1e-3, \"IoU mismatch\"\n",
    "\n",
    "\n",
    "compare_with_monai()\n",
    "print(\"\\nAll tests passed! Implementation matches MONAI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06104031-e9a1-4927-9a36-44f2fa5bcc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationMetrics:\n",
    "    @staticmethod\n",
    "    def _ensure_onehot(tensor, num_classes):\n",
    "        \"\"\"Convert tensor to one-hot format consistently with MONAI\"\"\"\n",
    "        if tensor.dim() == 4 and tensor.shape[1] != num_classes:  # [B, H, W, D] case\n",
    "            tensor = tensor.unsqueeze(1)\n",
    "        if tensor.shape[1] != num_classes:\n",
    "            tensor = torch.nn.functional.one_hot(tensor.long(), num_classes)\n",
    "            tensor = tensor.permute(0, -1, *range(1, tensor.dim()-1)).float()\n",
    "        return tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_tensors(y_pred, y_true):\n",
    "        \"\"\"Unified tensor preparation matching MONAI's expectations\"\"\"\n",
    "        # Get number of classes from y_true if not provided\n",
    "        num_classes = y_pred.shape[1] if y_pred.dim() > y_true.dim() else torch.max(y_true).item() + 1\n",
    "        \n",
    "        # Convert both tensors to one-hot format\n",
    "        y_pred_oh = SegmentationMetrics._ensure_onehot(y_pred, num_classes)\n",
    "        y_true_oh = SegmentationMetrics._ensure_onehot(y_true, num_classes)\n",
    "        \n",
    "        return y_pred_oh, y_true_oh, num_classes\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_spatial_dims(tensor):\n",
    "        \"\"\"Determine spatial dimensions based on tensor shape\"\"\"\n",
    "        if tensor.dim() == 4:  # 2D case [B, C, H, W]\n",
    "            return (2, 3)\n",
    "        elif tensor.dim() == 5:  # 3D case [B, C, H, W, D]\n",
    "            return (2, 3, 4)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported tensor dimension: {tensor.dim()}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def dice_coefficient(y_pred, y_true, smooth=1e-5):\n",
    "        y_pred_oh, y_true_oh, _ = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        spatial_dims = SegmentationMetrics._calculate_spatial_dims(y_pred_oh)\n",
    "        \n",
    "        intersection = torch.sum(y_pred_oh * y_true_oh, dim=spatial_dims)\n",
    "        union = torch.sum(y_pred_oh, dim=spatial_dims) + torch.sum(y_true_oh, dim=spatial_dims)\n",
    "        \n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        return torch.mean(dice), {f\"dice_class_{i}\": dice[:,i].mean().item() \n",
    "                                for i in range(dice.shape[1])}\n",
    "\n",
    "    @staticmethod\n",
    "    def iou_score(y_pred, y_true, smooth=1e-5):\n",
    "        y_pred_oh, y_true_oh, _ = SegmentationMetrics._prepare_tensors(y_pred, y_true)\n",
    "        spatial_dims = SegmentationMetrics._calculate_spatial_dims(y_pred_oh)\n",
    "        \n",
    "        intersection = torch.sum(y_pred_oh * y_true_oh, dim=spatial_dims)\n",
    "        union = torch.sum(y_pred_oh, dim=spatial_dims) + torch.sum(y_true_oh, dim=spatial_dims) - intersection\n",
    "        \n",
    "        iou = (intersection + smooth) / (union + smooth)\n",
    "        return torch.mean(iou), {f\"iou_class_{i}\": iou[:,i].mean().item() \n",
    "                               for i in range(iou.shape[1])}\n",
    "\n",
    "    @staticmethod\n",
    "    def all_metrics(y_pred, y_true):\n",
    "        metrics = {}\n",
    "        mean_dice, dice_classes = SegmentationMetrics.dice_coefficient(y_pred, y_true)\n",
    "        mean_iou, iou_classes = SegmentationMetrics.iou_score(y_pred, y_true)\n",
    "        \n",
    "        metrics.update(dice_classes)\n",
    "        metrics.update(iou_classes)\n",
    "        metrics.update({\n",
    "            'dice': mean_dice.item(),\n",
    "            'iou': mean_iou.item()\n",
    "        })\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f73a3a3-806b-45c0-8dc3-47a2a85ba29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dice': 0.33498871326446533, 'iou': 0.20119662582874298, 'dice_mean': 0.33498871326446533, 'iou_mean': 0.20119662582874298}\n"
     ]
    }
   ],
   "source": [
    "from monai.metrics import DiceMetric, MeanIoU\n",
    "from monai.data import decollate_batch\n",
    "from monai.transforms import AsDiscrete, EnsureType\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    def __init__(self, num_classes, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        \n",
    "        # MONAI metrics setup\n",
    "        self.dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "        self.iou_metric = MeanIoU(include_background=True, reduction=\"mean\")\n",
    "        \n",
    "        # Post-processing transforms\n",
    "        self.post_pred = AsDiscrete(argmax=True, to_onehot=num_classes)\n",
    "        self.post_label = AsDiscrete(to_onehot=num_classes)\n",
    "        self.ensure_type = EnsureType(device=device)\n",
    "\n",
    "    def _prepare_monai_inputs(self, y_pred, y_true):\n",
    "        \"\"\"Convert inputs to MONAI expected format\"\"\"\n",
    "        y_pred = self.ensure_type(y_pred)\n",
    "        y_true = self.ensure_type(y_true)\n",
    "        \n",
    "        # Add channel dim if needed (for class indices)\n",
    "        if y_true.ndim == y_pred.ndim - 1:\n",
    "            y_true = y_true.unsqueeze(1)\n",
    "            \n",
    "        return [self.post_pred(i) for i in decollate_batch(y_pred)], \\\n",
    "               [self.post_label(i) for i in decollate_batch(y_true)]\n",
    "\n",
    "    def compute_metrics(self, y_pred, y_true):\n",
    "        \"\"\"Main method that matches your original API\"\"\"\n",
    "        y_pred_pp, y_true_pp = self._prepare_monai_inputs(y_pred, y_true)\n",
    "        \n",
    "        # Compute metrics\n",
    "        self.dice_metric(y_pred=y_pred_pp, y=y_true_pp)\n",
    "        self.iou_metric(y_pred=y_pred_pp, y=y_true_pp)\n",
    "        \n",
    "        dice = self.dice_metric.aggregate().item()\n",
    "        iou = self.iou_metric.aggregate().item()\n",
    "        \n",
    "        # Reset for next batch\n",
    "        self.dice_metric.reset()\n",
    "        self.iou_metric.reset()\n",
    "        \n",
    "        return {\n",
    "            'dice': dice,\n",
    "            'iou': iou,\n",
    "            'dice_mean': dice,\n",
    "            'iou_mean': iou\n",
    "        }\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize\n",
    "    metrics = SegmentationMetrics(num_classes=3)\n",
    "    \n",
    "    # Test case - batch of 2 128x128 2D images\n",
    "    y_true = torch.randint(0, 3, (2, 128, 128))  # Class indices\n",
    "    y_pred = torch.randn(2, 3, 128, 128)  # Logits\n",
    "    \n",
    "    # Compute\n",
    "    results = metrics.compute_metrics(y_pred, y_true)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef10180c-dcd7-446f-bdf1-2c376b972f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_mean: 0.3302\n",
      "dice_class_0: 0.3312\n",
      "dice_class_1: 0.3336\n",
      "dice_class_2: 0.3258\n",
      "dice: 0.3302\n",
      "iou_mean: 0.1978\n",
      "iou_class_0: 0.1985\n",
      "iou_class_1: 0.2002\n",
      "iou_class_2: 0.1946\n",
      "iou: 0.1978\n",
      "precision_mean: 0.3302\n",
      "precision_class_0: 0.3302\n",
      "precision_class_1: 0.3302\n",
      "precision_class_2: 0.3302\n",
      "precision: 0.3302\n",
      "recall_mean: 0.3302\n",
      "recall_class_0: 0.3302\n",
      "recall_class_1: 0.3302\n",
      "recall_class_2: 0.3302\n",
      "recall: 0.3302\n"
     ]
    }
   ],
   "source": [
    "from monai.metrics import DiceMetric, MeanIoU\n",
    "from monai.data import decollate_batch\n",
    "from monai.transforms import AsDiscrete, EnsureType\n",
    "import torch\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    \"\"\"\n",
    "    Preserves original interface while using MONAI internally.\n",
    "    Output format matches exactly what you had before.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # MONAI metrics setup\n",
    "        self.dice_metric = DiceMetric(include_background=True, \n",
    "                                    reduction=\"none\",\n",
    "                                    get_not_nans=False)\n",
    "        self.iou_metric = MeanIoU(include_background=True,\n",
    "                                 reduction=\"none\",\n",
    "                                 get_not_nans=False)\n",
    "        \n",
    "        # Post-processing transforms\n",
    "        self.post_pred = AsDiscrete(argmax=True, to_onehot=num_classes)\n",
    "        self.post_label = AsDiscrete(to_onehot=num_classes)\n",
    "        self.ensure_type = EnsureType()\n",
    "\n",
    "    def _prepare_inputs(self, y_pred, y_true):\n",
    "        \"\"\"Convert inputs to MONAI expected format\"\"\"\n",
    "        y_pred = self.ensure_type(y_pred)\n",
    "        y_true = self.ensure_type(y_true)\n",
    "        \n",
    "        # Add channel dim if needed (for class indices)\n",
    "        if y_true.dim() == y_pred.dim() - 1:\n",
    "            y_true = y_true.unsqueeze(1)\n",
    "            \n",
    "        return [self.post_pred(i) for i in decollate_batch(y_pred)], \\\n",
    "               [self.post_label(i) for i in decollate_batch(y_true)]\n",
    "\n",
    "    def _create_metrics_dict(self, mean_value, class_values, prefix):\n",
    "        \"\"\"Creates the exact output format you had before\"\"\"\n",
    "        metrics = {\n",
    "            f\"{prefix}_mean\": mean_value.item()\n",
    "        }\n",
    "        \n",
    "        # Handle both tensor and list/array inputs\n",
    "        if torch.is_tensor(class_values):\n",
    "            if class_values.dim() == 0:  # Single value\n",
    "                metrics.update({f\"{prefix}_class_{i}\": class_values.item() \n",
    "                              for i in range(self.num_classes)})\n",
    "            else:  # Per-class values\n",
    "                metrics.update({f\"{prefix}_class_{i}\": class_values[i].item() \n",
    "                              for i in range(len(class_values))})\n",
    "        else:  # List or array\n",
    "            metrics.update({f\"{prefix}_class_{i}\": class_values[i] \n",
    "                          for i in range(len(class_values))})\n",
    "            \n",
    "        metrics[prefix] = metrics[f\"{prefix}_mean\"]  # Add the short version\n",
    "        return metrics\n",
    "\n",
    "    def _compute_precision_recall(self, y_pred_pp, y_true_pp):\n",
    "        \"\"\"Proper precision/recall calculation using TP/FP/FN\"\"\"\n",
    "        # Convert to tensors if they're lists\n",
    "        y_pred = torch.stack(y_pred_pp) if isinstance(y_pred_pp, list) else y_pred_pp\n",
    "        y_true = torch.stack(y_true_pp) if isinstance(y_true_pp, list) else y_true_pp\n",
    "        \n",
    "        # Flatten all predictions and labels\n",
    "        y_pred = y_pred.flatten(1)  # [N, C, H*W*D]\n",
    "        y_true = y_true.flatten(1)\n",
    "        \n",
    "        # Calculate TP, FP, FN per class\n",
    "        tp = (y_pred * y_true).sum(1)\n",
    "        fp = (y_pred * (1 - y_true)).sum(1)\n",
    "        fn = ((1 - y_pred) * y_true).sum(1)\n",
    "        \n",
    "        precision = (tp + 1e-7) / (tp + fp + 1e-7)\n",
    "        recall = (tp + 1e-7) / (tp + fn + 1e-7)\n",
    "        \n",
    "        return precision.mean(0), recall.mean(0)  # Mean across batch\n",
    "\n",
    "    def all_metrics(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Returns metrics in the EXACT original format.\n",
    "        \"\"\"\n",
    "        y_pred_pp, y_true_pp = self._prepare_inputs(y_pred, y_true)\n",
    "        \n",
    "        # Compute Dice and IoU (MONAI)\n",
    "        self.dice_metric(y_pred=y_pred_pp, y=y_true_pp)\n",
    "        dice_scores = self.dice_metric.aggregate()  # Shape: [batch, classes]\n",
    "        dice_mean = torch.mean(dice_scores)\n",
    "        self.dice_metric.reset()\n",
    "        \n",
    "        self.iou_metric(y_pred=y_pred_pp, y=y_true_pp)\n",
    "        iou_scores = self.iou_metric.aggregate()\n",
    "        iou_mean = torch.mean(iou_scores)\n",
    "        self.iou_metric.reset()\n",
    "        \n",
    "        # Compute precision and recall properly\n",
    "        precision, recall = self._compute_precision_recall(y_pred_pp, y_true_pp)\n",
    "        \n",
    "        # Build output\n",
    "        metrics = {}\n",
    "        metrics.update(self._create_metrics_dict(dice_mean, dice_scores.mean(0), 'dice'))\n",
    "        metrics.update(self._create_metrics_dict(iou_mean, iou_scores.mean(0), 'iou'))\n",
    "        metrics.update(self._create_metrics_dict(\n",
    "            torch.mean(precision), \n",
    "            precision, \n",
    "            'precision'))\n",
    "        metrics.update(self._create_metrics_dict(\n",
    "            torch.mean(recall),\n",
    "            recall,\n",
    "            'recall'))\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    metrics = SegmentationMetrics(num_classes=3)\n",
    "    \n",
    "    # Test case - batch of 2 128x128 2D images\n",
    "    y_true = torch.randint(0, 3, (2, 128, 128))  # Class indices\n",
    "    y_pred = torch.randn(2, 3, 128, 128)  # Logits\n",
    "    \n",
    "    # Compute - same call signature as before\n",
    "    results = metrics.all_metrics(y_pred, y_true)\n",
    "    \n",
    "    # Print in the exact original format\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e88f4a2-06d7-4e1b-81a6-e3724b010d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import SegmentationMetrics as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "999e4d9d-c649-4d31-853a-1cfde219edbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zeros(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got float\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "File \u001b[1;32m~\\TFG\\digipanca\\src\\metrics\\segmentation.py:261\u001b[0m, in \u001b[0;36mSegmentationMetrics.all_metrics\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m    258\u001b[0m     y_pred_indices \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Calculate Dice coefficient\u001b[39;00m\n\u001b[1;32m--> 261\u001b[0m mean_dice, class_dice \u001b[38;5;241m=\u001b[39m \u001b[43mSegmentationMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdice_coefficient\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m metrics\u001b[38;5;241m.\u001b[39mupdate(class_dice)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Calculate IoU score\u001b[39;00m\n",
      "File \u001b[1;32m~\\TFG\\digipanca\\src\\metrics\\segmentation.py:31\u001b[0m, in \u001b[0;36mSegmentationMetrics.dice_coefficient\u001b[1;34m(y_pred, y_true, smooth)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Convert predicted class indices to one-hot\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(y_true)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 31\u001b[0m     y_pred_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     y_pred_one_hot\u001b[38;5;241m.\u001b[39mscatter_(\u001b[38;5;241m1\u001b[39m, y_pred\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     37\u001b[0m     y_true_one_hot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m     38\u001b[0m         y_true\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), n_classes, y_true\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), y_true\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m), \n\u001b[0;32m     39\u001b[0m         device\u001b[38;5;241m=\u001b[39my_true\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m     40\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: zeros(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got float\""
     ]
    }
   ],
   "source": [
    "metrics = sm.all_metrics(y_true, y_pred)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
