{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9631107a-dfb1-446c-8ceb-7d8f4422f6e0",
   "metadata": {},
   "source": [
    "# Imports y config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01abb1d0-e181-4590-bb0c-dc866bfffad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae65a5cf-7829-4e3c-bed3-7338141d3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from src.metrics import SegmentationMetrics as sm2d\n",
    "from src.metrics.segmentation3d import SegmentationMetrics3D as sm3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c808cfb-0f7f-4041-b5b8-9ef062e49de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Usuario\\\\TFG\\\\digipanca\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7bad4-9df3-4f9a-93f2-d20c7fdfcf6b",
   "metadata": {},
   "source": [
    "# __Test metrics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a2aef2-afc9-4ecb-9fd7-3bb9d39362cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D\n",
    "y_pred_2d = torch.rand(1, 3, 256, 256)  # 2D logits\n",
    "y_true_2d = torch.randint(0, 3, (1, 256, 256))  # 2D labels\n",
    "\n",
    "# 3D\n",
    "y_pred_3d = torch.rand(1, 3, 64, 256, 256)  # 3D logits\n",
    "y_true_3d = torch.randint(0, 3, (1, 64, 256, 256))  # 3D labels\n",
    "\n",
    "# Compute metrics\n",
    "metrics_2d_a = sm2d.all_metrics(y_pred_2d, y_true_2d)\n",
    "metrics_2d_b = sm3d.all_metrics(y_pred_2d, y_true_2d)\n",
    "metrics_3d = sm3d.all_metrics(y_pred_3d, y_true_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2aa141e-3e54-436f-9658-4601be18cee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics 2D (a): {'dice_class_0': 0.33286917209625244, 'dice_class_1': 0.3338851034641266, 'dice_class_2': 0.3329617381095886, 'dice_mean': 0.3332386612892151, 'iou_class_0': 0.19966590404510498, 'iou_class_1': 0.20039740204811096, 'iou_class_2': 0.19973251223564148, 'iou_mean': 0.19993193447589874, 'precision_class_0': 0.332343190908432, 'precision_class_1': 0.33461466431617737, 'precision_class_2': 0.33276012539863586, 'precision_mean': 0.3332393169403076, 'recall_class_0': 0.333396852016449, 'recall_class_1': 0.3331587314605713, 'recall_class_2': 0.33316361904144287, 'recall_mean': 0.33323973417282104, 'dice': 0.3332386612892151, 'iou': 0.19993193447589874, 'precision': 0.3332393169403076, 'recall': 0.33323973417282104}\n",
      "Metrics 2D (b): {'dice_class_0': 0.33286917209625244, 'dice_class_1': 0.3338851034641266, 'dice_class_2': 0.3329617381095886, 'dice_mean': 0.3332386612892151, 'iou_class_0': 0.19966590404510498, 'iou_class_1': 0.20039740204811096, 'iou_class_2': 0.19973251223564148, 'iou_mean': 0.19993193447589874, 'precision_class_0': 0.332343190908432, 'precision_class_1': 0.33461466431617737, 'precision_class_2': 0.33276012539863586, 'precision_mean': 0.3332393169403076, 'recall_class_0': 0.333396852016449, 'recall_class_1': 0.3331587314605713, 'recall_class_2': 0.33316361904144287, 'recall_mean': 0.33323973417282104, 'dice': 0.3332386612892151, 'iou': 0.19993193447589874, 'precision': 0.3332393169403076, 'recall': 0.33323973417282104}\n",
      "Metrics 3D: {'dice_class_0': 1.9391213655471802, 'dice_class_1': 1.934476375579834, 'dice_class_2': 1.9346919059753418, 'dice_mean': 1.9360965490341187, 'iou_class_0': 31.852277755737305, 'iou_class_1': 29.523344039916992, 'iou_class_2': 29.624099731445312, 'iou_mean': 30.333242416381836, 'precision_class_0': 0.9998299479484558, 'precision_class_1': 0.9973989725112915, 'precision_class_2': 0.9974958896636963, 'precision_mean': 0.9982416033744812, 'recall_class_0': 32.025760650634766, 'recall_class_1': 31.985992431640625, 'recall_class_2': 32.004215240478516, 'recall_mean': 32.00532150268555, 'dice': 1.9360965490341187, 'iou': 30.333242416381836, 'precision': 0.9982416033744812, 'recall': 32.00532150268555}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metrics 2D (a): {metrics_2d_a}\")\n",
    "print(f\"Metrics 2D (b): {metrics_2d_b}\")\n",
    "print(f\"Metrics 3D: {metrics_3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6100971-2710-4011-823b-905d614c82cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las métricas 2D (a) y 2D (b) son exactamente iguales.\n",
      "Verificación completada.\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si los diccionarios son idénticos\n",
    "if metrics_2d_a == metrics_2d_b:\n",
    "    print(\"Las métricas 2D (a) y 2D (b) son exactamente iguales.\")\n",
    "else:\n",
    "    print(\"Las métricas 2D (a) y 2D (b) tienen diferencias.\")\n",
    "\n",
    "# Revisar valores que sean distintos\n",
    "for key in metrics_2d_a:\n",
    "    if key in metrics_2d_b:\n",
    "        value_a = metrics_2d_a[key]\n",
    "        value_b = metrics_2d_b[key]\n",
    "        if value_a != value_b:\n",
    "            print(f\"Diferencia en {key}: a={value_a}, b={value_b}\")\n",
    "\n",
    "print(\"Verificación completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a4f19-ce2f-4ed8-89f5-3616074b8cee",
   "metadata": {},
   "source": [
    "# new func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f662cb-54ae-4e7a-b900-861e2a13d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class sm3dd:\n",
    "    \"\"\"\n",
    "    Robust class for computing segmentation metrics for multiclass segmentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_tensors(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Prepare prediction and ground truth tensors for metric calculation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            Predicted segmentation mask (logits or one-hot)\n",
    "        y_true : torch.Tensor\n",
    "            Ground truth segmentation mask\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (predictions, ground_truth, num_classes)\n",
    "        \"\"\"\n",
    "        # If prediction is logits, convert to predictions\n",
    "        if y_pred.dim() in [4, 5]:  # [B, C, H, W] or [B, C, D, H, W]\n",
    "            y_pred_classes = torch.argmax(y_pred, dim=1)\n",
    "        else:\n",
    "            y_pred_classes = y_pred\n",
    "        \n",
    "        # Determine number of classes\n",
    "        num_classes = torch.max(torch.cat([y_pred_classes, y_true])).item() + 1\n",
    "        \n",
    "        return y_pred_classes, y_true, num_classes\n",
    "    \n",
    "    @staticmethod\n",
    "    def dice_coefficient(y_pred, y_true, smooth=1e-7):\n",
    "        \"\"\"\n",
    "        Compute Dice coefficient for multiclass segmentation.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (mean dice, per-class dice dictionary)\n",
    "        \"\"\"\n",
    "        y_pred, y_true, num_classes = sm3dd._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        dice_scores = []\n",
    "        class_dice = {}\n",
    "        \n",
    "        for cls in range(num_classes):\n",
    "            # Create binary masks for the current class\n",
    "            pred_mask = (y_pred == cls).float()\n",
    "            true_mask = (y_true == cls).float()\n",
    "            \n",
    "            # Compute intersection and union\n",
    "            intersection = torch.sum(pred_mask * true_mask)\n",
    "            union = torch.sum(pred_mask) + torch.sum(true_mask)\n",
    "            \n",
    "            # Compute Dice\n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            \n",
    "            dice_scores.append(dice)\n",
    "            class_dice[f\"dice_class_{cls}\"] = dice.item()\n",
    "        \n",
    "        mean_dice = torch.mean(torch.stack(dice_scores))\n",
    "        class_dice[\"dice_mean\"] = mean_dice.item()\n",
    "        \n",
    "        return mean_dice, class_dice\n",
    "    \n",
    "    @staticmethod\n",
    "    def iou_score(y_pred, y_true, smooth=1e-7):\n",
    "        \"\"\"\n",
    "        Compute Intersection over Union (IoU) for multiclass segmentation.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (mean iou, per-class iou dictionary)\n",
    "        \"\"\"\n",
    "        y_pred, y_true, num_classes = sm3dd._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        iou_scores = []\n",
    "        class_iou = {}\n",
    "        \n",
    "        for cls in range(num_classes):\n",
    "            # Create binary masks for the current class\n",
    "            pred_mask = (y_pred == cls).float()\n",
    "            true_mask = (y_true == cls).float()\n",
    "            \n",
    "            # Compute intersection and union\n",
    "            intersection = torch.sum(pred_mask * true_mask)\n",
    "            union = torch.sum(pred_mask) + torch.sum(true_mask) - intersection\n",
    "            \n",
    "            # Compute IoU\n",
    "            iou = (intersection + smooth) / (union + smooth)\n",
    "            \n",
    "            iou_scores.append(iou)\n",
    "            class_iou[f\"iou_class_{cls}\"] = iou.item()\n",
    "        \n",
    "        mean_iou = torch.mean(torch.stack(iou_scores))\n",
    "        class_iou[\"iou_mean\"] = mean_iou.item()\n",
    "        \n",
    "        return mean_iou, class_iou\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall(y_pred, y_true, smooth=1e-7):\n",
    "        \"\"\"\n",
    "        Compute Precision and Recall for multiclass segmentation.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (mean precision, mean recall, per-class precision, per-class recall)\n",
    "        \"\"\"\n",
    "        y_pred, y_true, num_classes = sm3dd._prepare_tensors(y_pred, y_true)\n",
    "        \n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        class_precision = {}\n",
    "        class_recall = {}\n",
    "        \n",
    "        for cls in range(num_classes):\n",
    "            # Create binary masks for the current class\n",
    "            pred_mask = (y_pred == cls).float()\n",
    "            true_mask = (y_true == cls).float()\n",
    "            \n",
    "            # True Positives, False Positives, False Negatives\n",
    "            true_positives = torch.sum(pred_mask * true_mask)\n",
    "            false_positives = torch.sum(pred_mask * (1 - true_mask))\n",
    "            false_negatives = torch.sum((1 - pred_mask) * true_mask)\n",
    "            \n",
    "            # Precision and Recall\n",
    "            precision = (true_positives + smooth) / (true_positives + false_positives + smooth)\n",
    "            recall = (true_positives + smooth) / (true_positives + false_negatives + smooth)\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            \n",
    "            class_precision[f\"precision_class_{cls}\"] = precision.item()\n",
    "            class_recall[f\"recall_class_{cls}\"] = recall.item()\n",
    "        \n",
    "        mean_precision = torch.mean(torch.stack(precision_scores))\n",
    "        mean_recall = torch.mean(torch.stack(recall_scores))\n",
    "        \n",
    "        class_precision[\"precision_mean\"] = mean_precision.item()\n",
    "        class_recall[\"recall_mean\"] = mean_recall.item()\n",
    "        \n",
    "        return mean_precision, mean_recall, class_precision, class_recall\n",
    "    \n",
    "    @staticmethod\n",
    "    def all_metrics(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute all metrics for multiclass segmentation.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary of all computed metrics\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mean_dice, class_dice = sm3dd.dice_coefficient(y_pred, y_true)\n",
    "        mean_iou, class_iou = sm3dd.iou_score(y_pred, y_true)\n",
    "        mean_precision, mean_recall, class_precision, class_recall = sm3dd.precision_recall(y_pred, y_true)\n",
    "        \n",
    "        # Merge all metrics\n",
    "        metrics.update(class_dice)\n",
    "        metrics.update(class_iou)\n",
    "        metrics.update(class_precision)\n",
    "        metrics.update(class_recall)\n",
    "        \n",
    "        # Add overall metrics\n",
    "        metrics['dice'] = mean_dice.item()\n",
    "        metrics['iou'] = mean_iou.item()\n",
    "        metrics['precision'] = mean_precision.item()\n",
    "        metrics['recall'] = mean_recall.item()\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79987e86-b293-4458-bfbe-ffd414c7eb61",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31b36d0-3fbb-4b04-b319-af3f23da6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D\n",
    "y_pred_2d = torch.rand(1, 3, 256, 256)  # 2D logits\n",
    "y_true_2d = torch.randint(0, 3, (1, 256, 256))  # 2D labels\n",
    "\n",
    "# 3D\n",
    "y_pred_3d = torch.rand(1, 3, 64, 256, 256)  # 3D logits\n",
    "y_true_3d = torch.randint(0, 3, (1, 64, 256, 256))  # 3D labels\n",
    "\n",
    "# Compute metrics\n",
    "metrics_2d_a = sm2d.all_metrics(y_pred_2d, y_true_2d)\n",
    "metrics_2d_b = sm3d.all_metrics(y_pred_2d, y_true_2d)\n",
    "metrics_3d_a = sm3d.all_metrics(y_pred_3d, y_true_3d)\n",
    "metrics_3d_b = sm3dd.all_metrics(y_pred_3d, y_true_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a23afd48-e60c-4045-97a5-cd47641a34d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las métricas 3D (a) y 3D (b) tienen diferencias.\n",
      "Diferencia en dice_class_0: a=1.9345697164535522, b=0.3338319659233093\n",
      "Diferencia en dice_class_1: a=1.9438923597335815, b=0.3332183361053467\n",
      "Diferencia en dice_class_2: a=1.9387074708938599, b=0.33346042037010193\n",
      "Diferencia en dice_mean: a=1.9390565156936646, b=0.3335035741329193\n",
      "Diferencia en iou_class_0: a=29.56686019897461, b=0.20035912096500397\n",
      "Diferencia en iou_class_1: a=34.64580535888672, b=0.19991721212863922\n",
      "Diferencia en iou_class_2: a=31.630409240722656, b=0.20009151101112366\n",
      "Diferencia en iou_mean: a=31.947690963745117, b=0.20012260973453522\n",
      "Diferencia en precision_class_0: a=0.9974095225334167, b=0.3335973620414734\n",
      "Diferencia en precision_class_1: a=1.0023902654647827, b=0.3330245614051819\n",
      "Diferencia en precision_class_2: a=0.9996621012687683, b=0.33388960361480713\n",
      "Diferencia en precision_mean: a=0.9998206496238708, b=0.3335038423538208\n",
      "Diferencia en recall_class_0: a=32.026187896728516, b=0.33406689763069153\n",
      "Diferencia en recall_class_1: a=32.002017974853516, b=0.3334123492240906\n",
      "Diferencia en recall_class_2: a=31.9721622467041, b=0.3330323398113251\n",
      "Diferencia en recall_mean: a=32.0001220703125, b=0.3335038721561432\n",
      "Diferencia en dice: a=1.9390565156936646, b=0.3335035741329193\n",
      "Diferencia en iou: a=31.947690963745117, b=0.20012260973453522\n",
      "Diferencia en precision: a=0.9998206496238708, b=0.3335038423538208\n",
      "Diferencia en recall: a=32.0001220703125, b=0.3335038721561432\n",
      "Verificación completada.\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si los diccionarios son idénticos\n",
    "if metrics_3d_a == metrics_3d_b:\n",
    "    print(\"Las métricas 3D (a) y 3D (b) son exactamente iguales.\")\n",
    "else:\n",
    "    print(\"Las métricas 3D (a) y 3D (b) tienen diferencias.\")\n",
    "\n",
    "# Revisar valores que sean distintos\n",
    "for key in metrics_3d_a:\n",
    "    if key in metrics_3d_b:\n",
    "        value_a = metrics_3d_a[key]\n",
    "        value_b = metrics_3d_b[key]\n",
    "        if value_a != value_b:\n",
    "            print(f\"Diferencia en {key}: a={value_a}, b={value_b}\")\n",
    "\n",
    "print(\"Verificación completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ffb93d-5976-484f-a60f-09c2b12f430a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dice_class_0': 0.3338319659233093, 'dice_class_1': 0.3332183361053467, 'dice_class_2': 0.33346042037010193, 'dice_mean': 0.3335035741329193, 'iou_class_0': 0.20035912096500397, 'iou_class_1': 0.19991721212863922, 'iou_class_2': 0.20009151101112366, 'iou_mean': 0.20012260973453522, 'precision_class_0': 0.3335973620414734, 'precision_class_1': 0.3330245614051819, 'precision_class_2': 0.33388960361480713, 'precision_mean': 0.3335038423538208, 'recall_class_0': 0.33406689763069153, 'recall_class_1': 0.3334123492240906, 'recall_class_2': 0.3330323398113251, 'recall_mean': 0.3335038721561432, 'dice': 0.3335035741329193, 'iou': 0.20012260973453522, 'precision': 0.3335038423538208, 'recall': 0.3335038721561432}\n"
     ]
    }
   ],
   "source": [
    "print(metrics_3d_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b288d5a-2f18-4d6e-b1c3-6f4ad95f024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    \"\"\"\n",
    "    Class for computing segmentation metrics for 2D and 3D segmentation tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def dice_coefficient(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute Dice coefficient for 2D and 3D segmentation.\n",
    "        \"\"\"\n",
    "        dim = y_pred.dim()\n",
    "        if dim == 5:  # 3D case: (B, C, D, H, W)\n",
    "            reduce_axes = (2, 3, 4)\n",
    "        elif dim == 4:  # 2D case: (B, C, H, W)\n",
    "            reduce_axes = (2, 3)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported tensor dimensions: {}\".format(dim))\n",
    "        \n",
    "        y_pred = torch.softmax(y_pred.float(), dim=1)\n",
    "        y_true_one_hot = torch.nn.functional.one_hot(y_true.long(), num_classes=y_pred.shape[1])\n",
    "        y_true_one_hot = y_true_one_hot.permute(0, -1, *range(1, y_true_one_hot.dim() - 1))\n",
    "        # y_true_one_hot = y_true_one_hot.permute(0, -1, *range(1, dim-1))\n",
    "        \n",
    "        intersection = torch.sum(y_pred * y_true_one_hot, dim=reduce_axes)\n",
    "        union = torch.sum(y_pred, dim=reduce_axes) + torch.sum(y_true_one_hot, dim=reduce_axes)\n",
    "        dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "        \n",
    "        mean_dice = torch.mean(dice, dim=0)\n",
    "        return mean_dice, {f\"dice_class_{i}\": d.item() for i, d in enumerate(mean_dice)}\n",
    "\n",
    "    @staticmethod\n",
    "    def iou_score(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute IoU (Jaccard Index) for 2D and 3D segmentation.\n",
    "        \"\"\"\n",
    "        dim = y_pred.dim()\n",
    "        if dim == 5:\n",
    "            reduce_axes = (2, 3, 4)\n",
    "        elif dim == 4:\n",
    "            reduce_axes = (2, 3)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported tensor dimensions: {}\".format(dim))\n",
    "        \n",
    "        y_pred = torch.softmax(y_pred, dim=1)\n",
    "        y_true_one_hot = torch.nn.functional.one_hot(y_true.long(), num_classes=y_pred.shape[1])\n",
    "        y_true_one_hot = y_true_one_hot.permute(0, -1, *range(1, dim-1))\n",
    "        \n",
    "        intersection = torch.sum(y_pred * y_true_one_hot, dim=reduce_axes)\n",
    "        union = torch.sum(y_pred, dim=reduce_axes) + torch.sum(y_true_one_hot, dim=reduce_axes) - intersection\n",
    "        iou = (intersection + smooth) / (union + smooth)\n",
    "        \n",
    "        mean_iou = torch.mean(iou, dim=0)\n",
    "        return mean_iou, {f\"iou_class_{i}\": d.item() for i, d in enumerate(mean_iou)}\n",
    "    \n",
    "    @staticmethod\n",
    "    def all_metrics(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute all segmentation metrics.\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        mean_dice, class_dice = SegmentationMetrics.dice_coefficient(y_pred, y_true)\n",
    "        mean_iou, class_iou = SegmentationMetrics.iou_score(y_pred, y_true)\n",
    "        \n",
    "        metrics.update(class_dice)\n",
    "        metrics.update(class_iou)\n",
    "        metrics['dice'] = mean_dice.mean().item()\n",
    "        metrics['iou'] = mean_iou.mean().item()\n",
    "        \n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c814700-c959-4195-900e-f7d9bd34b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Resultados para imágenes 2D:\n",
      "\n",
      "🔹 Resultados para volúmenes 3D:\n",
      "dice_class_0: 0.3337\n",
      "dice_class_1: 0.3332\n",
      "dice_class_2: 0.3334\n",
      "iou_class_0: 0.2002\n",
      "iou_class_1: 0.1999\n",
      "iou_class_2: 0.2000\n",
      "dice: 0.3334\n",
      "iou: 0.2001\n"
     ]
    }
   ],
   "source": [
    "def generate_synthetic_data(shape, num_classes):\n",
    "    \"\"\"\n",
    "    Genera datos sintéticos de segmentación con valores aleatorios.\n",
    "\n",
    "    Parameters:\n",
    "    - shape: Tuple con el tamaño del tensor (ej. (B, H, W) o (B, D, H, W))\n",
    "    - num_classes: Número de clases en la segmentación\n",
    "\n",
    "    Returns:\n",
    "    - y_pred: Tensor con predicciones (logits)\n",
    "    - y_true: Tensor con ground truth (clases)\n",
    "    \"\"\"\n",
    "    y_true = torch.randint(0, num_classes, shape)  # Ground truth con valores de clase\n",
    "    y_pred_logits = torch.rand((shape[0], num_classes, *shape[1:]))  # Simula logits\n",
    "\n",
    "    return y_pred_logits, y_true\n",
    "\n",
    "# Prueba con datos 2D\n",
    "num_classes = 3\n",
    "batch_size = 2\n",
    "height, width = 128, 128\n",
    "y_pred_2d, y_true_2d = generate_synthetic_data((batch_size, height, width), num_classes)\n",
    "\n",
    "# Prueba con datos 3D (volumen)\n",
    "depth = 32\n",
    "y_pred_3d, y_true_3d = generate_synthetic_data((batch_size, depth, height, width), num_classes)\n",
    "\n",
    "# Calcular métricas en 2D\n",
    "print(\"\\n🔹 Resultados para imágenes 2D:\")\n",
    "metrics_2d_c = SegmentationMetrics.all_metrics(y_pred_2d, y_true_2d)\n",
    "metrics_2d_a = sm2d.all_metrics(y_pred_2d, y_true_2d)\n",
    "# for k, v in metrics_2d_c.items():\n",
    "#     print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Calcular métricas en 3D\n",
    "print(\"\\n🔹 Resultados para volúmenes 3D:\")\n",
    "metrics_3d = SegmentationMetrics.all_metrics(y_pred_3d, y_true_3d)\n",
    "for k, v in metrics_3d.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6f1e28f-7e42-47f5-8bd8-2a5543796b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las métricas 2D (a) y 2D (c) tienen diferencias.\n",
      "Diferencia en dice_class_0: a=0.33450204133987427, b=0.334501713514328\n",
      "Diferencia en dice_class_1: a=0.33226069808006287, b=0.3322582542896271\n",
      "Diferencia en dice_class_2: a=0.332177996635437, b=0.33217430114746094\n",
      "Diferencia en iou_class_0: a=0.20084206759929657, b=0.20084208250045776\n",
      "Diferencia en iou_class_1: a=0.1992282122373581, b=0.19922709465026855\n",
      "Diferencia en iou_class_2: a=0.19916871190071106, b=0.19916707277297974\n",
      "Diferencia en dice: a=0.3329802453517914, b=0.33297809958457947\n",
      "Diferencia en iou: a=0.19974632561206818, b=0.19974541664123535\n",
      "Verificación completada.\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si los diccionarios son idénticos\n",
    "if metrics_2d_a == metrics_2d_c:\n",
    "    print(\"Las métricas 2D (a) y 2D (c) son exactamente iguales.\")\n",
    "else:\n",
    "    print(\"Las métricas 2D (a) y 2D (c) tienen diferencias.\")\n",
    "\n",
    "# Revisar valores que sean distintos\n",
    "for key in metrics_2d_a:\n",
    "    if key in metrics_2d_c:\n",
    "        value_a = metrics_2d_a[key]\n",
    "        value_b = metrics_2d_c[key]\n",
    "        if value_a != value_b:\n",
    "            print(f\"Diferencia en {key}: a={value_a}, b={value_b}\")\n",
    "\n",
    "print(\"Verificación completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8f02e3a-69fa-4e7e-9b98-6af4f9e26237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las métricas 3D y 3D (b) tienen diferencias.\n",
      "Diferencia en dice_class_0: a=0.3336580693721771, b=0.3338319659233093\n",
      "Diferencia en dice_class_1: a=0.3331666588783264, b=0.3332183361053467\n",
      "Diferencia en dice_class_2: a=0.33338677883148193, b=0.33346042037010193\n",
      "Diferencia en iou_class_0: a=0.20023386180400848, b=0.20035912096500397\n",
      "Diferencia en iou_class_1: a=0.19988000392913818, b=0.19991721212863922\n",
      "Diferencia en iou_class_2: a=0.20003849267959595, b=0.20009151101112366\n",
      "Diferencia en dice: a=0.3334038257598877, b=0.3335035741329193\n",
      "Diferencia en iou: a=0.20005078613758087, b=0.20012260973453522\n",
      "Verificación completada.\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si los diccionarios son idénticos\n",
    "if metrics_3d == metrics_3d_b:\n",
    "    print(\"Las métricas 3D y 3D (b) son exactamente iguales.\")\n",
    "else:\n",
    "    print(\"Las métricas 3D y 3D (b) tienen diferencias.\")\n",
    "\n",
    "# Revisar valores que sean distintos\n",
    "for key in metrics_3d:\n",
    "    if key in metrics_3d_b:\n",
    "        value_a = metrics_3d[key]\n",
    "        value_b = metrics_3d_b[key]\n",
    "        if value_a != value_b:\n",
    "            print(f\"Diferencia en {key}: a={value_a}, b={value_b}\")\n",
    "\n",
    "print(\"Verificación completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6f2b8-c67f-43b5-9ab3-2b91f1c891bf",
   "metadata": {},
   "source": [
    "# __vs MONAI__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2e1a941-9960-42fd-822e-1ab2d3d24a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI - Dice per class: 0.3337126672267914\n",
      "MONAI - IoU per class: 0.20027339458465576\n",
      "MONAI - Precision per class: tensor([[[ 29321.,  58304., 116020.,  58499.],\n",
      "         [ 29030.,  58262., 116687.,  58165.],\n",
      "         [ 29130.,  58097., 116918.,  57999.]]])\n",
      "MONAI - Recall per class: tensor([[[ 29321.,  58304., 116020.,  58499.],\n",
      "         [ 29030.,  58262., 116687.,  58165.],\n",
      "         [ 29130.,  58097., 116918.,  57999.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai.metrics as monai_metrics\n",
    "\n",
    "# Simulación de segmentaciones 3D (cambia esto con tus datos reales)\n",
    "y_true = torch.randint(0, 3, (1, 64, 64, 64))  # (batch, depth, height, width)\n",
    "y_pred = torch.randint(0, 3, (1, 64, 64, 64))  # (batch, depth, height, width)\n",
    "\n",
    "# Convertimos a one-hot encoding (MONAI requiere esto para métricas multicategoría)\n",
    "num_classes = 3\n",
    "y_true_onehot = torch.nn.functional.one_hot(y_true, num_classes=num_classes).permute(0, 4, 1, 2, 3)\n",
    "y_pred_onehot = torch.nn.functional.one_hot(y_pred, num_classes=num_classes).permute(0, 4, 1, 2, 3)\n",
    "\n",
    "# Convertir a tipo float\n",
    "y_true_onehot = y_true_onehot.float()\n",
    "y_pred_onehot = y_pred_onehot.float()\n",
    "\n",
    "# 1️⃣ Cálculo de Dice Score con MONAI\n",
    "dice_metric = monai_metrics.DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_result = dice_metric(y_pred_onehot, y_true_onehot)\n",
    "\n",
    "# 2️⃣ Cálculo de IoU con MONAI\n",
    "iou_metric = monai_metrics.MeanIoU(include_background=True, reduction=\"mean\")\n",
    "iou_result = iou_metric(y_pred_onehot, y_true_onehot)\n",
    "\n",
    "# 3️⃣ Precisión y Recall con MONAI\n",
    "precision_metric = monai_metrics.ConfusionMatrixMetric(metric_name=\"precision\", reduction=\"mean\")\n",
    "recall_metric = monai_metrics.ConfusionMatrixMetric(metric_name=\"recall\", reduction=\"mean\")\n",
    "\n",
    "precision_result = precision_metric(y_pred_onehot, y_true_onehot)\n",
    "recall_result = recall_metric(y_pred_onehot, y_true_onehot)\n",
    "\n",
    "# 4️⃣ Mostramos los resultados\n",
    "print(\"MONAI - Dice per class:\", dice_result.mean().item())\n",
    "print(\"MONAI - IoU per class:\", iou_result.mean().item())\n",
    "print(\"MONAI - Precision per class:\", precision_result)\n",
    "print(\"MONAI - Recall per class:\", recall_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9a417fe-a41d-470b-b40f-666482746dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 64 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Suponiendo que ya tienes y_pred y y_true cargados en memoria\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Asegúrate de que tengan el mismo formato que usaste en MONAI\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# y_pred y y_true deben ser tensores de PyTorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluar con SegmentationMetrics\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m metrics1 \u001b[38;5;241m=\u001b[39m \u001b[43mSegmentationMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultados SegmentationMetrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics1)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Evaluar con sm3dd\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[35], line 63\u001b[0m, in \u001b[0;36mSegmentationMetrics.all_metrics\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mCompute all segmentation metrics.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 63\u001b[0m mean_dice, class_dice \u001b[38;5;241m=\u001b[39m \u001b[43mSegmentationMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdice_coefficient\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m mean_iou, class_iou \u001b[38;5;241m=\u001b[39m SegmentationMetrics\u001b[38;5;241m.\u001b[39miou_score(y_pred, y_true)\n\u001b[0;32m     66\u001b[0m metrics\u001b[38;5;241m.\u001b[39mupdate(class_dice)\n",
      "Cell \u001b[1;32mIn[35], line 31\u001b[0m, in \u001b[0;36mSegmentationMetrics.dice_coefficient\u001b[1;34m(y_pred, y_true, smooth)\u001b[0m\n\u001b[0;32m     28\u001b[0m dice \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m intersection \u001b[38;5;241m+\u001b[39m smooth) \u001b[38;5;241m/\u001b[39m (union \u001b[38;5;241m+\u001b[39m smooth)\n\u001b[0;32m     30\u001b[0m mean_dice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(dice, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_dice, {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdice_class_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: d\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mean_dice)}\n",
      "Cell \u001b[1;32mIn[35], line 31\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     28\u001b[0m dice \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m intersection \u001b[38;5;241m+\u001b[39m smooth) \u001b[38;5;241m/\u001b[39m (union \u001b[38;5;241m+\u001b[39m smooth)\n\u001b[0;32m     30\u001b[0m mean_dice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(dice, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_dice, {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdice_class_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mean_dice)}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 64 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Suponiendo que ya tienes y_pred y y_true cargados en memoria\n",
    "# Asegúrate de que tengan el mismo formato que usaste en MONAI\n",
    "# y_pred y y_true deben ser tensores de PyTorch\n",
    "\n",
    "# Evaluar con SegmentationMetrics\n",
    "metrics1 = SegmentationMetrics.all_metrics(y_pred, y_true)\n",
    "print(\"Resultados SegmentationMetrics:\", metrics1)\n",
    "\n",
    "# Evaluar con sm3dd\n",
    "metrics2 = sm3dd.all_metrics(y_pred, y_true)\n",
    "print(\"Resultados sm3dd:\", metrics2)\n",
    "\n",
    "# Evaluar con SegmentationMetrics3D\n",
    "metrics3 = SegmentationMetrics3D.all_metrics(y_pred, y_true)\n",
    "print(\"Resultados SegmentationMetrics3D:\", metrics3)\n",
    "\n",
    "# Resultados de MONAI (asegúrate de tenerlos en un diccionario similar)\n",
    "monai_results = {\n",
    "    \"dice\": dice_metric.mean().item(),  # Ejemplo, reemplaza con los valores reales\n",
    "    \"iou\": iou_metric.mean().item(), \n",
    "    # Otras métricas si las tienes\n",
    "}\n",
    "\n",
    "# Comparación\n",
    "print(\"\\nComparación con MONAI:\")\n",
    "for metric in [\"dice\", \"iou\"]:\n",
    "    print(f\"{metric} - MONAI: {monai_results[metric]:.4f}, SegmentationMetrics: {metrics1[metric]:.4f}, sm3dd: {metrics2[metric]:.4f}, SegmentationMetrics3D: {metrics3[metric]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
