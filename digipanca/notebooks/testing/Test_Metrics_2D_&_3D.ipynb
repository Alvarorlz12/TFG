{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1038a910-14bc-4e31-8479-aafe8f5f8ef3",
   "metadata": {},
   "source": [
    "# _Imports & config_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d0b90f-1d6c-4f7f-a8b1-36b59c671d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fb691a-7b70-4cfd-a02a-a1de6854054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Usuario\\\\TFG\\\\digipanca\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24039b3-fc20-42af-9ad0-19e2cac2bf96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# __Class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3c639c-a7ae-484e-b677-24518fe44a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SegmentationMetrics2D3D:\n",
    "    \"\"\"\n",
    "    Class for computing segmentation metrics for 2D and 3D segmentation tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def dice_coefficient(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute Dice coefficient for 2D and 3D segmentation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            Predicted segmentation mask (class indices or one-hot)\n",
    "        y_true : torch.Tensor\n",
    "            Ground truth segmentation mask (class indices or one-hot)\n",
    "        smooth : float, optional\n",
    "            Smoothing factor to avoid division by zero\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Dice coefficient (overall and per-class)\n",
    "        \"\"\"\n",
    "        # Ensure inputs are 4D (2D: [B, C, H, W], 3D: [B, C, D, H, W])\n",
    "        if y_pred.dim() == 3 or y_pred.dim() == 4:\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            y_true = y_true.unsqueeze(1)\n",
    "\n",
    "        n_classes = torch.max(y_true).item() + 1\n",
    "        y_pred_one_hot = torch.zeros(\n",
    "            y_pred.size(0), n_classes, *y_pred.shape[2:], device=y_pred.device\n",
    "        )\n",
    "        y_pred_one_hot.scatter_(1, y_pred.long(), 1)\n",
    "\n",
    "        y_true_one_hot = torch.zeros(\n",
    "            y_true.size(0), n_classes, *y_true.shape[2:], device=y_true.device\n",
    "        )\n",
    "        y_true_one_hot.scatter_(1, y_true.long(), 1)\n",
    "\n",
    "        dice_scores = []\n",
    "        class_dice = {}\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i]\n",
    "            true_class = y_true_one_hot[:, i]\n",
    "\n",
    "            intersection = torch.sum(pred_class * true_class)\n",
    "            union = torch.sum(pred_class) + torch.sum(true_class)\n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            dice_scores.append(dice)\n",
    "            class_dice[f\"dice_class_{i}\"] = dice.item()\n",
    "\n",
    "        mean_dice = torch.mean(torch.stack(dice_scores))\n",
    "        class_dice[\"dice_mean\"] = mean_dice.item()\n",
    "\n",
    "        return mean_dice, class_dice\n",
    "\n",
    "    @staticmethod\n",
    "    def iou_score(y_pred, y_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute IoU (Jaccard Index) for 2D and 3D segmentation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            Predicted segmentation mask (class indices or one-hot)\n",
    "        y_true : torch.Tensor\n",
    "            Ground truth segmentation mask (class indices or one-hot)\n",
    "        smooth : float, optional\n",
    "            Smoothing factor to avoid division by zero\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (mean_iou, per_class_iou_dict)\n",
    "        \"\"\"\n",
    "        if y_pred.dim() == 3 or y_pred.dim() == 4:\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            y_true = y_true.unsqueeze(1)\n",
    "\n",
    "        n_classes = torch.max(y_true).item() + 1\n",
    "        y_pred_one_hot = torch.zeros(\n",
    "            y_pred.size(0), n_classes, *y_pred.shape[2:], device=y_pred.device\n",
    "        )\n",
    "        y_pred_one_hot.scatter_(1, y_pred.long(), 1)\n",
    "\n",
    "        y_true_one_hot = torch.zeros(\n",
    "            y_true.size(0), n_classes, *y_true.shape[2:], device=y_true.device\n",
    "        )\n",
    "        y_true_one_hot.scatter_(1, y_true.long(), 1)\n",
    "\n",
    "        iou_scores = []\n",
    "        class_iou = {}\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            pred_class = y_pred_one_hot[:, i]\n",
    "            true_class = y_true_one_hot[:, i]\n",
    "\n",
    "            intersection = torch.sum(pred_class * true_class)\n",
    "            union = torch.sum(pred_class) + torch.sum(true_class) - intersection\n",
    "            iou = (intersection + smooth) / (union + smooth)\n",
    "            iou_scores.append(iou)\n",
    "            class_iou[f\"iou_class_{i}\"] = iou.item()\n",
    "\n",
    "        mean_iou = torch.mean(torch.stack(iou_scores))\n",
    "        class_iou[\"iou_mean\"] = mean_iou.item()\n",
    "\n",
    "        return mean_iou, class_iou\n",
    "\n",
    "    @staticmethod\n",
    "    def all_metrics(y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute all metrics for 2D and 3D segmentation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            Predicted segmentation mask (class indices)\n",
    "        y_true : torch.Tensor\n",
    "            Ground truth segmentation mask (class indices)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary of all metrics\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "\n",
    "        # Calculate Dice coefficient\n",
    "        mean_dice, class_dice = SegmentationMetrics2D3D.dice_coefficient(y_pred, y_true)\n",
    "        metrics.update(class_dice)\n",
    "\n",
    "        # Calculate IoU score\n",
    "        mean_iou, class_iou = SegmentationMetrics2D3D.iou_score(y_pred, y_true)\n",
    "        metrics.update(class_iou)\n",
    "\n",
    "        # Add overall metrics\n",
    "        metrics['dice'] = mean_dice.item()\n",
    "        metrics['iou'] = mean_iou.item()\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345ec8a-649a-4806-88a6-f44b189fceb7",
   "metadata": {},
   "source": [
    "# __Test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f515ed-526c-4135-8faf-653f629b8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def to_one_hot(masks, num_classes):\n",
    "    \"\"\"\n",
    "    Convierte una máscara (2D o 3D) a un formato one-hot.\n",
    "\n",
    "    Args:\n",
    "        masks (torch.Tensor): Máscara de etiquetas de tamaño [batch_size, ..., height, width] o [batch_size, ..., depth, height, width].\n",
    "        num_classes (int): Número de clases a convertir.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Máscara en formato one-hot de tamaño [batch_size, num_classes, ..., height, width] o [batch_size, num_classes, ..., depth, height, width].\n",
    "    \"\"\"\n",
    "    # Verifica si la máscara es 2D o 3D\n",
    "    if masks.dim() == 3:  # Caso 2D (batch_size, height, width)\n",
    "        batch_size, height, width = masks.shape\n",
    "        # Reshape para agregar la dimensión de clases\n",
    "        masks_one_hot = torch.zeros(batch_size, num_classes, height, width, device=masks.device)\n",
    "        # Convierte los índices en one-hot\n",
    "        masks_one_hot.scatter_(1, masks.unsqueeze(1), 1)\n",
    "    \n",
    "    elif masks.dim() == 4:  # Caso 3D (batch_size, depth, height, width)\n",
    "        batch_size, depth, height, width = masks.shape\n",
    "        # Reshape para agregar la dimensión de clases\n",
    "        masks_one_hot = torch.zeros(batch_size, num_classes, depth, height, width, device=masks.device)\n",
    "        # Convierte los índices en one-hot\n",
    "        masks_one_hot.scatter_(1, masks.unsqueeze(1), 1)\n",
    "\n",
    "    return masks_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c449ac-aaac-4042-ba0e-7d4df53be612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256, 256])\n",
      "torch.Size([4, 5, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5  # Número de clases\n",
    "masks_2d = torch.randint(0, num_classes, (4, 256, 256))  # Simulamos una máscara 2D (4 imágenes, 256x256)\n",
    "print(masks_2d.shape)\n",
    "masks_one_hot_2d = to_one_hot(masks_2d, num_classes)\n",
    "print(masks_one_hot_2d.shape)  # Salida esperada: [4, 5, 256, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e924a6e-73e5-4385-af83-2cbd89cf25cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128, 64])\n",
      "torch.Size([1, 5, 128, 128, 64])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5  # Número de clases\n",
    "masks_3d = torch.randint(0, num_classes, (1, 128, 128, 64))  # Simulamos una máscara 3D (1 imagen, 128x128x64)\n",
    "print(masks_3d.shape)\n",
    "masks_one_hot_3d = to_one_hot(masks_3d, num_classes)\n",
    "print(masks_one_hot_3d.shape)  # Salida esperada: [1, 5, 128, 128, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39dbd5c0-940e-4e16-9c05-fc9b7a3f9896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.segmentation_monai import SegmentationMonaiMetrics as smm\n",
    "from src.metrics.segmentation_bak import SegmentationMetrics as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c469d4f1-5348-4ddb-b17e-955110fb4613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 256, 256])\n",
      "tensor([[[[-2.8458e-01, -4.9904e-01, -7.3456e-01,  ..., -5.1145e-01,\n",
      "            4.6625e-01,  5.2171e-02],\n",
      "          [ 3.7925e-01, -1.3227e+00, -4.8338e-01,  ...,  6.0373e-01,\n",
      "            2.6324e-01, -6.9275e-01],\n",
      "          [-4.8050e-01, -1.7489e+00,  2.7859e-01,  ...,  9.5167e-01,\n",
      "            4.6431e-02,  1.4337e+00],\n",
      "          ...,\n",
      "          [ 1.8550e+00,  7.5334e-02, -2.1264e-01,  ..., -1.2077e+00,\n",
      "           -6.3903e-01,  2.9483e-01],\n",
      "          [-3.0314e+00,  1.0875e+00, -1.6291e+00,  ...,  3.8931e-01,\n",
      "           -1.9849e+00, -4.8893e-01],\n",
      "          [-3.4027e-01, -1.1086e+00,  4.0716e-02,  ..., -4.7110e-01,\n",
      "           -6.6544e-01,  9.5736e-01]],\n",
      "\n",
      "         [[-5.2425e-01, -2.9773e-01, -7.7641e-01,  ...,  1.7241e+00,\n",
      "            5.6370e-01,  9.8772e-01],\n",
      "          [ 1.6733e+00,  4.8521e-02, -9.2547e-01,  ..., -1.4252e+00,\n",
      "           -5.1551e-01, -1.6048e-01],\n",
      "          [ 9.3728e-01, -1.0400e+00, -4.3233e-01,  ...,  2.8268e+00,\n",
      "           -1.6933e+00, -7.9983e-01],\n",
      "          ...,\n",
      "          [ 9.9525e-01, -1.2966e-01, -2.8124e-01,  ..., -8.5981e-01,\n",
      "            1.2020e+00, -2.2126e-01],\n",
      "          [ 3.0846e-01,  1.0000e+00,  2.8159e+00,  ..., -2.0974e-01,\n",
      "           -1.3593e+00, -2.1633e+00],\n",
      "          [-1.3248e+00, -5.4793e-01,  2.1709e-01,  ..., -9.6866e-01,\n",
      "            4.2633e-01, -8.3710e-01]],\n",
      "\n",
      "         [[ 5.8539e-01,  7.9667e-01,  6.6938e-01,  ..., -1.0966e+00,\n",
      "            1.8434e-01,  9.9127e-01],\n",
      "          [-1.9139e-01, -1.2209e+00,  1.9774e+00,  ...,  6.8659e-01,\n",
      "           -9.7118e-01, -3.2411e-01],\n",
      "          [ 3.2770e-01, -4.4105e-01,  1.5469e+00,  ..., -1.4032e+00,\n",
      "            3.1780e-01, -4.6984e-02],\n",
      "          ...,\n",
      "          [ 1.8462e+00,  1.6375e+00, -1.0223e+00,  ...,  1.6658e-01,\n",
      "           -1.0509e+00,  1.3181e+00],\n",
      "          [-2.7349e+00, -1.2147e+00,  1.9139e-01,  ..., -1.0034e+00,\n",
      "            5.2238e-01,  2.1407e+00],\n",
      "          [ 7.1740e-01, -9.7265e-01,  1.0630e+00,  ..., -4.1881e-01,\n",
      "           -9.0420e-01, -7.8474e-01]],\n",
      "\n",
      "         [[ 1.1185e+00,  4.5664e-01,  3.4139e+00,  ...,  5.3697e-01,\n",
      "            1.5691e+00, -1.0507e+00],\n",
      "          [-1.0176e+00,  1.6333e-01, -1.5369e+00,  ...,  3.7324e-01,\n",
      "           -4.0549e-01, -2.3869e+00],\n",
      "          [-7.4010e-01,  1.7220e-01,  9.4745e-01,  ...,  1.6348e-01,\n",
      "            5.7903e-01, -3.0890e-01],\n",
      "          ...,\n",
      "          [-1.2519e-01,  1.8476e+00, -7.0091e-01,  ...,  9.1247e-01,\n",
      "           -8.4034e-03, -7.8863e-01],\n",
      "          [-1.6203e+00, -4.3097e-01,  2.6647e-01,  ...,  1.9029e-01,\n",
      "           -1.1725e+00, -6.8310e-01],\n",
      "          [ 6.3418e-01,  6.8756e-01,  5.3629e-02,  ...,  1.9979e+00,\n",
      "           -1.4207e-01,  1.7428e+00]],\n",
      "\n",
      "         [[ 6.6404e-01, -4.1236e-01,  1.9811e+00,  ..., -1.5197e+00,\n",
      "            1.0373e+00,  2.6876e-01],\n",
      "          [-1.1165e+00, -1.6920e+00,  4.4217e-01,  ...,  2.3400e-01,\n",
      "            1.0245e+00,  1.0032e+00],\n",
      "          [ 1.7970e-01, -3.1914e-01, -7.9251e-01,  ...,  1.1178e+00,\n",
      "            1.8213e+00, -3.3082e-01],\n",
      "          ...,\n",
      "          [ 1.8114e-01, -1.3176e+00, -3.6081e-01,  ...,  5.1176e-01,\n",
      "            1.2635e+00,  1.0606e+00],\n",
      "          [ 3.0032e-02, -5.9631e-01, -1.5930e+00,  ..., -2.7893e-01,\n",
      "           -3.0481e-01, -9.0832e-01],\n",
      "          [ 6.3413e-01,  7.5885e-01,  5.8838e-01,  ...,  1.1249e+00,\n",
      "           -1.9850e+00, -5.4910e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2440e-03,  1.9762e-01, -6.3398e-01,  ..., -1.8285e+00,\n",
      "           -3.5401e-01, -1.5526e+00],\n",
      "          [ 6.5808e-02,  7.9498e-01,  1.8474e-02,  ...,  3.9818e-01,\n",
      "            1.0689e+00, -7.1356e-01],\n",
      "          [ 2.8539e+00,  7.2308e-01,  8.1420e-01,  ...,  6.2242e-01,\n",
      "           -1.0719e+00,  1.7146e+00],\n",
      "          ...,\n",
      "          [ 4.1348e-01, -1.9531e-01,  6.3092e-01,  ...,  5.7073e-01,\n",
      "            5.6434e-01,  1.5942e+00],\n",
      "          [ 8.9726e-01, -6.8631e-02, -1.6611e-01,  ..., -6.6030e-01,\n",
      "            9.9305e-01,  1.1141e+00],\n",
      "          [ 1.0452e+00,  9.0881e-01,  8.9069e-02,  ...,  5.0219e-01,\n",
      "           -1.1303e+00,  2.8183e-01]],\n",
      "\n",
      "         [[-8.9376e-01, -1.1497e+00,  1.4991e-01,  ..., -4.0609e-01,\n",
      "            8.6709e-01,  2.7130e-01],\n",
      "          [ 4.3416e-01,  6.7749e-02, -1.4672e+00,  ...,  1.4105e+00,\n",
      "           -6.0975e-01,  1.0849e+00],\n",
      "          [ 2.7493e-01, -8.0789e-01,  5.0190e-01,  ...,  1.2876e+00,\n",
      "           -4.3137e-01, -7.8425e-01],\n",
      "          ...,\n",
      "          [-2.8848e-01, -2.3537e+00,  2.9250e-01,  ...,  1.8184e+00,\n",
      "            6.0529e-02,  7.2697e-01],\n",
      "          [ 7.4416e-01,  4.3141e-01, -3.7442e-03,  ...,  7.0419e-02,\n",
      "            4.4143e-01,  3.2583e-01],\n",
      "          [ 7.0895e-01, -1.1185e-01,  7.9201e-01,  ...,  1.8787e-01,\n",
      "            3.0244e-02, -8.7610e-02]],\n",
      "\n",
      "         [[-3.3530e-01,  5.6173e-01, -1.4171e+00,  ..., -4.0542e-01,\n",
      "            5.9748e-01, -8.3928e-01],\n",
      "          [ 2.6586e-01, -1.5138e+00,  2.1231e+00,  ...,  2.7691e+00,\n",
      "           -6.8902e-01,  1.5572e+00],\n",
      "          [ 9.5283e-01, -1.0763e+00, -3.0265e-01,  ..., -4.8303e-01,\n",
      "            6.0933e-01, -1.2511e+00],\n",
      "          ...,\n",
      "          [-8.7685e-01, -1.1909e+00,  2.7212e+00,  ...,  3.8574e-01,\n",
      "            8.5862e-02, -2.0833e-01],\n",
      "          [ 8.9450e-01,  5.1246e-01,  7.3144e-01,  ..., -5.8692e-01,\n",
      "            1.5881e+00, -8.1094e-01],\n",
      "          [-1.1953e+00,  1.4574e+00,  2.7629e-01,  ..., -1.9123e-01,\n",
      "           -1.1807e+00, -7.2224e-01]],\n",
      "\n",
      "         [[ 9.6881e-01, -1.1472e+00,  2.0649e+00,  ..., -9.2145e-01,\n",
      "            1.6531e-01, -6.7850e-01],\n",
      "          [ 5.3431e-01,  3.4297e-02,  6.5650e-01,  ..., -4.9390e-01,\n",
      "            1.6736e-01, -2.1811e-01],\n",
      "          [-3.6813e-01,  2.0170e+00,  7.3442e-01,  ...,  1.7259e+00,\n",
      "            2.9121e-01, -7.9518e-01],\n",
      "          ...,\n",
      "          [ 5.3036e-01,  9.6917e-01, -7.5692e-01,  ..., -5.1736e-01,\n",
      "            4.4346e-01,  7.5107e-01],\n",
      "          [ 7.3686e-01, -3.0174e-01, -2.9890e-01,  ...,  1.0694e+00,\n",
      "            1.1026e+00,  9.3463e-01],\n",
      "          [-7.5057e-01, -3.1481e-01,  1.5234e+00,  ...,  5.0884e-02,\n",
      "            1.5295e+00, -1.3645e+00]],\n",
      "\n",
      "         [[ 1.1927e+00, -6.0608e-01, -8.2726e-01,  ..., -1.0019e-01,\n",
      "           -2.4510e-01, -3.5412e-01],\n",
      "          [ 1.7166e-02,  3.1877e-01,  1.3912e-01,  ..., -2.1817e-01,\n",
      "            6.7007e-01,  5.1693e-01],\n",
      "          [-3.7680e-01,  5.1626e-01,  2.6374e+00,  ..., -2.6977e-01,\n",
      "            1.7407e-01, -2.9088e-01],\n",
      "          ...,\n",
      "          [ 9.4688e-03,  5.1162e-01,  8.2553e-02,  ...,  1.8468e+00,\n",
      "           -1.3136e+00,  8.7835e-01],\n",
      "          [ 6.1997e-02,  2.0720e-01, -1.4475e+00,  ..., -5.8565e-01,\n",
      "            2.1495e-01, -9.5443e-01],\n",
      "          [ 1.1169e+00, -7.3163e-01,  2.0086e+00,  ...,  7.7491e-01,\n",
      "           -1.1061e+00,  1.3813e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9463e+00,  1.9756e-01,  1.0633e+00,  ..., -1.0030e+00,\n",
      "            1.3005e+00, -1.8466e-01],\n",
      "          [-4.0538e-02,  1.1191e+00, -2.7917e-01,  ...,  5.9277e-01,\n",
      "            9.4724e-01,  3.3970e-01],\n",
      "          [ 5.5641e-01, -7.9361e-01,  1.2404e+00,  ..., -6.3469e-01,\n",
      "           -7.2334e-01, -1.7131e+00],\n",
      "          ...,\n",
      "          [ 9.5884e-01, -1.2225e-01, -1.0828e+00,  ...,  2.3494e-02,\n",
      "           -8.9117e-01, -1.0496e-01],\n",
      "          [-2.9773e-01, -1.4129e+00,  2.6472e-01,  ...,  5.2666e-01,\n",
      "           -1.9818e+00, -3.8287e-01],\n",
      "          [-1.3637e-01,  5.3286e-01, -2.7032e-01,  ...,  1.7950e+00,\n",
      "           -2.6965e-01,  1.4003e+00]],\n",
      "\n",
      "         [[-2.6803e-01, -6.7971e-01,  3.2645e-01,  ..., -4.6077e-01,\n",
      "            3.7684e-01,  8.7716e-01],\n",
      "          [-3.9503e-01,  1.4017e+00, -5.1604e-01,  ..., -1.0260e-01,\n",
      "           -1.3968e+00, -1.2949e-01],\n",
      "          [-1.0598e+00,  1.7030e-01, -7.3360e-01,  ..., -2.2175e-01,\n",
      "            1.0067e+00, -1.3766e+00],\n",
      "          ...,\n",
      "          [ 7.3186e-02, -1.1362e+00, -1.6629e+00,  ...,  8.4809e-01,\n",
      "           -4.7864e-01,  8.6780e-01],\n",
      "          [-1.0692e+00,  3.1030e-01, -2.2765e-01,  ..., -4.0778e-01,\n",
      "           -4.8233e-01,  1.7116e+00],\n",
      "          [-1.6031e+00, -2.0656e+00, -3.3236e-01,  ...,  1.5773e+00,\n",
      "            9.1713e-01,  4.9223e-01]],\n",
      "\n",
      "         [[ 5.9164e-01, -9.4294e-01, -4.1866e-01,  ..., -2.8743e-01,\n",
      "            1.4741e-01,  1.8872e+00],\n",
      "          [ 9.8752e-01, -1.4153e+00,  4.5175e-01,  ..., -1.5278e+00,\n",
      "            4.1216e-01, -1.0244e+00],\n",
      "          [-1.3323e+00,  1.4965e+00,  5.1920e-02,  ..., -5.9350e-02,\n",
      "            1.2656e-01, -3.2478e-01],\n",
      "          ...,\n",
      "          [-2.2900e+00,  1.6145e+00,  9.6195e-01,  ...,  1.4482e+00,\n",
      "           -3.8028e-01,  3.5511e+00],\n",
      "          [ 5.1899e-01, -1.6478e+00, -1.3906e-01,  ...,  1.3558e-01,\n",
      "            5.3603e-01, -5.8857e-01],\n",
      "          [ 9.2201e-01,  3.1267e-01,  2.0528e-01,  ...,  2.7961e-01,\n",
      "           -1.2312e-02,  1.1222e+00]],\n",
      "\n",
      "         [[-3.9786e-01,  4.3917e-01,  6.6386e-01,  ..., -9.6125e-01,\n",
      "           -3.7636e-01,  4.7720e-02],\n",
      "          [ 2.7980e+00, -7.3738e-02,  1.0132e+00,  ...,  1.2350e+00,\n",
      "            7.1976e-01, -1.6932e+00],\n",
      "          [ 2.2540e-01,  9.4702e-01,  7.9205e-01,  ..., -1.2245e+00,\n",
      "           -3.0177e-02,  3.1212e-01],\n",
      "          ...,\n",
      "          [-2.4945e-03,  6.6086e-02, -1.2956e-01,  ..., -1.5121e+00,\n",
      "            1.2182e+00,  2.5842e+00],\n",
      "          [ 7.4599e-01,  4.8261e-01, -6.4013e-01,  ...,  2.3965e+00,\n",
      "            4.2632e-02, -4.2727e-01],\n",
      "          [-1.1492e+00, -4.8110e-01,  6.3306e-01,  ..., -1.2169e+00,\n",
      "           -1.1508e+00,  7.0684e-01]],\n",
      "\n",
      "         [[-2.9834e-01, -3.7179e-01,  8.2647e-01,  ..., -3.0544e-01,\n",
      "           -5.5097e-01, -9.1380e-01],\n",
      "          [-8.6002e-02,  7.6685e-01, -3.6806e-01,  ..., -4.5204e-01,\n",
      "           -1.4931e+00, -1.9522e-01],\n",
      "          [-3.0453e-01,  1.5957e+00,  7.2094e-01,  ...,  8.1333e-01,\n",
      "           -7.6260e-01, -5.7807e-01],\n",
      "          ...,\n",
      "          [-1.1103e+00, -1.6364e+00,  7.2463e-01,  ...,  2.0758e-01,\n",
      "           -1.3424e+00,  2.7680e-01],\n",
      "          [-1.1494e+00, -1.3075e+00, -3.2664e-01,  ...,  3.9942e-01,\n",
      "            3.6477e-01,  7.0006e-01],\n",
      "          [ 7.2417e-01, -1.7831e-01,  2.1556e+00,  ..., -1.8775e-01,\n",
      "           -3.2810e-01,  8.7920e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.2848e-01,  1.5042e+00,  2.2142e-01,  ...,  1.2088e+00,\n",
      "            1.5156e-01,  4.2855e-01],\n",
      "          [-1.1007e+00,  5.4936e-01,  6.2105e-01,  ..., -3.4078e-01,\n",
      "            6.4705e-02,  4.8394e-01],\n",
      "          [-4.4367e-01, -2.7412e-01, -2.9133e+00,  ..., -7.8303e-01,\n",
      "           -2.0325e+00, -7.6077e-01],\n",
      "          ...,\n",
      "          [ 1.2386e+00, -6.0171e-01, -1.0992e-01,  ...,  8.9821e-01,\n",
      "            1.5756e+00, -2.4705e-01],\n",
      "          [ 8.3047e-01, -1.5066e+00, -9.0792e-01,  ..., -5.2626e-01,\n",
      "           -2.2044e+00,  4.8780e-01],\n",
      "          [-4.7358e-01, -6.1115e-01,  7.1079e-01,  ...,  1.1166e+00,\n",
      "           -3.3980e-01,  5.3655e-01]],\n",
      "\n",
      "         [[-6.2666e-02,  1.0591e-01, -7.2271e-01,  ..., -1.4549e+00,\n",
      "           -1.2794e-01,  1.0296e+00],\n",
      "          [-7.7861e-01, -8.8305e-01, -1.2085e+00,  ..., -1.2760e+00,\n",
      "           -1.4952e+00,  7.2393e-01],\n",
      "          [ 1.4852e+00, -8.5608e-01,  9.7123e-01,  ...,  8.3392e-01,\n",
      "           -6.8013e-01, -9.4884e-01],\n",
      "          ...,\n",
      "          [-1.0167e+00, -1.7804e+00, -1.1485e-01,  ...,  7.0681e-01,\n",
      "            1.1125e+00, -7.4266e-01],\n",
      "          [-2.8993e+00, -2.5609e-01,  4.2942e-01,  ...,  6.0712e-01,\n",
      "           -7.4694e-03,  4.5709e-01],\n",
      "          [-2.2393e+00,  4.2516e-01,  2.1937e+00,  ..., -5.8734e-01,\n",
      "           -8.3068e-01,  1.9681e+00]],\n",
      "\n",
      "         [[ 2.8270e-01, -1.3803e+00,  2.7187e-01,  ..., -1.8352e+00,\n",
      "            8.5005e-01,  1.2746e+00],\n",
      "          [ 5.5891e-03, -4.9780e-01,  7.8079e-01,  ..., -9.8047e-02,\n",
      "           -7.8072e-01, -1.9042e-01],\n",
      "          [ 7.8400e-01, -5.9503e-01, -3.1979e-01,  ..., -2.6238e-01,\n",
      "           -7.1684e-01, -1.1218e+00],\n",
      "          ...,\n",
      "          [ 2.2153e-01,  5.3031e-02,  2.0721e-01,  ..., -1.0506e+00,\n",
      "           -3.4148e-01,  1.9178e-01],\n",
      "          [ 1.4681e+00,  1.3716e+00,  5.1895e-01,  ...,  8.9112e-01,\n",
      "           -7.6955e-01, -4.2839e-02],\n",
      "          [ 6.2033e-01, -1.0448e+00,  1.3892e+00,  ..., -1.3971e+00,\n",
      "            3.3935e-01,  2.3620e-01]],\n",
      "\n",
      "         [[ 7.0650e-01, -1.5026e-01,  7.8272e-01,  ..., -4.3295e-01,\n",
      "            1.7739e+00,  5.9566e-01],\n",
      "          [-8.0870e-02, -5.4535e-01, -9.7131e-01,  ...,  2.9180e-01,\n",
      "           -1.0397e+00, -1.9862e-01],\n",
      "          [ 1.4567e+00, -1.9548e+00,  7.6313e-01,  ...,  7.1214e-01,\n",
      "            1.2715e+00, -2.2409e+00],\n",
      "          ...,\n",
      "          [-2.8421e-01, -3.1498e-01,  4.6163e-01,  ..., -6.2010e-02,\n",
      "            4.3430e-02,  1.4545e+00],\n",
      "          [-8.5503e-01, -1.2488e+00,  9.0550e-01,  ...,  1.3374e-01,\n",
      "           -4.3728e-01, -6.9633e-02],\n",
      "          [ 3.6293e-01,  6.6735e-01,  9.6157e-01,  ...,  5.5740e-01,\n",
      "           -4.0694e-02, -5.0714e-01]],\n",
      "\n",
      "         [[ 1.1223e+00,  1.3392e-01,  1.3876e+00,  ..., -1.9901e-01,\n",
      "            1.7589e+00, -6.0862e-01],\n",
      "          [ 1.4461e+00,  9.0501e-01, -9.5690e-01,  ..., -1.6723e+00,\n",
      "           -1.1670e+00,  1.4732e+00],\n",
      "          [-5.0508e-01,  9.2554e-01,  1.0598e+00,  ..., -1.0952e+00,\n",
      "           -3.2242e+00,  5.3580e-01],\n",
      "          ...,\n",
      "          [-8.7567e-01, -8.1012e-01, -2.0230e+00,  ...,  6.5675e-01,\n",
      "            8.3669e-01, -2.0625e+00],\n",
      "          [ 1.2195e+00, -5.8851e-01, -4.7696e-01,  ...,  3.7011e-01,\n",
      "           -6.5334e-01,  8.9270e-01],\n",
      "          [-5.2200e-01,  4.4269e-01,  1.0437e+00,  ...,  5.5600e-01,\n",
      "           -2.4564e-01, -8.0442e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "num_classes = 5\n",
    "height, width = 256, 256\n",
    "\n",
    "# Salida del modelo (logits)\n",
    "y_pred_logits = torch.randn(batch_size, num_classes, height, width)\n",
    "print(y_pred_logits.shape)\n",
    "print(y_pred_logits)\n",
    "# m2d = smm.convert_to_one_hot(y_pred_logits, masks_2d)\n",
    "# m2d = sm.dice_coefficient(masks_2d, y_pred_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4edfaefd-089c-4d36-a89e-24ef8adca2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_logits.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad1dd72-0f6c-4746-bf3b-6ca60423bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D case\n",
      "y_pred shape: torch.Size([4, 5, 256, 256]), y_true shape: torch.Size([4, 256, 256])\n",
      "y_pred values: tensor([-4.6263, -4.6085, -4.5831,  ...,  4.5355,  4.7422,  4.7642])\n",
      "y_true_one_hot shape: torch.Size([4, 5, 256, 256]), y_pred_one_hot shape: torch.Size([4, 5, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "y_pred_one_hot, y_true_one_hot = smm.convert_to_one_hot(y_pred_logits, masks_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60cbee0-ce08-4207-b2e8-5d7b3d698b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n",
      "else if\n"
     ]
    }
   ],
   "source": [
    "metrics_a = sm.dice_coefficient(y_pred_one_hot, y_true_one_hot)\n",
    "metrics_b = sm.dice_coefficient(y_pred_logits, masks_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7e30c8-5678-4c09-8441-c3bfc6a7db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.2011), {'dice_class_0': 0.20053575932979584, 'dice_class_1': 0.20105890929698944, 'dice_class_2': 0.20377790927886963, 'dice_class_3': 0.20013177394866943, 'dice_class_4': 0.19978252053260803, 'dice_mean': 0.20105738937854767})\n"
     ]
    }
   ],
   "source": [
    "print(metrics_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45df90d8-d9eb-4838-a296-bf7df13767d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.2004), {'dice_class_0': 0.19954991340637207, 'dice_class_1': 0.20108310878276825, 'dice_class_2': 0.20121122896671295, 'dice_class_3': 0.19977664947509766, 'dice_class_4': 0.20027513802051544, 'dice_mean': 0.20037920773029327})\n"
     ]
    }
   ],
   "source": [
    "print(metrics_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ba71590-53e7-4447-82ee-659fe6b88ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n",
      "==> Comparación de Dice Score por clase:\n",
      "Clase 0: MONAI = 0.2005, Mi implementación = 0.2005\n",
      "Clase 1: MONAI = 0.2011, Mi implementación = 0.2011\n",
      "Clase 2: MONAI = 0.2038, Mi implementación = 0.2038\n",
      "Clase 3: MONAI = 0.2001, Mi implementación = 0.2001\n",
      "Clase 4: MONAI = 0.1998, Mi implementación = 0.1998\n",
      "\n",
      "==> Dice medio:\n",
      "MONAI = 0.2011, Mi implementación = 0.2011\n"
     ]
    }
   ],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "# ======================\n",
    "# Cálculo con MONAI\n",
    "# ======================\n",
    "n_classes = num_classes\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"none\")  # \"none\" para obtener todas las clases\n",
    "monai_dice = dice_metric(y_pred_one_hot, y_true_one_hot)\n",
    "\n",
    "# ======================\n",
    "# Cálculo con tu implementación\n",
    "# ======================\n",
    "_, my_dice = sm.dice_coefficient(y_pred_one_hot, y_true_one_hot)  # Devuelve valores por clase en un diccionario\n",
    "\n",
    "# ======================\n",
    "# Comparación\n",
    "# ======================\n",
    "print(\"==> Comparación de Dice Score por clase:\")\n",
    "for i in range(n_classes):\n",
    "    print(f\"Clase {i}: MONAI = {monai_dice[:, i].mean().item():.4f}, Mi implementación = {my_dice[f'dice_class_{i}']:.4f}\")\n",
    "\n",
    "print(f\"\\n==> Dice medio:\")\n",
    "print(f\"MONAI = {monai_dice.mean().item():.4f}, Mi implementación = {my_dice['dice_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e22b3b7-5db1-44a0-9840-c54e2840b1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D case\n",
      "y_pred shape: torch.Size([4, 5, 256, 256]), y_true shape: torch.Size([4, 256, 256])\n",
      "y_pred values: tensor([-4.6263, -4.6085, -4.5831,  ...,  4.5355,  4.7422,  4.7642])\n",
      "y_true_one_hot shape: torch.Size([4, 5, 256, 256]), y_pred_one_hot shape: torch.Size([4, 5, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "metrics_c = smm.compute_dice(y_pred_logits, masks_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6673282-ff5a-4e87-9b46-246bdfec82e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.2011), {'dice_class_0': 0.2005341649055481, 'dice_class_1': 0.20105457305908203, 'dice_class_2': 0.20378108322620392, 'dice_class_3': 0.20013247430324554, 'dice_class_4': 0.19977997243404388, 'dice_mean': 0.20105645060539246})\n"
     ]
    }
   ],
   "source": [
    "print(metrics_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd407c66-32c6-4d5e-9f4c-069ce2483672",
   "metadata": {},
   "source": [
    "# __Test 3D__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67e456a6-1b59-499d-97ae-ea722d5a6fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 5, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5  # Número de clases\n",
    "masks_3d = torch.randint(0, num_classes, (1, 64, 128, 128))  # Simulamos una máscara 3D (1 imagen, 128x128x64)\n",
    "print(masks_3d.shape)\n",
    "masks_one_hot_3d = to_one_hot(masks_3d, num_classes)\n",
    "print(masks_one_hot_3d.shape)  # Salida esperada: [1, 5, 64, 128, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80b972e9-56b9-4529-ba53-34641169f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_classes = 5\n",
    "depth, height, width = 64, 128, 128\n",
    "\n",
    "# Salida del modelo (logits)\n",
    "y_pred_logits_3d = torch.randn(batch_size, num_classes, depth, height, width)\n",
    "print(y_pred_logits_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71b75cef-ec1d-4ab2-99b2-354c4e455ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D case\n",
      "y_pred shape: torch.Size([1, 5, 64, 128, 128]), y_true shape: torch.Size([1, 64, 128, 128])\n",
      "y_pred values: tensor([-5.2455, -4.8909, -4.8806,  ...,  4.8246,  4.8773,  4.9632])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 64, 128, 128]), y_pred_one_hot shape: torch.Size([1, 5, 64, 128, 128])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "y_pred_one_hot_3d, y_true_one_hot_3d = smm.convert_to_one_hot(y_pred_logits_3d, masks_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60b28230-b210-48fa-9455-18a4003a84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D case\n",
      "y_pred shape: torch.Size([1, 5, 64, 128, 128]), y_true shape: torch.Size([1, 64, 128, 128])\n",
      "y_pred values: tensor([-5.2455, -4.8909, -4.8806,  ...,  4.8246,  4.8773,  4.9632])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 64, 128, 128]), y_pred_one_hot shape: torch.Size([1, 5, 64, 128, 128])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "(tensor(0.1999), {'dice_class_0': 0.20025311410427094, 'dice_class_1': 0.20036616921424866, 'dice_class_2': 0.19872121512889862, 'dice_class_3': 0.19920654594898224, 'dice_class_4': 0.20111529529094696, 'dice_mean': 0.19993247091770172})\n"
     ]
    }
   ],
   "source": [
    "metrics_3d = smm.compute_dice(y_pred_logits_3d, masks_3d)\n",
    "print(metrics_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f840d8a5-eff8-4b2c-9dcc-83e8ec00851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D case\n",
      "y_pred shape: torch.Size([1, 5, 64, 128, 128]), y_true shape: torch.Size([1, 64, 128, 128])\n",
      "y_pred values: tensor([-5.2455, -4.8909, -4.8806,  ...,  4.8246,  4.8773,  4.9632])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 64, 128, 128]), y_pred_one_hot shape: torch.Size([1, 5, 64, 128, 128])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "==> Comparación de Dice Score por clase:\n",
      "Clase 0: MONAI = 0.2003, Mi implementación = 0.2003\n",
      "Clase 1: MONAI = 0.2004, Mi implementación = 0.2004\n",
      "Clase 2: MONAI = 0.1987, Mi implementación = 0.1987\n",
      "Clase 3: MONAI = 0.1992, Mi implementación = 0.1992\n",
      "Clase 4: MONAI = 0.2011, Mi implementación = 0.2011\n",
      "\n",
      "==> Dice medio:\n",
      "MONAI = 0.1999, Mi implementación = 0.1999\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# Cálculo con MONAI\n",
    "# ======================\n",
    "n_classes = num_classes\n",
    "dice_metric_3d = DiceMetric(include_background=True, reduction=\"none\")  # \"none\" para obtener todas las clases\n",
    "monai_dice_3d = dice_metric(y_pred_one_hot_3d, y_true_one_hot_3d)\n",
    "\n",
    "# ======================\n",
    "# Cálculo con tu implementación\n",
    "# ======================\n",
    "_, my_dice_3d = smm.compute_dice(y_pred_logits_3d, masks_3d)  # Devuelve valores por clase en un diccionario\n",
    "\n",
    "# ======================\n",
    "# Comparación\n",
    "# ======================\n",
    "print(\"==> Comparación de Dice Score por clase:\")\n",
    "for i in range(n_classes):\n",
    "    print(f\"Clase {i}: MONAI = {monai_dice_3d[:, i].mean().item():.4f}, Mi implementación = {my_dice_3d[f'dice_class_{i}']:.4f}\")\n",
    "\n",
    "print(f\"\\n==> Dice medio:\")\n",
    "print(f\"MONAI = {monai_dice_3d.mean().item():.4f}, Mi implementación = {my_dice_3d['dice_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cde57d44-a385-46ce-8d43-c9024f8d5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_one_hot(tensor):\n",
    "    \"\"\"\n",
    "    Check if the tensor is one-hot encoded.\n",
    "    \"\"\"\n",
    "    return (tensor.sum(dim=1) == 1).all() and torch.all((tensor == 0) | (tensor == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14327ba1-2afc-4085-b109-e430f84e35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False) False\n",
      "tensor(True) True\n",
      "tensor(False) False\n",
      "tensor(True) True\n",
      "tensor(True) True\n",
      "tensor(False) False\n",
      "tensor(True) True\n",
      "tensor(True) True\n",
      "tensor(True) True\n"
     ]
    }
   ],
   "source": [
    "print(is_one_hot(masks_2d), False)\n",
    "print(is_one_hot(masks_one_hot_2d), True)\n",
    "print(is_one_hot(y_pred_logits), False)\n",
    "print(is_one_hot(y_pred_one_hot), True)\n",
    "print(is_one_hot(y_true_one_hot), True)\n",
    "print(is_one_hot(masks_3d), False)\n",
    "print(is_one_hot(masks_one_hot_3d), True)\n",
    "print(is_one_hot(y_pred_one_hot_3d), True)\n",
    "print(is_one_hot(y_true_one_hot_3d), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45a494f4-5fe1-4e49-bea7-f55e86ce79fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D case\n",
      "y_pred shape: torch.Size([1, 5, 64, 128, 128]), y_true shape: torch.Size([1, 64, 128, 128])\n",
      "y_pred values: tensor([-5.2455, -4.8909, -4.8806,  ...,  4.8246,  4.8773,  4.9632])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 64, 128, 128]), y_pred_one_hot shape: torch.Size([1, 5, 64, 128, 128])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "(tensor(0.1999), {'dice_class_0': 0.20025311410427094, 'dice_class_1': 0.20036616921424866, 'dice_class_2': 0.19872121512889862, 'dice_class_3': 0.19920654594898224, 'dice_class_4': 0.20111529529094696, 'dice_mean': 0.19993247091770172})\n",
      "Both y_pred and y_true are already one-hot encoded.\n",
      "(tensor(0.1999), {'dice_class_0': 0.20025311410427094, 'dice_class_1': 0.20036616921424866, 'dice_class_2': 0.19872121512889862, 'dice_class_3': 0.19920654594898224, 'dice_class_4': 0.20111529529094696, 'dice_mean': 0.19993247091770172})\n"
     ]
    }
   ],
   "source": [
    "metrics_3d_a = smm.compute_dice(y_pred_logits_3d, masks_3d)\n",
    "print(metrics_3d_a)\n",
    "metrics_3d_b = smm.compute_dice(y_pred_one_hot_3d, masks_one_hot_3d)\n",
    "print(metrics_3d_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a537b56-bc5f-4e1f-9491-551f0e748b7e",
   "metadata": {},
   "source": [
    "## __Perfect and worst case__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e44332cb-0027-4cd1-9768-43802cd0cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 5, 64, 128, 128])\n",
      "torch.Size([1, 5, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5  # Número de clases\n",
    "y_true_3d_perfect_i = torch.randint(0, num_classes, (1, 64, 128, 128))  # Simulamos una máscara 3D (1 imagen, 128x128x64)\n",
    "print(y_true_3d_perfect_i.shape)\n",
    "y_true_3d_perfect = to_one_hot(y_true_3d_perfect_i, num_classes)\n",
    "print(y_true_3d_perfect.shape)  # Salida esperada: [1, 5, 64, 128, 128]\n",
    "y_pred_3d_perfect = y_true_3d_perfect.clone()\n",
    "print(y_pred_3d_perfect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a4c52db-3cb7-4466-ac4c-a2b04f673b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n",
      "(tensor(1.), {'dice_class_0': 1.0, 'dice_class_1': 1.0, 'dice_class_2': 1.0, 'dice_class_3': 1.0, 'dice_class_4': 1.0, 'dice_mean': 1.0})\n"
     ]
    }
   ],
   "source": [
    "perfect_3d_dice = smm.compute_dice(y_pred_3d_perfect, y_true_3d_perfect)\n",
    "print(perfect_3d_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04b0a0be-05a5-4ef9-afef-0a63587290d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 128, 128])\n",
      "Both y_pred and y_true are already one-hot encoded.\n",
      "(tensor(0.), {'dice_class_0': 0.0, 'dice_class_1': 0.0, 'dice_class_2': 0.0, 'dice_class_3': 0.0, 'dice_class_4': 0.0, 'dice_mean': 0.0})\n"
     ]
    }
   ],
   "source": [
    "y_pred_3d_worst = (y_true_3d_perfect_i + 1) % num_classes\n",
    "print(y_pred_3d_worst.shape)\n",
    "y_pred_3d_worst = to_one_hot(y_pred_3d_worst, num_classes)\n",
    "worst_3d_dice = smm.compute_dice(y_pred_3d_worst, y_true_3d_perfect)\n",
    "print(worst_3d_dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b537f2-c2ac-4cab-ac6e-2b54aa60d293",
   "metadata": {},
   "source": [
    "## __Consistency test: 3D (depth=1) == 2D__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d55055-c523-4e51-a968-a0ea677832d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true_2d: torch.Size([1, 256, 256]) | y_true_3d: torch.Size([1, 256, 256, 1])\n",
      "y_pred_2d: torch.Size([1, 5, 256, 256]) | y_pred_3d: torch.Size([1, 5, 256, 256, 1])\n",
      "y_true_2d: torch.Size([1, 256, 256]) | y_true_3d: torch.Size([1, 1, 256, 256])\n",
      "y_pred_2d: torch.Size([1, 5, 256, 256]) | y_pred_3d: torch.Size([1, 5, 1, 256, 256])\n",
      "2D case\n",
      "y_pred shape: torch.Size([1, 5, 256, 256]), y_true shape: torch.Size([1, 256, 256])\n",
      "y_pred values: tensor([-4.2794, -4.2765, -4.1770,  ...,  4.0452,  4.3115,  4.3712])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 256, 256]), y_pred_one_hot shape: torch.Size([1, 5, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "3D case\n",
      "y_pred shape: torch.Size([1, 5, 1, 256, 256]), y_true shape: torch.Size([1, 1, 256, 256])\n",
      "y_pred values: tensor([-4.2794, -4.2765, -4.1770,  ...,  4.0452,  4.3115,  4.3712])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 1, 256, 256]), y_pred_one_hot shape: torch.Size([1, 5, 1, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "Equals: True\n",
      "(tensor(0.2010), {'dice_class_0': 0.20039895176887512, 'dice_class_1': 0.20205311477184296, 'dice_class_2': 0.202885240316391, 'dice_class_3': 0.202366903424263, 'dice_class_4': 0.19722826778888702, 'dice_mean': 0.20098650455474854})\n",
      "(tensor(0.2010), {'dice_class_0': 0.20039895176887512, 'dice_class_1': 0.20205311477184296, 'dice_class_2': 0.202885240316391, 'dice_class_3': 0.202366903424263, 'dice_class_4': 0.19722826778888702, 'dice_mean': 0.20098650455474854})\n"
     ]
    }
   ],
   "source": [
    "def consistency_test(metric='dice'):\n",
    "    b, num_classes, d, h, w = 1, 5, 1, 256, 256\n",
    "    y_true_2d = torch.randint(0, num_classes, (b, h, w))\n",
    "    y_pred_2d = torch.randn(b, num_classes, h, w)\n",
    "    y_true_3d = y_true_2d.unsqueeze(-1)  # [B, H, W, 1]\n",
    "    y_pred_3d = y_pred_2d.unsqueeze(-1)  # [B, C, H, W, 1]\n",
    "    print(f\"y_true_2d: {y_true_2d.shape} | y_true_3d: {y_true_3d.shape}\")\n",
    "    print(f\"y_pred_2d: {y_pred_2d.shape} | y_pred_3d: {y_pred_3d.shape}\")\n",
    "    y_true_3d = torch.permute(y_true_3d, (0, 3, 1, 2))\n",
    "    y_pred_3d = torch.permute(y_pred_3d, (0, 1, 4, 2, 3))\n",
    "    print(f\"y_true_2d: {y_true_2d.shape} | y_true_3d: {y_true_3d.shape}\")\n",
    "    print(f\"y_pred_2d: {y_pred_2d.shape} | y_pred_3d: {y_pred_3d.shape}\")\n",
    "\n",
    "    if metric == 'dice':\n",
    "        metric_2d = smm.compute_dice(y_pred_2d, y_true_2d)\n",
    "        metric_3d = smm.compute_dice(y_pred_3d, y_true_3d)\n",
    "    elif metric == 'iou':\n",
    "        metric_2d = smm.compute_iou(y_pred_2d, y_true_2d)\n",
    "        metric_3d = smm.compute_iou(y_pred_3d, y_true_3d)\n",
    "\n",
    "    print(\"Equals:\", metric_2d==metric_3d)\n",
    "    print(metric_2d)\n",
    "    print(metric_3d)\n",
    "\n",
    "consistency_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3664f02-4f4a-491c-b79f-8e9ab22fda85",
   "metadata": {},
   "source": [
    "# __Test IoU__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a62d9f6-410c-4030-8f9e-8af4ac606d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D case\n",
      "y_pred shape: torch.Size([4, 5, 256, 256]), y_true shape: torch.Size([4, 256, 256])\n",
      "y_pred values: tensor([-4.6263, -4.6085, -4.5831,  ...,  4.5355,  4.7422,  4.7642])\n",
      "y_true_one_hot shape: torch.Size([4, 5, 256, 256]), y_pred_one_hot shape: torch.Size([4, 5, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "3D case\n",
      "y_pred shape: torch.Size([1, 5, 64, 128, 128]), y_true shape: torch.Size([1, 64, 128, 128])\n",
      "y_pred values: tensor([-5.2455, -4.8909, -4.8806,  ...,  4.8246,  4.8773,  4.9632])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 64, 128, 128]), y_pred_one_hot shape: torch.Size([1, 5, 64, 128, 128])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "(tensor(0.1118), {'iou_class_0': 0.11144384741783142, 'iou_class_1': 0.11176510900259018, 'iou_class_2': 0.11345276981592178, 'iou_class_3': 0.11119396239519119, 'iou_class_4': 0.11097584664821625, 'iou_mean': 0.11176630109548569})\n",
      "(tensor(0.1111), {'iou_class_0': 0.11126738041639328, 'iou_class_1': 0.11133718490600586, 'iou_class_2': 0.11032229661941528, 'iou_class_3': 0.11062154173851013, 'iou_class_4': 0.11179999262094498, 'iou_mean': 0.1110696792602539})\n"
     ]
    }
   ],
   "source": [
    "iou_2d = smm.compute_iou(y_pred_logits, masks_2d)\n",
    "iou_3d = smm.compute_iou(y_pred_logits_3d, masks_3d)\n",
    "print(iou_2d)\n",
    "print(iou_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04be1c19-1c1e-4f4b-947c-51d4cd0d3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1118), {'iou_class_0': 0.11144192516803741, 'iou_class_1': 0.11176513880491257, 'iou_class_2': 0.11344805359840393, 'iou_class_3': 0.11119246482849121, 'iou_class_4': 0.11097687482833862, 'iou_mean': 0.11176488548517227})\n"
     ]
    }
   ],
   "source": [
    "iou_2d_b = sm.iou_score(y_pred_one_hot, masks_one_hot_2d)\n",
    "print(iou_2d_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fc7f2aa-ff47-4873-91a5-8c92921e3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_iou(y_pred, y_true):\n",
    "    y_pred_one_hot, y_true_one_hot = smm.convert_to_one_hot(y_pred, y_true)\n",
    "    # Calculate IoU for each class\n",
    "    iou_scores = []\n",
    "    class_iou = {}\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        pred_class = y_pred_one_hot[:, i, ...]\n",
    "        true_class = y_true_one_hot[:, i, ...]\n",
    "        \n",
    "        intersection = torch.sum(pred_class * true_class)\n",
    "        union = torch.sum(pred_class) + torch.sum(true_class) - intersection\n",
    "        iou = (intersection + 1e-9) / (union + 1e-9)\n",
    "        iou_scores.append(iou)\n",
    "        class_iou[f\"iou_class_{i}\"] = iou.item()\n",
    "    \n",
    "    mean_iou = torch.mean(torch.stack(iou_scores))\n",
    "    class_iou[\"iou_mean\"] = mean_iou.item()\n",
    "    \n",
    "    return mean_iou, class_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8363fc5c-776f-4189-9440-fefa59c92313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D case\n",
      "y_pred shape: torch.Size([4, 5, 256, 256]), y_true shape: torch.Size([4, 256, 256])\n",
      "y_pred values: tensor([-4.6263, -4.6085, -4.5831,  ...,  4.5355,  4.7422,  4.7642])\n",
      "y_true_one_hot shape: torch.Size([4, 5, 256, 256]), y_pred_one_hot shape: torch.Size([4, 5, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "(tensor(0.1118), {'iou_class_0': 0.11144192516803741, 'iou_class_1': 0.11176513880491257, 'iou_class_2': 0.11344805359840393, 'iou_class_3': 0.11119246482849121, 'iou_class_4': 0.11097687482833862, 'iou_mean': 0.11176488548517227})\n"
     ]
    }
   ],
   "source": [
    "miou_2d = manual_iou(y_pred_logits, masks_2d)\n",
    "print(miou_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2348fc6-e3c0-4ac3-b139-eb4cf0de3cad",
   "metadata": {},
   "source": [
    "## __Perfect and worst case__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0764323f-195a-4728-9a2c-23c62e7340ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n",
      "(tensor(1.), {'iou_class_0': 1.0, 'iou_class_1': 1.0, 'iou_class_2': 1.0, 'iou_class_3': 1.0, 'iou_class_4': 1.0, 'iou_mean': 1.0})\n"
     ]
    }
   ],
   "source": [
    "perfect_3d_iou = smm.compute_iou(y_pred_3d_perfect, y_true_3d_perfect)\n",
    "print(perfect_3d_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18f38139-aefa-4776-9c4c-97e81d18f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n",
      "(tensor(0.), {'iou_class_0': 0.0, 'iou_class_1': 0.0, 'iou_class_2': 0.0, 'iou_class_3': 0.0, 'iou_class_4': 0.0, 'iou_mean': 0.0})\n"
     ]
    }
   ],
   "source": [
    "worst_3d_iou = smm.compute_iou(y_pred_3d_worst, y_true_3d_perfect)\n",
    "print(worst_3d_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df18e1b-7544-4ba7-ac9a-2c774a273875",
   "metadata": {},
   "source": [
    "## __Consistency test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c31e6a0e-6db0-4703-9630-72529197a725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true_2d: torch.Size([1, 256, 256]) | y_true_3d: torch.Size([1, 256, 256, 1])\n",
      "y_pred_2d: torch.Size([1, 5, 256, 256]) | y_pred_3d: torch.Size([1, 5, 256, 256, 1])\n",
      "y_true_2d: torch.Size([1, 256, 256]) | y_true_3d: torch.Size([1, 1, 256, 256])\n",
      "y_pred_2d: torch.Size([1, 5, 256, 256]) | y_pred_3d: torch.Size([1, 5, 1, 256, 256])\n",
      "2D case\n",
      "y_pred shape: torch.Size([1, 5, 256, 256]), y_true shape: torch.Size([1, 256, 256])\n",
      "y_pred values: tensor([-4.8800, -4.5549, -4.5389,  ...,  4.6270,  4.6670,  5.0255])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 256, 256]), y_pred_one_hot shape: torch.Size([1, 5, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "3D case\n",
      "y_pred shape: torch.Size([1, 5, 1, 256, 256]), y_true shape: torch.Size([1, 1, 256, 256])\n",
      "y_pred values: tensor([-4.8800, -4.5549, -4.5389,  ...,  4.6270,  4.6670,  5.0255])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 1, 256, 256]), y_pred_one_hot shape: torch.Size([1, 5, 1, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "Equals: True\n",
      "(tensor(0.1115), {'iou_class_0': 0.11194314062595367, 'iou_class_1': 0.11024489253759384, 'iou_class_2': 0.11108763515949249, 'iou_class_3': 0.1119159534573555, 'iou_class_4': 0.11243538558483124, 'iou_mean': 0.11152540147304535})\n",
      "(tensor(0.1115), {'iou_class_0': 0.11194314062595367, 'iou_class_1': 0.11024489253759384, 'iou_class_2': 0.11108763515949249, 'iou_class_3': 0.1119159534573555, 'iou_class_4': 0.11243538558483124, 'iou_mean': 0.11152540147304535})\n"
     ]
    }
   ],
   "source": [
    "consistency_test('iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1a812-91d0-412e-a936-9027cd3d5475",
   "metadata": {},
   "source": [
    "# __Precision and recall__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94a42710-4a55-4d41-a933-8e5cd1ddeb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_logits: torch.Size([4, 5, 256, 256]) | masks_2d: torch.Size([4, 256, 256])\n",
      "y_pred_logits_3d: torch.Size([1, 5, 64, 128, 128]) | masks_3d: torch.Size([1, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_pred_logits: {y_pred_logits.shape} | masks_2d: {masks_2d.shape}\")\n",
    "print(f\"y_pred_logits_3d: {y_pred_logits_3d.shape} | masks_3d: {masks_3d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1636fcd-57da-4f85-aed1-ad336c3b5490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D case\n",
      "y_pred shape: torch.Size([4, 5, 256, 256]), y_true shape: torch.Size([4, 256, 256])\n",
      "y_pred values: tensor([-4.6263, -4.6085, -4.5831,  ...,  4.5355,  4.7422,  4.7642])\n",
      "y_true_one_hot shape: torch.Size([4, 5, 256, 256]), y_pred_one_hot shape: torch.Size([4, 5, 256, 256])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n",
      "3D case\n",
      "y_pred shape: torch.Size([1, 5, 64, 128, 128]), y_true shape: torch.Size([1, 64, 128, 128])\n",
      "y_pred values: tensor([-5.2455, -4.8909, -4.8806,  ...,  4.8246,  4.8773,  4.9632])\n",
      "y_true_one_hot shape: torch.Size([1, 5, 64, 128, 128]), y_pred_one_hot shape: torch.Size([1, 5, 64, 128, 128])\n",
      "y_true values: tensor([0, 1, 2, 3, 4])\n",
      "y_true_one_hot values: tensor([0., 1.])\n",
      "y_pred_one_hot values: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "pr_2d = smm.compute_precision_recall(y_pred_logits, masks_2d)\n",
    "pr_3d = smm.compute_precision_recall(y_pred_logits_3d, masks_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b33c4f62-bd02-4c79-9d3b-dcf4ff70aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.2011), tensor(0.2011), {'precision_class_0': 0.19984491169452667, 'precision_class_1': 0.2016676962375641, 'precision_class_2': 0.20346364378929138, 'precision_class_3': 0.20045655965805054, 'precision_class_4': 0.19988667964935303, 'precision_mean': 0.20106391608715057}, {'recall_class_0': 0.2012466937303543, 'recall_class_1': 0.2004479616880417, 'recall_class_2': 0.20411993563175201, 'recall_class_3': 0.1998201310634613, 'recall_class_4': 0.19967710971832275, 'recall_mean': 0.2010623663663864})\n",
      "(tensor(0.1999), tensor(0.1999), {'precision_class_0': 0.19995534420013428, 'precision_class_1': 0.2003929167985916, 'precision_class_2': 0.19859257340431213, 'precision_class_3': 0.19917000830173492, 'precision_class_4': 0.20155660808086395, 'precision_mean': 0.1999334841966629}, {'recall_class_0': 0.20055177807807922, 'recall_class_1': 0.2003394216299057, 'recall_class_2': 0.19885002076625824, 'recall_class_3': 0.19924309849739075, 'recall_class_4': 0.20067590475082397, 'recall_mean': 0.1999320536851883})\n"
     ]
    }
   ],
   "source": [
    "print(pr_2d)\n",
    "print(pr_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0d428fb-15c1-477a-a664-eb4d13952313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.2011), tensor(0.2011), {'precision_class_0': 0.1998366117477417, 'precision_class_1': 0.2016657441854477, 'precision_class_2': 0.20344407856464386, 'precision_class_3': 0.20045144855976105, 'precision_class_4': 0.19988928735256195, 'precision_mean': 0.20105743408203125}, {'recall_class_0': 0.20123980939388275, 'recall_class_1': 0.2004557102918625, 'recall_class_2': 0.20411284267902374, 'recall_class_3': 0.1998131275177002, 'recall_class_4': 0.19967585802078247, 'recall_mean': 0.201059490442276})\n"
     ]
    }
   ],
   "source": [
    "pr_2d_b = sm.precision_recall(y_pred_one_hot, masks_one_hot_2d)\n",
    "print(pr_2d_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2295ffdd-b316-4694-8dac-beff425b132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION\n",
      "torch.Size([4, 5])\n",
      "tensor([[0.1976, 0.1987, 0.2041, 0.2018, 0.2015],\n",
      "        [0.2028, 0.1984, 0.1985, 0.1997, 0.1988],\n",
      "        [0.1955, 0.2047, 0.2079, 0.1983, 0.1988],\n",
      "        [0.2035, 0.2048, 0.2033, 0.2021, 0.2004]])\n",
      "tensor([0.1998, 0.2017, 0.2035, 0.2005, 0.1999])\n",
      "tensor(0.2011)\n",
      "RECALL\n",
      "torch.Size([4, 5])\n",
      "tensor([[0.1995, 0.1974, 0.2062, 0.2006, 0.1999],\n",
      "        [0.2064, 0.1987, 0.1993, 0.1959, 0.1979],\n",
      "        [0.1988, 0.2037, 0.2039, 0.2001, 0.1986],\n",
      "        [0.2003, 0.2020, 0.2070, 0.2026, 0.2022]])\n",
      "tensor([0.2012, 0.2004, 0.2041, 0.1998, 0.1997])\n",
      "tensor(0.2011)\n"
     ]
    }
   ],
   "source": [
    "from monai.metrics import get_confusion_matrix, compute_confusion_matrix_metric\n",
    "cm = get_confusion_matrix(y_pred_one_hot, masks_one_hot_2d)\n",
    "# --------------\n",
    "# Precision\n",
    "monai_cm_metrics = compute_confusion_matrix_metric('precision', cm)\n",
    "print(\"PRECISION\")\n",
    "print(monai_cm_metrics.shape)\n",
    "print(monai_cm_metrics)\n",
    "monai_cm_metrics = monai_cm_metrics.mean(dim=0)\n",
    "print(monai_cm_metrics)\n",
    "print(monai_cm_metrics.mean())\n",
    "# --------------\n",
    "# Recall\n",
    "monai_cm_metrics = compute_confusion_matrix_metric('recall', cm)\n",
    "print(\"RECALL\")\n",
    "print(monai_cm_metrics.shape)\n",
    "print(monai_cm_metrics)\n",
    "monai_cm_metrics = monai_cm_metrics.mean(dim=0)\n",
    "print(monai_cm_metrics)\n",
    "print(monai_cm_metrics.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb9fd4-de96-4909-aca2-bd950d064104",
   "metadata": {},
   "source": [
    "# __Manual vs MONAI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12849f14-c053-4d7a-8048-68bced18f372",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b372e395-a0e5-492c-a16a-99191afba665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI time: 0.005656 seconds\n",
      "Manual time: 0.002005 seconds\n",
      "MONAI Precision: 0.19924600422382355\n",
      "Manual Precision: 0.1992441862821579\n",
      "Precision difference: 1.817941665649414e-06\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from monai.metrics import get_confusion_matrix, compute_confusion_matrix_metric\n",
    "\n",
    "# Crear datos de ejemplo\n",
    "batch_size = 4\n",
    "n_classes = 5\n",
    "height, width = 256, 256\n",
    "y_pred = torch.randn(batch_size, n_classes, height, width)  # Predicción\n",
    "y_true = torch.randint(0, n_classes, (batch_size, height, width))  # Ground truth\n",
    "\n",
    "# Convertir a one-hot\n",
    "y_pred_one_hot = torch.zeros(batch_size, n_classes, height, width, device=y_pred.device)\n",
    "y_pred_classes = torch.argmax(y_pred, dim=1, keepdim=True)\n",
    "y_pred_one_hot.scatter_(1, y_pred_classes, 1)\n",
    "\n",
    "y_true_one_hot = torch.zeros(batch_size, n_classes, height, width, device=y_true.device)\n",
    "y_true_one_hot.scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "\n",
    "# MONAI\n",
    "start_time = time.time()\n",
    "cm = get_confusion_matrix(y_pred_one_hot, y_true_one_hot)\n",
    "precision = compute_confusion_matrix_metric('precision', cm)\n",
    "precision = precision.mean(dim=0).mean()\n",
    "end_time = time.time()\n",
    "print(f\"MONAI time: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# Cálculo manual\n",
    "start_time = time.time()\n",
    "# Aquí puedes hacer el cálculo manual de precisión (simplificado para ejemplo)\n",
    "tp = torch.sum(y_pred_one_hot * y_true_one_hot, dim=(0, 2, 3))\n",
    "fp = torch.sum(y_pred_one_hot, dim=(0, 2, 3)) - tp\n",
    "fn = torch.sum(y_true_one_hot, dim=(0, 2, 3)) - tp\n",
    "precision_manual = tp / (tp + fp + 1e-12)  # Evitar división por cero\n",
    "precision_manual_mean = precision_manual.mean()\n",
    "end_time = time.time()\n",
    "print(f\"Manual time: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# Asumiendo que precision_monai y precision_manual son los resultados de MONAI y manual, respectivamente\n",
    "print(f\"MONAI Precision: {precision}\")\n",
    "print(f\"Manual Precision: {precision_manual.mean().item()}\")\n",
    "print(f\"Precision difference: {torch.abs(precision - precision_manual.mean().item()).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f34de-9cba-4d7f-b93d-5122bfb6c42e",
   "metadata": {},
   "source": [
    "## __Dice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8775a0d2-fe8f-43a2-9d52-4426197d2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(metrics_a, metrics_b):\n",
    "    if metrics_a == metrics_b:\n",
    "        print(\"Both metrics are identical.\")\n",
    "    else:\n",
    "        print(\"Metrics have differences.\")\n",
    "\n",
    "    print('-' * 30)\n",
    "\n",
    "    mean_a, class_a = metrics_a\n",
    "    mean_b, class_b = metrics_b\n",
    "    print(f\"Mean A: {mean_a.item()}\")\n",
    "    print(f\"Mean B: {mean_b.item()}\")\n",
    "\n",
    "    print('-' * 30)\n",
    "\n",
    "    for key in class_a:\n",
    "        if key in class_b:\n",
    "            a = class_a[key]\n",
    "            b = class_b[key]\n",
    "            same = 'EQ' if a == b else 'DIFF'\n",
    "            print(f\"{same} - {key}\")\n",
    "            if a != b:\n",
    "                print(f\"\\ta: {a}\\n\\tb: {b}\")\n",
    "\n",
    "    print('-' * 30)\n",
    "\n",
    "    print(\"Verification completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10799d22-a6a9-4e04-acd9-4e7424659f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_dice(y_pred, y_true):\n",
    "    C = y_true.size(1)\n",
    "    sum_dims = tuple(range(2, y_true.ndim))\n",
    "    \n",
    "    intersection = torch.sum(y_pred * y_true, dim=sum_dims)\n",
    "    union = torch.sum(y_pred, dim=sum_dims) + torch.sum(y_true, dim=sum_dims)\n",
    "\n",
    "    dice_scores = 2. * intersection / (union + 1e-12)\n",
    "    dice_scores = dice_scores.mean(dim=0)\n",
    "\n",
    "    dice_dict = {f\"dice_class_{i}\": dice_scores[i].item() for i in range(C)}\n",
    "    dice_dict[\"dice_mean\"] = dice_scores.mean().item()\n",
    "    \n",
    "    return dice_scores.mean(), dice_dict\n",
    "    \n",
    "    # print(\"Manual Dice Scores:\", dice_scores_manual)\n",
    "    # print(\"Manual Dice Mean:\", dice_scores_manual.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68927365-7540-4801-ad17-92d50b3744cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "monai_dice = smm.compute_dice(y_pred_one_hot, y_true_one_hot)\n",
    "md = manual_dice(y_pred_one_hot, y_true_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee6e48c8-dd61-4be2-aa11-6eec6b9652f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1992), {'dice_class_0': 0.19837766885757446, 'dice_class_1': 0.19877730309963226, 'dice_class_2': 0.2004932165145874, 'dice_class_3': 0.1992664635181427, 'dice_class_4': 0.19928932189941406, 'dice_mean': 0.1992408037185669})\n",
      "--------------\n",
      "(tensor(0.1992), {'dice_class_0': 0.19837766885757446, 'dice_class_1': 0.19877730309963226, 'dice_class_2': 0.2004932165145874, 'dice_class_3': 0.1992664635181427, 'dice_class_4': 0.19928932189941406, 'dice_mean': 0.1992408037185669})\n",
      "--------------\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(monai_dice)\n",
    "print('--------------')\n",
    "print(md)\n",
    "print('--------------')\n",
    "print(monai_dice==md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9931857f-49b0-45ca-80f1-53d4890a471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "monai_dice_3d = smm.compute_dice(y_pred_one_hot_3d, y_true_one_hot_3d)\n",
    "md_3d = manual_dice(y_pred_one_hot_3d, y_true_one_hot_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fa8c6d1-8fff-4634-88a5-3cd0f7c5d3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1999), {'dice_class_0': 0.20025311410427094, 'dice_class_1': 0.20036616921424866, 'dice_class_2': 0.19872121512889862, 'dice_class_3': 0.19920654594898224, 'dice_class_4': 0.20111529529094696, 'dice_mean': 0.19993247091770172})\n",
      "--------------\n",
      "(tensor(0.1999), {'dice_class_0': 0.20025311410427094, 'dice_class_1': 0.20036616921424866, 'dice_class_2': 0.19872121512889862, 'dice_class_3': 0.19920654594898224, 'dice_class_4': 0.20111529529094696, 'dice_mean': 0.19993247091770172})\n",
      "--------------\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(monai_dice_3d)\n",
    "print('--------------')\n",
    "print(md_3d)\n",
    "print('--------------')\n",
    "print(monai_dice_3d==md_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4679ad1-6a84-48c2-8ed4-c7a03e73dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both metrics are identical.\n",
      "------------------------------\n",
      "Mean A: 0.19993247091770172\n",
      "Mean B: 0.19993247091770172\n",
      "------------------------------\n",
      "EQ - dice_class_0\n",
      "EQ - dice_class_1\n",
      "EQ - dice_class_2\n",
      "EQ - dice_class_3\n",
      "EQ - dice_class_4\n",
      "EQ - dice_mean\n",
      "------------------------------\n",
      "Verification completed\n"
     ]
    }
   ],
   "source": [
    "compare_metrics(monai_dice_3d, md_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d30c18-92b4-4119-b2b1-93a9ff73c1ca",
   "metadata": {},
   "source": [
    "## __IoU Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d4f0412-fd8b-4c16-b729-70116bf056d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_iou(y_pred, y_true):\n",
    "    C = y_true.size(1)  # Número de clases\n",
    "    sum_dims = tuple(range(2, y_true.ndim))  # Sumar en todas las dimensiones espaciales\n",
    "\n",
    "    intersection = torch.sum(y_pred * y_true, dim=sum_dims)\n",
    "    union = torch.sum(y_pred, dim=sum_dims) + torch.sum(y_true, dim=sum_dims) - intersection\n",
    "\n",
    "    iou_scores = intersection / (union + 1e-12)  # Pequeña constante para evitar división por cero\n",
    "    iou_scores = iou_scores.mean(dim=0)  # Promedio sobre el batch\n",
    "\n",
    "    iou_dict = {f\"iou_class_{i}\": iou_scores[i].item() for i in range(C)}\n",
    "    iou_dict[\"iou_mean\"] = iou_scores.mean().item()\n",
    "    \n",
    "    return iou_scores.mean(), iou_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e696424b-3c49-43a8-b310-4023605bcd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "monai_iou = smm.compute_iou(y_pred_one_hot, y_true_one_hot)\n",
    "miou = manual_iou(y_pred_one_hot, y_true_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb781044-ea87-4580-ab42-c21953cdd2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both metrics are identical.\n",
      "------------------------------\n",
      "Mean A: 0.11064586788415909\n",
      "Mean B: 0.11064586788415909\n",
      "------------------------------\n",
      "EQ - iou_class_0\n",
      "EQ - iou_class_1\n",
      "EQ - iou_class_2\n",
      "EQ - iou_class_3\n",
      "EQ - iou_class_4\n",
      "EQ - iou_mean\n",
      "------------------------------\n",
      "Verification completed\n"
     ]
    }
   ],
   "source": [
    "compare_metrics(monai_iou, miou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07b41d7a-49f1-4ae2-aac4-095e68a17ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "monai_iou_3d = smm.compute_iou(y_pred_one_hot_3d, y_true_one_hot_3d)\n",
    "miou_3d = manual_iou(y_pred_one_hot_3d, y_true_one_hot_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7be4ce9e-b647-4b18-a520-74b2e72fdfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both metrics are identical.\n",
      "------------------------------\n",
      "Mean A: 0.1110696792602539\n",
      "Mean B: 0.1110696792602539\n",
      "------------------------------\n",
      "EQ - iou_class_0\n",
      "EQ - iou_class_1\n",
      "EQ - iou_class_2\n",
      "EQ - iou_class_3\n",
      "EQ - iou_class_4\n",
      "EQ - iou_mean\n",
      "------------------------------\n",
      "Verification completed\n"
     ]
    }
   ],
   "source": [
    "compare_metrics(monai_iou_3d, miou_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8392b6-618a-47b6-ac17-a8f753d752cc",
   "metadata": {},
   "source": [
    "## __Precision & recall__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d44572a-58df-4892-b9e8-86ba06a057a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_precision_recall(y_pred, y_true):\n",
    "    C = y_true.size(1)  # Número de clases\n",
    "    sum_dims = tuple(range(2, y_true.ndim))\n",
    "    \n",
    "    # True Positives (TP), False Positives (FP) y False Negatives (FN)\n",
    "    TP = torch.sum(y_pred * y_true, dim=sum_dims)  # Elementos correctamente predichos\n",
    "    FP = torch.sum(y_pred, dim=sum_dims) - TP  # Predicciones incorrectas\n",
    "    FN = torch.sum(y_true, dim=sum_dims) - TP  # Elementos no detectados\n",
    "    \n",
    "    # Cálculo de Precision y Recall\n",
    "    precision = TP / (TP + FP + 1e-12)\n",
    "    recall = TP / (TP + FN + 1e-12)\n",
    "    \n",
    "    # Promediar sobre el batch\n",
    "    precision = precision.mean(dim=0)\n",
    "    recall = recall.mean(dim=0)\n",
    "    \n",
    "    precision_dict = {f\"precision_class_{i}\": precision[i].item() for i in range(C)}\n",
    "    recall_dict = {f\"recall_class_{i}\": recall[i].item() for i in range(C)}\n",
    "    \n",
    "    precision_dict[\"precision_mean\"] = precision.mean().item()\n",
    "    recall_dict[\"recall_mean\"] = recall.mean().item()\n",
    "    \n",
    "    return precision.mean(), recall.mean(), precision_dict, recall_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f6fd584-5a34-462f-beae-61fb2717ec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "monai_pr = smm.compute_precision_recall(y_pred_one_hot, y_true_one_hot)\n",
    "mpr = manual_precision_recall(y_pred_one_hot, y_true_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b4da6e4-7c03-4f38-96a6-6ce856777c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both metrics are identical.\n",
      "------------------------------\n",
      "Mean A: 0.19924600422382355\n",
      "Mean B: 0.19924600422382355\n",
      "------------------------------\n",
      "EQ - precision_class_0\n",
      "EQ - precision_class_1\n",
      "EQ - precision_class_2\n",
      "EQ - precision_class_3\n",
      "EQ - precision_class_4\n",
      "EQ - precision_mean\n",
      "------------------------------\n",
      "Verification completed\n",
      "==============================\n",
      "Both metrics are identical.\n",
      "------------------------------\n",
      "Mean A: 0.19924746453762054\n",
      "Mean B: 0.19924746453762054\n",
      "------------------------------\n",
      "EQ - recall_class_0\n",
      "EQ - recall_class_1\n",
      "EQ - recall_class_2\n",
      "EQ - recall_class_3\n",
      "EQ - recall_class_4\n",
      "EQ - recall_mean\n",
      "------------------------------\n",
      "Verification completed\n"
     ]
    }
   ],
   "source": [
    "monai_p = monai_pr[::2]\n",
    "monai_r = monai_pr[1::2]\n",
    "mp = mpr[::2]\n",
    "mr = mpr[1::2]\n",
    "compare_metrics(monai_p, mp)\n",
    "print('='*30)\n",
    "compare_metrics(monai_r, mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "438ed1c2-07b5-4c5e-b772-0b28f7e24216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from monai.metrics import get_confusion_matrix, compute_confusion_matrix_metric\n",
    "\n",
    "# Crear datos de ejemplo\n",
    "def test():\n",
    "    batch_size = 64\n",
    "    n_classes = 5\n",
    "    height, width = 256, 256\n",
    "    y_pred = torch.randn(batch_size, n_classes, height, width)  # Predicción\n",
    "    y_true = torch.randint(0, n_classes, (batch_size, height, width))  # Ground truth\n",
    "    \n",
    "    # Convertir a one-hot\n",
    "    y_pred_one_hot = torch.zeros(batch_size, n_classes, height, width, device=y_pred.device)\n",
    "    y_pred_classes = torch.argmax(y_pred, dim=1, keepdim=True)\n",
    "    y_pred_one_hot.scatter_(1, y_pred_classes, 1)\n",
    "    \n",
    "    y_true_one_hot = torch.zeros(batch_size, n_classes, height, width, device=y_true.device)\n",
    "    y_true_one_hot.scatter_(1, y_true.unsqueeze(1).long(), 1)\n",
    "    \n",
    "    # MONAI\n",
    "    start_time = time.time()\n",
    "    cm = get_confusion_matrix(y_pred_one_hot, y_true_one_hot)\n",
    "    precision = compute_confusion_matrix_metric('precision', cm)\n",
    "    precision = precision.mean(dim=0).mean()\n",
    "    end_time = time.time()\n",
    "    print(f\"MONAI time: {end_time - start_time:.6f} seconds\")\n",
    "    \n",
    "    # Cálculo manual\n",
    "    start_time = time.time()\n",
    "    # Aquí puedes hacer el cálculo manual de precisión (simplificado para ejemplo)\n",
    "    precision_manual = manual_precision_recall(y_pred_one_hot, y_true_one_hot)[0]\n",
    "    end_time = time.time()\n",
    "    print(f\"Manual time: {end_time - start_time:.6f} seconds\")\n",
    "    \n",
    "    # Asumiendo que precision_monai y precision_manual son los resultados de MONAI y manual, respectivamente\n",
    "    print(f\"MONAI Precision: {precision}\")\n",
    "    print(f\"Manual Precision: {precision_manual.mean().item()}\")\n",
    "    print(f\"Precision difference: {torch.abs(precision - precision_manual.mean().item()).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b5c315e-19a9-455f-91bb-4925c20ef0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI time: 0.147126 seconds\n",
      "Manual time: 0.017724 seconds\n",
      "MONAI Precision: 0.20030975341796875\n",
      "Manual Precision: 0.20030975341796875\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.142831 seconds\n",
      "Manual time: 0.019365 seconds\n",
      "MONAI Precision: 0.20011715590953827\n",
      "Manual Precision: 0.20011715590953827\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.214869 seconds\n",
      "Manual time: 0.178271 seconds\n",
      "MONAI Precision: 0.19937287271022797\n",
      "Manual Precision: 0.19937287271022797\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.127131 seconds\n",
      "Manual time: 0.019512 seconds\n",
      "MONAI Precision: 0.20042698085308075\n",
      "Manual Precision: 0.20042698085308075\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.121785 seconds\n",
      "Manual time: 0.021129 seconds\n",
      "MONAI Precision: 0.19999970495700836\n",
      "Manual Precision: 0.19999970495700836\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.127602 seconds\n",
      "Manual time: 0.016638 seconds\n",
      "MONAI Precision: 0.19979746639728546\n",
      "Manual Precision: 0.19979746639728546\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.143857 seconds\n",
      "Manual time: 0.017687 seconds\n",
      "MONAI Precision: 0.19999894499778748\n",
      "Manual Precision: 0.19999894499778748\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.139207 seconds\n",
      "Manual time: 0.018285 seconds\n",
      "MONAI Precision: 0.20018582046031952\n",
      "Manual Precision: 0.20018582046031952\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.146759 seconds\n",
      "Manual time: 0.020203 seconds\n",
      "MONAI Precision: 0.19975502789020538\n",
      "Manual Precision: 0.19975502789020538\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n",
      "MONAI time: 0.151333 seconds\n",
      "Manual time: 0.056643 seconds\n",
      "MONAI Precision: 0.19982309639453888\n",
      "Manual Precision: 0.19982309639453888\n",
      "Precision difference: 0.0\n",
      "████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    test()\n",
    "    print('█'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92e43e-87e8-4b2c-a139-c0f1421ea386",
   "metadata": {},
   "source": [
    "# __Test new Class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50af65d8-582e-4595-a128-cf526542a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import SegmentationMetrics as SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9fd3d2b-6979-4e6f-8f9d-274837be0c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = SM.all_metrics(y_pred_logits, masks_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70e7c688-263b-4c1b-b8f6-5e7816c786bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dice_class_0': 0.2005341649055481, 'dice_class_1': 0.20105457305908203, 'dice_class_2': 0.20378108322620392, 'dice_class_3': 0.20013247430324554, 'dice_class_4': 0.19977997243404388, 'dice_mean': 0.20105645060539246, 'iou_class_0': 0.11144384741783142, 'iou_class_1': 0.11176510900259018, 'iou_class_2': 0.11345276981592178, 'iou_class_3': 0.11119396239519119, 'iou_class_4': 0.11097584664821625, 'iou_mean': 0.11176630109548569, 'precision_class_0': 0.19984491169452667, 'precision_class_1': 0.2016676962375641, 'precision_class_2': 0.20346364378929138, 'precision_class_3': 0.20045655965805054, 'precision_class_4': 0.19988667964935303, 'recall_class_0': 0.2012466937303543, 'recall_class_1': 0.2004479616880417, 'recall_class_2': 0.20411993563175201, 'recall_class_3': 0.1998201310634613, 'recall_class_4': 0.19967710971832275, 'dice': 0.20105645060539246, 'iou': 0.11176630109548569, 'precision': 0.20106391608715057, 'recall': 0.2010623663663864}\n"
     ]
    }
   ],
   "source": [
    "print(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d0f7a06-dbd4-4f4c-a4bf-4fd1aa8258ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true_2d: torch.Size([1, 256, 256]) | y_true_3d: torch.Size([1, 256, 256, 1])\n",
      "y_pred_2d: torch.Size([1, 5, 256, 256]) | y_pred_3d: torch.Size([1, 5, 256, 256, 1])\n",
      "y_true_2d: torch.Size([1, 256, 256]) | y_true_3d: torch.Size([1, 1, 256, 256])\n",
      "y_pred_2d: torch.Size([1, 5, 256, 256]) | y_pred_3d: torch.Size([1, 5, 1, 256, 256])\n",
      "Equals: True\n",
      "(tensor(0.1972), {'dice_class_0': 0.195200115442276, 'dice_class_1': 0.19414156675338745, 'dice_class_2': 0.1973593831062317, 'dice_class_3': 0.19856853783130646, 'dice_class_4': 0.200923353433609, 'dice_mean': 0.19723859429359436})\n",
      "(tensor(0.1972), {'dice_class_0': 0.195200115442276, 'dice_class_1': 0.19414156675338745, 'dice_class_2': 0.1973593831062317, 'dice_class_3': 0.19856853783130646, 'dice_class_4': 0.200923353433609, 'dice_mean': 0.19723859429359436})\n"
     ]
    }
   ],
   "source": [
    "def consistency_test(metric='dice'):\n",
    "    b, num_classes, d, h, w = 1, 5, 1, 256, 256\n",
    "    y_true_2d = torch.randint(0, num_classes, (b, h, w))\n",
    "    y_pred_2d = torch.randn(b, num_classes, h, w)\n",
    "    y_true_3d = y_true_2d.unsqueeze(-1)  # [B, H, W, 1]\n",
    "    y_pred_3d = y_pred_2d.unsqueeze(-1)  # [B, C, H, W, 1]\n",
    "    print(f\"y_true_2d: {y_true_2d.shape} | y_true_3d: {y_true_3d.shape}\")\n",
    "    print(f\"y_pred_2d: {y_pred_2d.shape} | y_pred_3d: {y_pred_3d.shape}\")\n",
    "    y_true_3d = torch.permute(y_true_3d, (0, 3, 1, 2))\n",
    "    y_pred_3d = torch.permute(y_pred_3d, (0, 1, 4, 2, 3))\n",
    "    print(f\"y_true_2d: {y_true_2d.shape} | y_true_3d: {y_true_3d.shape}\")\n",
    "    print(f\"y_pred_2d: {y_pred_2d.shape} | y_pred_3d: {y_pred_3d.shape}\")\n",
    "\n",
    "    if metric == 'dice':\n",
    "        metric_2d = SM.dice_coefficient(y_pred_2d, y_true_2d)\n",
    "        metric_3d = SM.dice_coefficient(y_pred_3d, y_true_3d)\n",
    "    elif metric == 'iou':\n",
    "        metric_2d = SM.iou_score(y_pred_2d, y_true_2d)\n",
    "        metric_3d = SM.iou_score(y_pred_3d, y_true_3d)\n",
    "\n",
    "    print(\"Equals:\", metric_2d==metric_3d)\n",
    "    print(metric_2d)\n",
    "    print(metric_3d)\n",
    "\n",
    "consistency_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04d5275d-ae2e-4c8f-b7bd-f6d653975f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both y_pred and y_true are already one-hot encoded.\n",
      "else\n",
      "Metrics have differences.\n",
      "------------------------------\n",
      "Mean A: 0.1992408037185669\n",
      "Mean B: 0.1992429792881012\n",
      "------------------------------\n",
      "DIFF - dice_class_0\n",
      "\ta: 0.19837766885757446\n",
      "\tb: 0.1983867734670639\n",
      "DIFF - dice_class_1\n",
      "\ta: 0.19877730309963226\n",
      "\tb: 0.19877557456493378\n",
      "DIFF - dice_class_2\n",
      "\ta: 0.2004932165145874\n",
      "\tb: 0.20049138367176056\n",
      "DIFF - dice_class_3\n",
      "\ta: 0.1992664635181427\n",
      "\tb: 0.1992613524198532\n",
      "DIFF - dice_class_4\n",
      "\ta: 0.19928932189941406\n",
      "\tb: 0.19929976761341095\n",
      "DIFF - dice_mean\n",
      "\ta: 0.1992408037185669\n",
      "\tb: 0.1992429792881012\n",
      "------------------------------\n",
      "Verification completed\n",
      "Metrics have differences.\n",
      "------------------------------\n",
      "Mean A: 0.1992408037185669\n",
      "Mean B: 0.20105645060539246\n",
      "------------------------------\n",
      "DIFF - dice_class_0\n",
      "\ta: 0.19837766885757446\n",
      "\tb: 0.2005341649055481\n",
      "DIFF - dice_class_1\n",
      "\ta: 0.19877730309963226\n",
      "\tb: 0.20105457305908203\n",
      "DIFF - dice_class_2\n",
      "\ta: 0.2004932165145874\n",
      "\tb: 0.20378108322620392\n",
      "DIFF - dice_class_3\n",
      "\ta: 0.1992664635181427\n",
      "\tb: 0.20013247430324554\n",
      "DIFF - dice_class_4\n",
      "\ta: 0.19928932189941406\n",
      "\tb: 0.19977997243404388\n",
      "DIFF - dice_mean\n",
      "\ta: 0.1992408037185669\n",
      "\tb: 0.20105645060539246\n",
      "------------------------------\n",
      "Verification completed\n"
     ]
    }
   ],
   "source": [
    "monai_dice = smm.compute_dice(y_pred_one_hot, y_true_one_hot)\n",
    "md_a = sm.dice_coefficient(y_pred_one_hot, y_true_one_hot)\n",
    "md_b = SM.dice_coefficient(y_pred_logits, masks_2d)\n",
    "compare_metrics(monai_dice, md_a)\n",
    "compare_metrics(monai_dice, md_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97a13f31-4988-401a-a8fd-bc8dd4368e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_2():\n",
    "    batch_size = 4\n",
    "    num_classes = 5\n",
    "    height, width = 256, 256\n",
    "    \n",
    "    # Salida del modelo (logits)\n",
    "    y_pred_logits = torch.randn(batch_size, num_classes, height, width)\n",
    "    print(y_pred_logits.shape)\n",
    "    \n",
    "    num_classes = 5  # Número de clases\n",
    "    masks_2d = torch.randint(0, num_classes, (4, 256, 256))  # Simulamos una máscara 2D (4 imágenes, 256x256)\n",
    "    print(masks_2d.shape)\n",
    "\n",
    "    # Convert to one hot\n",
    "    y_pred_one_hot, y_true_one_hot = SM.convert_to_one_hot(y_pred_logits, masks_2d)\n",
    "\n",
    "    monai_dice = smm.compute_dice(y_pred_one_hot, y_true_one_hot)\n",
    "    md_a = sm.dice_coefficient(y_pred_one_hot, y_true_one_hot)\n",
    "    md_b = SM.dice_coefficient(y_pred_logits, masks_2d)\n",
    "    compare_metrics(monai_dice, md_a)\n",
    "    compare_metrics(monai_dice, md_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ffbcd82-99c5-4d5c-ae59-4b863fde2dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 256, 256])\n",
      "torch.Size([4, 256, 256])\n",
      "Both y_pred and y_true are already one-hot encoded.\n",
      "else\n",
      "Metrics have differences.\n",
      "------------------------------\n",
      "Mean A: 0.20026692748069763\n",
      "Mean B: 0.2002691924571991\n",
      "------------------------------\n",
      "DIFF - dice_class_0\n",
      "\ta: 0.1961025595664978\n",
      "\tb: 0.19610051810741425\n",
      "DIFF - dice_class_1\n",
      "\ta: 0.20210085809230804\n",
      "\tb: 0.20210175216197968\n",
      "DIFF - dice_class_2\n",
      "\ta: 0.1993359625339508\n",
      "\tb: 0.1993325650691986\n",
      "DIFF - dice_class_3\n",
      "\ta: 0.20173121988773346\n",
      "\tb: 0.20173537731170654\n",
      "DIFF - dice_class_4\n",
      "\ta: 0.20206411182880402\n",
      "\tb: 0.2020758092403412\n",
      "DIFF - dice_mean\n",
      "\ta: 0.20026692748069763\n",
      "\tb: 0.2002691924571991\n",
      "------------------------------\n",
      "Verification completed\n",
      "Both metrics are identical.\n",
      "------------------------------\n",
      "Mean A: 0.20026692748069763\n",
      "Mean B: 0.20026692748069763\n",
      "------------------------------\n",
      "EQ - dice_class_0\n",
      "EQ - dice_class_1\n",
      "EQ - dice_class_2\n",
      "EQ - dice_class_3\n",
      "EQ - dice_class_4\n",
      "EQ - dice_mean\n",
      "------------------------------\n",
      "Verification completed\n"
     ]
    }
   ],
   "source": [
    "test_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb868a66-1ef9-4d6d-bafa-635eaf063aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_3():\n",
    "    batch_size = 4\n",
    "    num_classes = 5\n",
    "    height, width = 256, 256\n",
    "    \n",
    "    # Salida del modelo (logits)\n",
    "    y_pred_logits = torch.randn(batch_size, num_classes, height, width)\n",
    "    \n",
    "    num_classes = 5  # Número de clases\n",
    "    masks_2d = torch.randint(0, num_classes, (4, 256, 256))  # Simulamos una máscara 2D (4 imágenes, 256x256)\n",
    "\n",
    "    # Convert to one hot\n",
    "    _, y_true_one_hot = SM.convert_to_one_hot(y_pred_logits, masks_2d)\n",
    "\n",
    "    y_true_one_hot_2 = to_one_hot(masks_2d, num_classes)\n",
    "\n",
    "    print(\"Equals:\", (y_true_one_hot.all()==y_true_one_hot_2.all()).item())\n",
    "    print(f\"class: {y_true_one_hot.shape}\")\n",
    "    print(f\"to 1H: {y_true_one_hot_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12af686e-515a-4557-b359-851c37d4801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equals: True\n",
      "class: torch.Size([4, 5, 256, 256])\n",
      "to 1H: torch.Size([4, 5, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8332ea49-763e-4064-9b07-f5f09168248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect case:\n",
      "(tensor(1.), {'dice_class_0': 1.0, 'dice_class_1': 1.0, 'dice_class_2': 1.0, 'dice_class_3': 1.0, 'dice_class_4': 1.0, 'dice_mean': 1.0})\n",
      "Worst case\n",
      "(tensor(0.), {'dice_class_0': 0.0, 'dice_class_1': 0.0, 'dice_class_2': 0.0, 'dice_class_3': 0.0, 'dice_class_4': 0.0, 'dice_mean': 0.0})\n",
      "------------------------------\n",
      "else\n",
      "(tensor(1.), {'dice_class_0': 1.0, 'dice_class_1': 1.0, 'dice_class_2': 1.0, 'dice_class_3': 1.0, 'dice_class_4': 1.0, 'dice_mean': 1.0})\n",
      "else\n",
      "(tensor(2.3842e-12), {'dice_class_0': 2.3862248982320367e-12, 'dice_class_1': 2.3887727733373776e-12, 'dice_class_2': 2.38605966582095e-12, 'dice_class_3': 2.378387200727139e-12, 'dice_class_4': 2.3815138229521526e-12, 'dice_mean': 2.384191802318192e-12})\n"
     ]
    }
   ],
   "source": [
    "def test_perfect_worst():\n",
    "    num_classes = 5  # Número de clases\n",
    "    y_true_3d_perfect_i = torch.randint(0, num_classes, (1, 64, 128, 128))  # Simulamos una máscara 3D (1 imagen, 128x128x64)\n",
    "    # print(y_true_3d_perfect_i.shape)\n",
    "    y_true_3d_perfect = to_one_hot(y_true_3d_perfect_i, num_classes)\n",
    "    # print(y_true_3d_perfect.shape)  # Salida esperada: [1, 5, 64, 128, 128]\n",
    "    y_pred_3d_perfect = y_true_3d_perfect.clone()\n",
    "    # print(y_pred_3d_perfect.shape)\n",
    "    perfect_3d_dice = SM.dice_coefficient(y_pred_3d_perfect, y_true_3d_perfect)\n",
    "    print('Perfect case:')\n",
    "    print(perfect_3d_dice)\n",
    "    y_pred_3d_worst = (y_true_3d_perfect_i + 1) % num_classes\n",
    "    # print(y_pred_3d_worst.shape)\n",
    "    y_pred_3d_worst = to_one_hot(y_pred_3d_worst, num_classes)\n",
    "    worst_3d_dice = SM.dice_coefficient(y_pred_3d_worst, y_true_3d_perfect)\n",
    "    print('Worst case')\n",
    "    print(worst_3d_dice)\n",
    "\n",
    "    print('-'*30)\n",
    "    perfect_3d_dice = sm.dice_coefficient(y_pred_3d_perfect, y_true_3d_perfect)\n",
    "    print(perfect_3d_dice)\n",
    "    worst_3d_dice = sm.dice_coefficient(y_pred_3d_worst, y_true_3d_perfect)\n",
    "    print(worst_3d_dice)\n",
    "\n",
    "test_perfect_worst()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
